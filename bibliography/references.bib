@book{adjaouteAI2024,
  title = {Inside {{AI}}},
  author = {Adjaoute, Akli},
  date = {2024},
  publisher = {Manning},
  location = {Shelter Island, NY},
  abstract = {Inside AI provides a clear-headed overview of modern artificial intelligence, including the recent advances of Generative AI and Large Language Models. Its accessible and jargon-free explanations of leading AI techniques showcase how AI delivers tangible advantages to businesses. Both inspiring and practical, this book provides a proven framework for developing successful AI applications},
  isbn = {978-1-63343-772-2},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/6F3462PP/Adjaoute - 2024 - Inside AI.pdf}
}

@unpublished{agnerfogOptimizationManuals,
  title = {Optimization Manuals},
  author = {{Agner Fog}},
  url = {https://www.agner.org/optimize/#manuals},
  urldate = {2025-12-07},
  howpublished = {Manual},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/27TEB2SD/asmexamples.zip;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/4GVCFF5U/optimizing_assembly.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/8W5UB8IN/optimizing_cpp.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/ANRBYKB2/microarchitecture.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/B3E79CG3/instruction_tables.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/FP7V5ZU7/instruction_tables.ods;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/K4HJVWI7/cppexamples.zip;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/YKE5RDNS/calling_conventions.pdf}
}

@book{ahmad40AlgorithmsEvery2020,
  title = {40 {{Algorithms}} Every Programmer Should Know: {{Hone}} Your Problem-Solving Skills by Learning Different Algorithms and Their Implementation in Python},
  shorttitle = {40 {{Algorithms}} Every Programmer Should Know},
  author = {Ahmad, Imran},
  date = {2020},
  publisher = {Packt Publishing},
  location = {Place of publication not identified},
  abstract = {Learn the techniques you need to know to design algorithms for solving complex problems Become familiar with neural networks and deep learning techniques Explore different types of algorithms and choose the right data structures for their optimal implementation Book DescriptionAlgorithms have always played an important role in both the science and practice of computing. Beyond traditional computing, the ability to use algorithms to solve real-world problems is an important skill that any developer or programmer must have. This book will help you not only to develop the skills to select and use an algorithm to solve real-world problems but also to understand how it works. You'll start with an introduction to algorithms and discover various algorithm design techniques, before exploring how to implement different types of algorithms, such as searching and sorting, with the help of practical examples. As you advance to a more complex set of algorithms, you'll learn about linear programming, page ranking, and graphs, and even work with machine learning algorithms, understanding the math and logic behind them. Further on, case studies such as weather prediction, tweet clustering, and movie recommendation engines will show you how to apply these algorithms optimally. Finally, you'll become well versed in techniques that enable parallel processing, giving you the ability to use these algorithms for compute-intensive tasks. By the end of this book, you'll have become adept at solving real-world computational problems by using a wide range of algorithms},
  isbn = {978-1-78980-121-7 978-1-78980-986-2},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/Zotero/storage/SR8AV4RJ/Ahmad - 2020 - 40 Algorithms every programmer should know Hone your problem-solving skills by learning different a.pdf}
}

@misc{alexspartalisALLONEMATHEMATICS2013,
  title = {{{ALL IN ONE MATHEMATICS CHEAT SHEET V2}}.10},
  author = {{ALEX SPARTALIS}},
  date = {2013},
  url = {https://www.gsdproductions.com.au/uploads/3/5/9/8/3598073/all_in_one_cheat_sheet_v2.10_-_web.pdf},
  urldate = {2025-12-07},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/DFTXCHAP/ALEX SPARTALIS - 2013 - ALL IN ONE MATHEMATICS CHEAT SHEET V2.10.pdf}
}

@book{AlicesAdventuresDifferentiable2024,
  title = {Alice’s {{Adventures}} in a Differentiable Wonderland: {{A}} Primer on Designing Neural Networks ({{Volume I}})},
  date = {2024-07-16},
  publisher = {Independently published},
  isbn = {979-8-3321-6618-1},
  langid = {english},
  pagetotal = {279},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/YDX3PZKE/2024 - Alice’s Adventures in a differentiable wonderland A primer on designing neural networks (Volume I).pdf}
}

@article{alonBalancedFamiliesPerfect,
  title = {Balanced {{Families}} of {{Perfect Hash Functions}} and {{Their Applications}}},
  author = {Alon, Noga and Gutner, Shai},
  abstract = {Abstract. The construction of perfect hash functions is a well-studied topic. In this paper, this concept is generalized with the following definition. We say that a family of functions from [n] to [k] is a δ-balanced (n, k)-family of perfect hash functions if for every S ⊆ [n], |S| = k, the number of functions that are 1-1 on S is between T /δ and δT for some constant T {$>$} 0. The standard definition of a family of perfect hash functions requires that there will be at least one function that is 1-1 on S, for each S of size k. In the new notion of balanced families, we require the number of 1-1 functions to be almost the same (taking δ to be close to 1) for every such S. Our main result is that for any constant δ {$>$} 1, a δbalanced (n, k)-family of perfect hash functions of size 2O(k log log k) log n can be constructed in time 2O(k log log k)n log n. Using the technique of color-coding we can apply our explicit constructions to devise approximation algorithms for various counting problems in graphs. In particular, we exhibit a deterministic polynomial time algorithm for approximating both the number of simple paths of length k and the number of simple cycles of size k for any k ≤ O( log n log log log n ) in a graph with n vertices. The approximation is up to any fixed desirable relative error.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/3PAQ6JZW/Alon und Gutner - Balanced Families of Perfect Hash Functions and Their Applications.pdf}
}

@inproceedings{altadmri37MillionCompilations2015,
  title = {37 {{Million Compilations}}: {{Investigating Novice Programming Mistakes}} in {{Large-Scale Student Data}}},
  shorttitle = {37 {{Million Compilations}}},
  booktitle = {Proceedings of the 46th {{ACM Technical Symposium}} on {{Computer Science Education}}},
  author = {Altadmri, Amjad and Brown, Neil C.C.},
  date = {2015-02-24},
  pages = {522--527},
  publisher = {ACM},
  location = {Kansas City Missouri USA},
  doi = {10.1145/2676723.2677258},
  url = {https://dl.acm.org/doi/10.1145/2676723.2677258},
  urldate = {2025-12-04},
  abstract = {Previous investigations of student errors have typically focused on samples of hundreds of students at individual institutions. This work uses a year’s worth of compilation events from over 250,000 students all over the world, taken from the large Blackbox data set. We analyze the frequency, time-to-fix, and spread of errors among users, showing how these factors inter-relate, in addition to their development over the course of the year. These results can inform the design of courses, textbooks and also tools to target the most frequent (or hardest to fix) errors.},
  eventtitle = {{{SIGCSE}} '15: {{The}} 46th {{ACM Technical Symposium}} on {{Computer Science Education}}},
  isbn = {978-1-4503-2966-8},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/2874279Y/Altadmri und Brown - 2015 - 37 Million Compilations Investigating Novice Programming Mistakes in Large-Scale Student Data.pdf}
}

@article{AMSMathDocumentation,
  title = {{{AMSMath}} - {{Documentation}}},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/UA8PQNAY/amsldoc.pdf}
}

@book{anayaCleanCodePython2021,
  title = {Clean {{Code}} in {{Python}}: {{Develop}} Maintainable and Efficient Code},
  shorttitle = {Clean {{Code}} in {{Python}}},
  author = {Anaya, Mariano},
  date = {2021},
  edition = {2},
  publisher = {Packt Publishing Limited},
  location = {Birmingham},
  abstract = {bTackle inefficiencies and errors the Pythonic way/bh4Key Features/h4ulliEnhance your coding skills using the new features introduced in Python 3.9/liliImplement the refactoring techniques and SOLID principles in Python/liliApply microservices to your legacy systems by implementing practical techniques/li/ulh4Book Description/h4Experienced professionals in every field face several instances of disorganization, poor readability, and testability due to unstructured code. With updated code and revised content aligned to the new features of Python 3.9, this second edition of Clean Code in Python will provide you with all the tools you need to overcome these obstacles and manage your projects successfully. The book begins by describing the basic elements of writing clean code and how it plays a key role in Python programming. You will learn about writing efficient and readable code using the Python standard library and best practices for software design. The book discusses object-oriented programming in Python and shows you how to use objects with descriptors and generators. It will also show you the design principles of software testing and how to resolve problems by implementing software design patterns in your code. In the concluding chapter, we break down a monolithic application into a microservices-based one starting from the code as the basis for a solid platform. By the end of this clean code book, you will be proficient in applying industry-approved coding practices to design clean, sustainable, and readable real-world Python code.h4What you will learn/h4ulliSet up a productive development environment by leveraging automatic tools/liliLeverage the magic methods in Python to write better code, abstracting complexity away and encapsulating details/liliCreate advanced object-oriented designs using unique features of Python, such as descriptors/liliEliminate duplicated code by creating powerful abstractions using software engineering principles of object-oriented design/liliCreate Python-specific solutions using decorators and descriptors/liliRefactor code effectively with the help of unit tests/liliBuild the foundations for solid architecture with a clean code base as its cornerstone/li/ulh4Who this book is for/h4This book is designed to benefit new as well as experienced programmers. It will appeal to team leads, software architects and senior software engineers who would like to write Pythonic code to save on costs and improve efficiency. The book assumes that you have a strong understanding of programming},
  isbn = {978-1-80056-021-5 978-1-80056-209-7},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/MHKPUPLK/Anaya - 2021 - Clean Code in Python Develop maintainable and efficient code.pdf}
}

@book{andersonSecurityEngineeringGuide2020,
  title = {Security Engineering: A Guide to Building Dependable Distributed Systems},
  shorttitle = {Security Engineering},
  author = {Anderson, Ross},
  date = {2020},
  edition = {Third edition},
  publisher = {John Wiley \& Sons},
  location = {Indianapolis},
  abstract = {The world has changed radically since the first edition of this book was published in 2001. Spammers, virus writers, phishermen, money launderers, and spies now trade busily with each other in a lively online criminal economy and as they specialize, they get better. In this indispensable, fully updated guide, Ross Anderson reveals how to build systems that stay dependable whether faced with error or malice. Here?s straight talk on critical topics such as technical engineering basics, types of attack, specialized protection mechanisms, security psychology, policy, and more},
  isbn = {978-1-119-64278-7 978-1-119-64468-2 978-1-119-64283-1 978-1-119-64281-7},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/3LKXYSVP/Anderson - 2020 - Security engineering a guide to building dependable distributed systems.pdf}
}

@book{anticPythonNaturalLanguage2021,
  title = {Python Natural Language Processing Cookbook: Over 50 Recipes to Understand, Analyze, and Generate Text for Implementing Language Processing Tasks},
  shorttitle = {Python Natural Language Processing Cookbook},
  author = {Antić, Zhenya},
  date = {2021},
  publisher = {Packt},
  location = {Birmingham Mumbai},
  abstract = {Get to grips with solving real-world NLP problems, such as dependency parsing, information extraction, topic modeling, and text data visualizationKey FeaturesAnalyze varying complexities of text using popular Python packages such as NLTK, spaCy, sklearn, and gensimImplement common and not-so-common linguistic processing tasks using Python librariesOvercome the common challenges faced while implementing NLP pipelinesBook DescriptionPython is the most widely used language for natural language processing (NLP) thanks to its extensive tools and libraries for analyzing text and extracting computer-usable data. This book will take you through a range of techniques for text processing, from basics such as parsing the parts of speech to complex topics such as topic modeling, text classification, and visualization. Starting with an overview of NLP, the book presents recipes for dividing text into sentences, stemming and lemmatization, removing stopwords, and parts of speech tagging to help you to prepare your data. You'll then learn ways of extracting and representing grammatical information, such as dependency parsing and anaphora resolution, discover different ways of representing the semantics using bag-of-words, TF-IDF, word embeddings, and BERT, and develop skills for text classification using keywords, SVMs, LSTMs, and other techniques. As you advance, you'll also see how to extract information from text, implement unsupervised and supervised techniques for topic modeling, and perform topic modeling of short texts, such as tweets. Additionally, the book shows you how to develop chatbots using NLTK and Rasa and visualize text data. By the end of this NLP book, you'll have developed the skills to use a powerful set of tools for text processing. What you will learnBecome well-versed with basic and advanced NLP techniques in PythonRepresent grammatical information in text using spaCy, and semantic information using bag-of-words, TF-IDF, and word embeddingsPerform text classification using different methods, including SVMs and LSTMsExplore different techniques for topic modeling such as K-means, LDA, NMF, and BERTWork with visualization techniques such as NER and word clouds for different NLP toolsBuild a basic chatbot using NLTK and RasaExtract information from text using regular expression techniques and statistical and deep learning toolsWho this book is forThis book is for data scientists and professionals who want to learn how to work with text. Intermediate knowledge of Python will help you to make the most out of this book. If you are an NLP practitioner, this book will serve as a code reference when working on your projects},
  isbn = {978-1-83898-731-2 978-1-83898-778-7},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/PU846CSI/Antić - 2021 - Python natural language processing cookbook over 50 recipes to understand, analyze, and generate te.pdf}
}

@book{arndtMattersComputationalIdeas2011,
  title = {Matters {{Computational}}: {{Ideas}}, {{Algorithms}}, {{Source Code}}},
  shorttitle = {Matters {{Computational}}},
  author = {Arndt, Jörg},
  date = {2011},
  series = {{{SpringerLink Bücher}}},
  publisher = {Springer-Verlag Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-14764-7},
  abstract = {This is a book for computationalists, whether working programmers or anyone interested in methods of computation and algorithms. Where necessary, the underlying ideas are explained and the algorithms are formally presented. The C++ programming language is used for low-level algorithms, and there is only a minimal set of features beyond plain C. For material, where technicalities in the C++ code would obscure the underlying ideas, the author presents either pseudo-code or, with arithmetical algorithms, the GP language. Appendix C includes an introduction to GP. Example computations are mostly given with algorithms, some of them made with programs the author refers to. Various optimization techniques are described and the actual performance of many given implementations is indicated. The accompanying software, the FXT and the hfloat libraries, are written for POSIX-compliant platforms such as the Linux and BSD operating systems},
  isbn = {978-3-642-14763-0 978-3-642-14764-7},
  langid = {english},
  pagetotal = {978},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/3GIVAVE6/Arndt - 2011 - Matters Computational Ideas, Algorithms, Source Code.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/LPD5SLKF/fxtbook.pdf}
}

@article{article,
  title = {A Theoretical Framework for Back-Propagation},
  author = {Lecun, Yann},
  date = {2001-08},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/LU5SITGU/A Theoretical Framework for Back-Propagation (2001).pdf}
}

@report{aruobaComparisonProgrammingLanguages2014,
  title = {A {{Comparison}} of {{Programming Languages}} in {{Economics}}},
  author = {Aruoba, S. Borağan and Fernández-Villaverde, Jesús},
  date = {2014-06},
  number = {w20263},
  pages = {w20263},
  institution = {National Bureau of Economic Research},
  location = {Cambridge, MA},
  doi = {10.3386/w20263},
  url = {http://www.nber.org/papers/w20263.pdf},
  urldate = {2025-12-04},
  abstract = {We solve the stochastic neoclassical growth model, the workhorse of modern macroeconomics, using C++11, Fortran 2008, Java, Julia, Python, Matlab, Mathematica, and R. We implement the same algorithm, value function iteration with grid search, in each of the languages. We report the execution times of the codes in a Mac and in a Windows computer and comment on the strength and weakness of each language.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/QAWP6US2/Aruoba und Fernández-Villaverde - 2014 - A Comparison of Programming Languages in Economics.pdf}
}

@book{asifPythonGeeksBuild2021,
  title = {Python for {{Geeks}}: {{Build}} Production-Ready Applications Using Advanced {{Python}} Concepts and Industry Best Practices},
  shorttitle = {Python for {{Geeks}}},
  author = {Asif, Muhammad},
  date = {2021},
  edition = {1},
  publisher = {Packt Publishing Limited},
  location = {Birmingham},
  abstract = {bTake your Python skills to the next level to develop scalable, real-world applications for local as well as cloud deployment/bh4Key Features/h4ulliAll code examples have been tested with Python 3.7 and Python 3.8 and are expected to work with any future 3.x release/liliLearn how to build modular and object-oriented applications in Python/liliDiscover how to use advanced Python techniques for the cloud and clusters/li/ulh4Book Description/h4Python is a multipurpose language that can be used for multiple use cases. Python for Geeks will teach you how to advance in your career with the help of expert tips and tricks.You'll start by exploring the different ways of using Python optimally, both from the design and implementation point of view. Next, you'll understand the life cycle of a large-scale Python project. As you advance, you'll focus on different ways of creating an elegant design by modularizing a Python project and learn best practices and design patterns for using Python. You'll also discover how to scale out Python beyond a single thread and how to implement multiprocessing and multithreading in Python. In addition to this, you'll understand how you can not only use Python to deploy on a single machine but also use clusters in private as well as in public cloud computing environments. You'll then explore data processing techniques, focus on reusable, scalable data pipelines, and learn how to use these advanced techniques for network automation, serverless functions, and machine learning. Finally, you'll focus on strategizing web development design using the techniques and best practices covered in the book.By the end of this Python book, you'll be able to do some serious Python programming for large-scale complex projects.h4What you will learn/h4ulliUnderstand how to design and manage complex Python projects/liliStrategize test-driven development (TDD) in Python/liliExplore multithreading and multiprogramming in Python/liliUse Python for data processing with Apache Spark and Google Cloud Platform (GCP)/liliDeploy serverless programs on public clouds such as GCP/liliUse Python to build web applications and application programming interfaces/liliApply Python for network automation and serverless functions/liliGet to grips with Python for data analysis and machine learning/li/ulh4Who this book is for/h4This book is for intermediate-level Python developers in any field who are looking to build their skills to develop and manage large-scale complex projects. Developers who want to create reusable modules and Python libraries and cloud developers building applications for cloud deployment will also find this book useful. Prior experience with Python will help you get the most out of this book},
  isbn = {978-1-80107-011-9 978-1-80107-335-6},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/5I6ZYQM5/Asif - 2021 - Python for Geeks Build production-ready applications using advanced Python concepts and industry be.pdf}
}

@book{bahreeGenerativeAIAction2024,
  title = {Generative {{AI}} in Action},
  author = {Bahree, Amit and Boyd, Eric},
  date = {2024},
  publisher = {Manning},
  location = {Shelter Island},
  isbn = {978-1-63343-694-7},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/IMNAYSXT/Bahree und Boyd - 2024 - Generative AI in action.pdf}
}

@article{bangaScalableExplicitEvent,
  title = {A {{Scalable}} and {{Explicit Event Delivery Mechanism}} for {{UNIX}}},
  author = {Banga, Gaurav and Mogul, Jeffrey C and Druschel, Peter},
  abstract = {UNIX applications not wishing to block when doing I/O often use the select() system call, to wait for events on multiple file descriptors. The select() mechanism works well for small-scale applications, but scales poorly as the number of file descriptors increases. Many modern applications, such as Internet servers, use hundreds or thousands of file descriptors, and suffer greatly from the poor scalability of select(). Previous work has shown that while the traditional implementation of select() can be improved, the poor scalability is inherent in the design. We present a new event-delivery mechanism, which allows the application to register interest in one or more sources of events, and to efficiently dequeue new events. We show that this mechanism, which requires only minor changes to applications, performs independently of the number of file descriptors.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/8T8BJWBE/Banga et al. - A Scalable and Explicit Event Delivery Mechanism for UNIX.pdf}
}

@book{barberBayesianReasoningMachine2012,
  title = {Bayesian {{Reasoning}} and {{Machine Learning}}},
  author = {Barber, David},
  date = {2012-06-05},
  edition = {1},
  publisher = {Cambridge University Press},
  doi = {10.1017/CBO9780511804779},
  url = {https://www.cambridge.org/core/product/identifier/9780511804779/type/book},
  urldate = {2025-12-07},
  abstract = {Machine learning methods extract value from vast data sets quickly and with modest resources. They are established tools in a wide range of industrial applications, including search engines, DNA sequencing, stock market analysis, and robot locomotion, and their use is spreading rapidly. People who know the methods have their choice of rewarding jobs. This hands-on text opens these opportunities to computer science students with modest mathematical backgrounds. It is designed for final-year undergraduates and master's students with limited background in linear algebra and calculus. Comprehensive and coherent, it develops everything from basic reasoning to advanced techniques within the framework of graphical models. Students learn more than a menu of techniques, they develop analytical and problem-solving skills that equip them for the real world. Numerous examples and exercises, both computer based and theoretical, are included in every chapter. Resources for students and instructors, including a MATLAB toolbox, are available online.},
  isbn = {978-0-521-51814-7 978-0-511-80477-9},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/N72YRLK9/Barber - 2012 - Bayesian Reasoning and Machine Learning.pdf}
}

@article{barneDataStructuresAlgorithms,
  title = {Data {{Structures}} and {{Algorithms}}},
  author = {Barne, Granville and Tongo, Luca Del},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/7HLKRDRL/Barne und Tongo - Data Structures and Algorithms.pdf}
}

@article{barrosoDatacenterComputerDesigning,
  title = {The {{Datacenter}} as a {{Computer}}: {{Designing Warehouse-Scale Machines}}, {{Third Edition}}},
  author = {Barroso, Luiz André and Hölzle, Urs and Ranganathan, Parthasarathy},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/3LE2L929/Barroso et al. - The Datacenter as a Computer Designing Warehouse-Scale Machines, Third Edition.pdf}
}

@online{belazzouguiCacheObliviousPeelingRandom2013,
  title = {Cache-{{Oblivious Peeling}} of {{Random Hypergraphs}}},
  author = {Belazzougui, Djamal and Boldi, Paolo and Ottaviano, Giuseppe and Venturini, Rossano and Vigna, Sebastiano},
  date = {2013-12-02},
  eprint = {1312.0526},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1312.0526},
  url = {http://arxiv.org/abs/1312.0526},
  urldate = {2025-12-04},
  abstract = {The computation of a peeling order in a randomly generated hypergraph is the most timeconsuming step in a number of constructions, such as perfect hashing schemes, random r-SAT solvers, error-correcting codes, and approximate set encodings. While there exists a straightforward linear time algorithm, its poor I/O performance makes it impractical for hypergraphs whose size exceeds the available internal memory.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Data Structures and Algorithms},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/U46HDC7R/Belazzougui et al. - 2013 - Cache-Oblivious Peeling of Random Hypergraphs.pdf}
}

@incollection{belazzouguiHashDisplaceCompress2009,
  title = {Hash, {{Displace}}, and {{Compress}}},
  booktitle = {Algorithms - {{ESA}} 2009},
  author = {Belazzougui, Djamal and Botelho, Fabiano C. and Dietzfelbinger, Martin},
  editor = {Fiat, Amos and Sanders, Peter},
  date = {2009},
  volume = {5757},
  pages = {682--693},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-04128-0_61},
  url = {http://link.springer.com/10.1007/978-3-642-04128-0_61},
  urldate = {2025-12-04},
  abstract = {A hash function h, i.e., a function from the set U of all keys to the range range [m] = \{0, . . . , m − 1\} is called a perfect hash function (PHF) for a subset S ⊆ U of size n ≤ m if h is 1–1 on S. The important performance parameters of a PHF are representation size, evaluation time and construction time. In this paper, we present an algorithm that permits to obtain PHFs with representation size very close to optimal while retaining O(n) construction time and O(1) evaluation time. For example in the case m = 2n we obtain a PHF that uses space 0.67 bits per key, and for m = 1.23n we obtain space 1.4 bits per key, which was not achievable with previously known methods. Our algorithm is inspired by several known algorithms; the main new feature is that we combine a modification of Pagh’s “hash-and-displace” approach with data compression on a sequence of hash function indices. That combination makes it possible to significantly reduce space usage while retaining linear construction time and constant query time. Our algorithm can also be used for k-perfect hashing, where at most k keys may be mapped to the same value. For the analysis we assume that fully random hash functions are given for free; such assumptions can be justified and were made in previous papers.},
  isbn = {978-3-642-04127-3 978-3-642-04128-0},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/2QNWTWK6/Belazzougui et al. - 2009 - Hash, Displace, and Compress.pdf}
}

@inproceedings{belazzouguiMonotoneMinimalPerfect2009,
  title = {Monotone {{Minimal Perfect Hashing}}: {{Searching}} a {{Sorted Table}} with {{{\mkbibemph{O}}}} (1) {{Accesses}}},
  shorttitle = {Monotone {{Minimal Perfect Hashing}}},
  booktitle = {Proceedings of the {{Twentieth Annual ACM-SIAM Symposium}} on {{Discrete Algorithms}}},
  author = {Belazzougui, Djamal and Boldi, Paolo and Pagh, Rasmus and Vigna, Sebastiano},
  date = {2009-01-04},
  pages = {785--794},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9781611973068.86},
  url = {https://epubs.siam.org/doi/10.1137/1.9781611973068.86},
  urldate = {2025-12-04},
  abstract = {A minimal perfect hash function maps a set S of n keys into the set \{ 0, 1, . . . , n − 1 \} bijectively. Classical results state that minimal perfect hashing is possible in constant time using a structure occupying space close to the lower bound of log e bits per element. Here we consider the problem of monotone minimal perfect hashing, in which the bijection is required to preserve the lexicographical ordering of the keys. A monotone minimal perfect hash function can be seen as a very weak form of index that provides ranking just on the set S (and answers randomly outside of S). Our goal is to minimise the description size of the hash function: we show that, for a set S of n elements out of a universe of 2w elements, O(n log log w) bits are sufficient to hash monotonically with evaluation time O(log w). Alternatively, we can get space O(n log w) bits with O(1) query time. Both of these data structures improve a straightforward construction with O(n log w) space and O(log w) query time. As a consequence, it is possible to search a sorted table with O(1) accesses to the table (using additional O(n log log w) bits). Our results are based on a structure (of independent interest) that represents a trie in a very compact way, but admits errors. As a further application of the same structure, we show how to compute the predecessor (in the sorted order of S) of an arbitrary element, using O(1) accesses in expectation and an index of O(n log w) bits, improving the trivial result of O(nw) bits. This implies an efficient index for searching a blocked memory.},
  eventtitle = {Proceedings of the {{Twentieth Annual ACM-SIAM Symposium}} on {{Discrete Algorithms}}},
  isbn = {978-0-89871-680-1 978-1-61197-306-8},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/DPJU8DHH/Belazzougui et al. - 2009 - Monotone Minimal Perfect Hashing Searching a Sorted Table with O (1) Accesses.pdf}
}

@article{bengioNeuralProbabilisticLanguage,
  title = {A {{Neural Probabilistic Language Model}}},
  author = {Bengio, Yoshua and Ducharme, Réjean and Vincent, Pascal and Jauvin, Christian},
  abstract = {A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difficult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a significant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach significantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/SHWH5L3U/Bengio et al. - A Neural Probabilistic Language Model.pdf}
}

@book{benjamincrowellFundamentalsCalculus2016,
  title = {Fundamentals of {{Calculus}}},
  author = {{Benjamin Crowell} and {Joel Robbin} and {Sigurd Angenent}},
  date = {2016-01-18},
  publisher = {self published},
  url = {https://lightandmatter.com/fund/fund.pdf},
  langid = {english},
  pagetotal = {246},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/JNLZC5JD/Fundamentals of Calculs - Crowell et al - 2016.pdf}
}

@online{beraAdvancedBloomFilter2012,
  title = {Advanced {{Bloom Filter Based Algorithms}} for {{Efficient Approximate Data De-Duplication}} in {{Streams}}},
  author = {Bera, Suman K. and Dutta, Sourav and Narang, Ankur and Bhattacherjee, Souvik},
  date = {2012-12-17},
  eprint = {1212.3964},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1212.3964},
  url = {http://arxiv.org/abs/1212.3964},
  urldate = {2025-12-07},
  abstract = {Data intensive applications and computing has emerged as a central area of modern research with the explosion of data stored world-wide. Applications involving telecommunication call data records, web pages, online transactions, medical records, stock markets, climate warning systems, etc., necessitate efficient management and processing of such massively exponential amount of data from diverse sources. Duplicate detection and removal of redundancy from such multibillion datasets helps in resource and compute efficiency for downstream processing. De-duplication or Intelligent Compression in streaming scenarios for approximate identification and elimination of duplicates from such unbounded data stream is a greater challenge given the real-time nature of data arrival. Stable Bloom Filters (SBF) addresses this problem to a certain extent. However, SBF suffers from a high false negative rate and slow convergence rate, thereby rendering it inefficient for applications with low false negative rate tolerances.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Information Retrieval},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/VXFDVJMU/Bera et al. - 2012 - Advanced Bloom Filter Based Algorithms for Efficient Approximate Data De-Duplication in Streams.pdf}
}

@book{bertonAnsibleKubernetesExample2023,
  title = {Ansible for {{Kubernetes}} by {{Example}}: {{Automate Your Kubernetes Cluster}} with {{Ansible}}},
  shorttitle = {Ansible for {{Kubernetes}} by {{Example}}},
  author = {Berton, Luca},
  date = {2023},
  edition = {1st ed},
  publisher = {Apress L. P},
  location = {Berkeley, CA},
  isbn = {978-1-4842-9284-6 978-1-4842-9285-3},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/TVUSJSIP/Berton - 2023 - Ansible for Kubernetes by Example Automate Your Kubernetes Cluster with Ansible.epub}
}

@book{bertonKubernetesRecipesPractical2025,
  title = {Kubernetes {{Recipes}}: A Practical Guide for Container Orchestration and Deployment},
  shorttitle = {Kubernetes {{Recipes}}},
  author = {Berton, Luca and Stencel, Grzegorz},
  date = {2025},
  edition = {1. Auflage},
  publisher = {APRESS},
  location = {Bournemouth},
  isbn = {979-8-8688-1324-5},
  langid = {english},
  pagetotal = {749},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/DAGN4GUH/Berton und Stencel - 2025 - Kubernetes Recipes a practical guide for container orchestration and deployment.epub}
}

@article{bezosEnumitemCustomizingLists,
  title = {Enumitem - {{Customizing}} Lists with the Enumitem Package},
  author = {Bezos, Javier},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/8DJBVPVK/Bezos - Customizing lists with the enumitem package.pdf}
}

@article{bezPerfectHashFunction,
  title = {Perfect Hash Function Generation on the GPU with RecSplit - Master's Thesis of Dominik Bez},
  author = {Bez, Dominik},
  langid = {ngerman},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/TXFYCQ76/Bez - Perfect Hash Function Generation on the GPU with RecSplit - Master's Thesis of Dominik Bez.pdf}
}

@article{blundellWritingSimpleOperating,
  title = {Writing a {{Simple Operating System}} — from {{Scratch}}},
  author = {Blundell, Nick},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/DESWSXG4/Blundell - Writing a Simple Operating System — from Scratch.pdf}
}

@article{botelhoApproachMinimalPerfect,
  title = {An {{Approach}} for {{Minimal Perfect Hash Functions}} for {{Very Large Databases}}},
  author = {Botelho, Fabiano C and Kohayakawa, Yoshiharu and Ziviani, Nivio},
  abstract = {We propose a novel external memory based algorithm for constructing minimal perfect hash functions h for huge sets of keys. For a set of n keys, our algorithm outputs h in time O(n). The algorithm needs a small vector of one byte entries in main memory to construct h. The evaluation of h(x) requires three memory accesses for any key x. The description of h takes a constant number of up to 9 bits for each key, which is optimal and close to the theoretical lower bound, i.e., around 2 bits per key. In our experiments, we used a collection of 1 billion URLs collected from the web, each URL 64 characters long on average. For this collection, our algorithm (i) finds a minimal perfect hash function in approximately 3 hours using a commodity PC, (ii) needs just 5.45 megabytes of internal memory to generate h and (iii) takes 8.1 bits per key for the description of h.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/FFTVBG9E/Botelho et al. - An Approach for Minimal Perfect Hash Functions for Very Large Databases.pdf}
}

@incollection{botelhoPracticalMinimalPerfect2005,
  title = {A {{Practical Minimal Perfect Hashing Method}}},
  booktitle = {Experimental and {{Efficient Algorithms}}},
  author = {Botelho, Fabiano C. and Kohayakawa, Yoshiharu and Ziviani, Nivio},
  editor = {Nikoletseas, Sotiris E.},
  editora = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard},
  editoratype = {redactor},
  date = {2005},
  volume = {3503},
  pages = {488--500},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/11427186_42},
  url = {http://link.springer.com/10.1007/11427186_42},
  urldate = {2025-12-04},
  abstract = {We propose a novel algorithm based on random graphs to construct minimal perfect hash functions h. For a set of n keys, our algorithm outputs h in expected time O(n). The evaluation of h(x) requires two memory accesses for any key x and the description of h takes up 1.15n words. This improves the space requirement to 55\% of a previous minimal perfect hashing scheme due to Czech, Havas and Majewski. A simple heuristic further reduces the space requirement to 0.93n words, at the expense of a slightly worse constant in the time complexity. Large scale experimental results are presented.},
  isbn = {978-3-540-25920-6 978-3-540-32078-4},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/C2F7RW7R/Botelho et al. - 2005 - A Practical Minimal Perfect Hashing Method.pdf}
}

@incollection{botelhoPracticalMinimalPerfect2005a,
  title = {A {{Practical Minimal Perfect Hashing Method}}},
  booktitle = {Experimental and {{Efficient Algorithms}}},
  author = {Botelho, Fabiano C. and Kohayakawa, Yoshiharu and Ziviani, Nivio},
  editor = {Nikoletseas, Sotiris E.},
  editora = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard},
  editoratype = {redactor},
  date = {2005},
  volume = {3503},
  pages = {488--500},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/11427186_42},
  url = {http://link.springer.com/10.1007/11427186_42},
  urldate = {2025-12-05},
  abstract = {We propose a novel algorithm based on random graphs to construct minimal perfect hash functions h. For a set of n keys, our algorithm outputs h in expected time O(n). The evaluation of h(x) requires two memory accesses for any key x and the description of h takes up 1.15n words. This improves the space requirement to 55\% of a previous minimal perfect hashing scheme due to Czech, Havas and Majewski. A simple heuristic further reduces the space requirement to 0.93n words, at the expense of a slightly worse constant in the time complexity. Large scale experimental results are presented.},
  isbn = {978-3-540-25920-6 978-3-540-32078-4},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/UWMVUHWD/Botelho et al. - 2005 - A Practical Minimal Perfect Hashing Method.pdf}
}

@incollection{botelhoSimpleSpaceEfficientMinimal2007,
  title = {Simple and {{Space-Efficient Minimal Perfect Hash Functions}}},
  booktitle = {Algorithms and {{Data Structures}}},
  author = {Botelho, Fabiano C. and Pagh, Rasmus and Ziviani, Nivio},
  editor = {Dehne, Frank and Sack, Jörg-Rüdiger and Zeh, Norbert},
  date = {2007},
  volume = {4619},
  pages = {139--150},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  issn = {0302-9743, 1611-3349},
  doi = {10.1007/978-3-540-73951-7_13},
  url = {http://link.springer.com/10.1007/978-3-540-73951-7_13},
  urldate = {2025-12-04},
  abstract = {A perfect hash function (PHF) h : U → [0, m − 1] for a key set S is a function that maps the keys of S to unique values. The minimum amount of space to represent a PHF for a given set S is known to be approximately 1.44n2/m bits, where n = |S|. In this paper we present new algorithms for construction and evaluation of PHFs of a given set (for m = n and m = 1.23n), with the following properties: 1. Evaluation of a PHF requires constant time. 2. The algorithms are simple to describe and implement, and run in linear time. 3. The amount of space needed to represent the PHFs is around a factor 2 from the information theoretical minimum. No previously known algorithm has these properties. To our knowledge, any algorithm in the literature with the third property either: – Requires exponential time for construction and evaluation, or – Uses near-optimal space only asymptotically, for extremely large n. Thus, our main contribution is a scheme that gives low space usage for realistic values of n. The main technical ingredient is a new way of basing PHFs on random hypergraphs. Previously, this approach has been used to design simple PHFs with superlinear space usage3.},
  isbn = {978-3-540-73948-7 978-3-540-73951-7},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/D58HBBK3/Botelho et al. - 2007 - Simple and Space-Efficient Minimal Perfect Hash Functions.pdf}
}

@book{bothLinuxSmallBusiness2022,
  title = {Linux for {{Small Business Owners}}: {{Using Free}} and {{Open Source Software}} to {{Power Your Dreams}}},
  shorttitle = {Linux for {{Small Business Owners}}},
  author = {Both, David},
  namea = {Bulka, Cyndi},
  nameatype = {collaborator},
  date = {2022},
  edition = {1st ed},
  publisher = {Apress L. P},
  location = {Berkeley, CA},
  abstract = {Intro -- Table of Contents -- About the Authors -- About the Technical Reviewer -- Acknowledgments -- Introduction -- Chapter 1: Using Linux - The Personal Case -- Objectives -- Introduction -- Who We Are -- Cyndi -- David -- Why I Use Linux -- Linux Is Free (as in Beer) -- Linux Is Free (as in Speech) -- Linux Is Safe -- Linux Is Reliable -- Linux Is Powerful -- Linux Gives You Complete Control -- Linux Extends the Life of Your Hardware -- Linux Is Easy -- Lots of Software -- Linux Is Fun -- Chapter Summary -- Exercises -- Chapter 2: A Bit of History - Becoming Linux -- Objectives -- Introduction -- Windows Origins -- Unix -- The Birth of Linux -- The Linux Truth -- What It Means to Small Business Owners -- Chapter Summary -- Chapter 3: Using Linux - The Business Case -- Objectives -- Introduction -- The Usual Reasons for Using Linux -- Reliability -- Extensive Software Choices -- Security -- Free as in Beer -- Free as in Speech -- Cyndi -- David -- SELinux -- Support -- Proprietary Software and Maintainability -- FOSS and Maintainability -- Stability -- Why You Should Use Linux -- The Points of Pain -- Chapter Summary -- Chapter 4: Choosing Hardware -- Objectives -- Introduction -- Bottom Line -- Compatibility -- Viewing Information Using BIOS or UEFI -- Accessing BIOS/UEFI -- System Information -- Rescuing Older Computers -- Guidelines for Older Computers -- General Considerations for Used Computers -- Purchasing a New Computer -- Guidelines for New Computers -- Processor Details -- Intel -- AMD -- Processor Comparison List -- Standardization -- What We Have -- Laptops -- Where to Buy -- Choosing a Computer Store -- Big-Box Stores -- Linux User Groups -- Online Computer Stores -- System76 -- Emperor Linux -- Our Test Computer -- Entering BIOS Mode -- Chapter Summary -- Chapter 5: Take Linux for a Test Drive -- Objectives -- Introduction},
  isbn = {978-1-4842-8263-2 978-1-4842-8264-9},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/JSMHTMDL/Both - 2022 - Linux for Small Business Owners Using Free and Open Source Software to Power Your Dreams.epub}
}

@book{bothSystemdLinuxSysAdmins2025,
  title = {Systemd for {{Linux SysAdmins}}: All You Need to Know about the Systemd Suite for {{Linux}} Users},
  shorttitle = {Systemd for {{Linux SysAdmins}}},
  author = {Both, David P.},
  date = {2025},
  publisher = {APRESS},
  location = {New York, NY},
  abstract = {Explore the world of systemd--yes, all lower-case, even at the beginning of a sentence-- which is the modern replacement for init and SystemV init scripts. It is also much more. It can evoke a wide range of reactions from SysAdmins and others responsible for keeping Linux systems up and running. The fact that systemd is taking over so many tasks in modern Linux systems has engendered push-back and discord among certain groups of developers and SysAdmins. You will learn systemd's strengths and weaknesses, and why there's no truth in the myth that systemd is a monolithic monstrosity.Learn how systemd is the mother of all processes, and is responsible for bringing the Linux host up to a state in which productive work can be done. You'll learn about the functions assumed by systemd, which is far more extensive than the old init program, and how it manages many aspects of a running Linux host, including: Mounting filesystems Managing hardware Creating new systemd services and understanding existing ones Creating timers that trigger system maintenance events Starting and managing the system services that are required to have a productive Linux host Using the systemd journal to access critical performance and problem solving information. Why the systemd plan to take over the world is actually a good thing systemd for Linux SysAdmins is your one-stop shop, giving you everythiing you need to get started and utilize this software suite for Linux operatiing systems. You Will Learn: How to use systemd, what it is, and what it does To manage each of the major functional components of systemd and learn from real-world examples to illustrate their typical usage by SysAdmins Pragmatic work-arounds, hints and tricks to minimize issues to ensure you have greater systemd functionality This Book is for: Linux system administrators (SysAdmins) who need to or are already in the process of switching from SystemV to systemd. It's also intended for SysAdmins with more systemd experience but who want to improve their knowledge and skills with systemd},
  isbn = {979-8-8688-1328-3},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/32RTQJFD/Both - 2025 - Systemd for Linux SysAdmins all you need to know about the systemd suite for Linux users.epub}
}

@book{bothUsingAdministeringLinux2023,
  title = {Using and {{Administering Linux}}: {{Zero}} to {{SysAdmin}}: {{Getting Started}}},
  shorttitle = {Using and {{Administering Linux}}},
  author = {Both, David},
  date = {2023},
  edition = {2nd ed},
  publisher = {Apress L. P},
  location = {Berkeley, CA},
  abstract = {Intro -- Table of Contents -- About the Author -- About the Technical Reviewers -- Acknowledgments -- Introduction -- Chapter 1: Introduction -- Objectives -- About Linux -- The Birth of Windows -- Black Box Syndrome -- The Birth of Linux -- The Open Box -- The Linux Truth -- Knowledge -- Flexibility -- Stability -- Scalability -- Security -- Freedom -- Our Software Rights -- Longevity -- Data -- Resist Malware -- Should I Be a SysAdmin? -- About This Course -- About the Experiments -- What to Do If the Experiments Do Not Work -- Terminology -- How to Access the Command Line -- Chapter Summary -- Exercises -- Chapter 2: Introduction to Operating Systems -- Objectives -- Choice - Really! -- What Is an Operating System? -- Hardware -- Motherboard -- The Processor -- Hyperthreading -- P- and E-Cores -- Peripherals -- The Operating System -- The Definition -- Typical Operating System Functions -- Memory Management -- Multitasking -- Multiuser -- Process Management -- Interprocess Communication -- Device Management -- Error Handling -- Utilities -- A Bit of History -- Starting with UNICS -- UNIX -- The Berkeley Software Distribution (BSD) -- The Unix Philosophy -- A (Very) Brief History of Linux -- Core Utilities -- GNU Coreutils -- util-linux -- Copyleft -- Games -- Chapter Summary -- Exercises -- Chapter 3: The Linux Philosophy for SysAdmins -- Objectives -- Background -- The Structure of the Philosophy -- The Tenets -- Data Streams Are a Universal Interface -- Transforming Data Streams -- Everything Is a File -- Use the Linux FHS -- Embrace the CLI -- Be the Lazy SysAdmin -- Automate Everything -- Always Use Shell Scripts -- Test Early and Test Often -- Use Commonsense Naming -- Store Data in Open Formats -- Use Separate Filesystems for Data -- Make Programs Portable -- Use Open Source Software -- Strive for Elegance -- Find the Simplicity},
  isbn = {978-1-4842-9618-9},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/RSFGU7XT/Both - 2023 - Using and Administering Linux Zero to SysAdmin Getting Started.epub}
}

@book{bothUsingAdministeringLinux2023a,
  title = {Using and {{Administering Linux}}: {{Zero}} to {{SysAdmin}}: {{Advanced Topics}}},
  shorttitle = {Using and {{Administering Linux}}},
  author = {Both, David},
  date = {2023},
  edition = {2nd ed},
  publisher = {Apress L. P},
  location = {Berkeley, CA},
  abstract = {Intro -- Table of Contents -- About the Author -- About the Technical Reviewers -- Acknowledgments -- Introduction -- Chapter 20: Logical Volume Management (LVM) -- Objectives -- The Need for Logical Volume Management -- Running Out of Disk Space in VirtualBox -- Recovery -- LVM Structure -- Extending a Logical Volume -- Creating and Extending Volume Groups -- Create a New Volume Group -- Extend an Existing Volume Group -- Tips -- Advanced Capabilities -- Chapter Summary -- Exercises -- Chapter 21: File Managers -- Objectives -- Introduction -- Text-Mode Interface -- Graphical Interface -- Default File Manager -- Text-Mode File Managers -- Midnight Commander -- Other Text-Mode File Managers -- Vifm -- nnn -- Graphical File Managers -- Krusader -- Thunar -- Dolphin -- XFE -- Other File Managers -- Chapter Summary -- Exercises -- Chapter 22: Everything Is a File -- Objectives -- What Is a File? -- Device Files -- Device File Creation -- udev Simplification -- Naming Rules -- Rule Change Blues -- Device Data Flow -- Device File Classification -- Fun with Device Files -- Randomness, Zero, and More -- Back Up the Master Boot Record -- Implications of Everything Is a File -- Chapter Summary -- Exercises -- Chapter 23: Managing Processes -- Objectives -- Processes -- Process Scheduling in the Kernel -- Tools -- top -- Summary Section -- Process Section -- More About Load Averages … -- …and Signals -- CPU Hogs -- Process Scheduling -- Nice Numbers -- Killing Processes -- Other Interactive Tools -- atop -- Summary Section -- Process Section -- Configuration -- htop -- Summary Section -- Process Section -- Configuration -- Glances -- Summary Section -- Process Section -- Sidebar -- Configuration -- Other Tools -- The Impact of Measurement -- Chapter Summary -- Exercises -- Chapter 24: Special Filesystems -- Objectives -- Introduction},
  isbn = {978-1-4842-9615-8},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/RKCELKEN/Both - 2023 - Using and Administering Linux Zero to SysAdmin Advanced Topics.epub}
}

@book{bothUsingAdministeringLinux2023b,
  title = {Using and {{Administering Linux}}: {{Zero}} to {{SysAdmin}}: {{Network Services}}},
  shorttitle = {Using and {{Administering Linux}}},
  author = {Both, David},
  date = {2023},
  edition = {2nd ed},
  publisher = {Apress L. P},
  location = {Berkeley, CA},
  abstract = {Intro -- Table of Contents -- About the Author -- About the Technical Reviewers -- Acknowledgments -- Introduction -- Chapter 42: Server Preparation -- Objectives -- Overview -- Creating the VM -- Installing Linux -- Personalization and Updates -- Virtual Network Configuration -- Adjusting the Firewall -- Overview of DHCP -- Installing the DHCP Server -- Configuring the DHCP Server -- Configuring the Client Host -- Configuring Guest Hosts -- The Final dhcpd.conf File -- Configuring NTP with Chrony -- Configuring the NTP Server -- Configure and Test the NTP Client -- Chapter Summary -- Exercises -- Chapter 43: Name Services -- Objectives -- Introducing Domain Name Services -- How a Name Search Works -- Top-Level Configuration -- NSS and NSSwitch -- resolv.conf -- Historical Usage -- Current Usage -- systemd-resolved.service -- Name Service Strategies -- The /etc/hosts File -- mDNS -- How It Works -- mDNS Performance -- nss-DNS -- The DNS Database -- Using the dig and nslookup Commands -- Interpreting dig Command Results -- Advanced dig Command Results -- Common DNS Record Types -- SOA -- ORIGIN -- NS -- A -- AAAA -- CNAME -- DNSKEY -- DS -- MX -- PTR -- RRSIG -- Other Records -- Using BIND -- Preparation -- Setting Up the Caching Name Server -- Configuring the Firewall for DNS -- Start the Name Service -- Reconfiguring DHCP -- Using the Top-Level DNS Servers -- Creating a Primary Name Server -- Creating the Forward Zone File -- Adding the Forward Zone File to named.conf -- Adding CNAME Records -- Creating the Reverse Zone File -- Adding the Reverse Zone to named.conf -- Automating BIND Administration -- Chapter Summary -- Exercises -- Chapter 44: Routing -- Objectives -- Introduction -- Routing on a Workstation -- Creating a Router -- Setting Up the Router -- Kernel Configuration -- Firewall State -- Firewall Requirements -- Zones},
  isbn = {978-1-4842-9786-5},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/VZ747Z4K/Both - 2023 - Using and Administering Linux Zero to SysAdmin Network Services.epub}
}

@inproceedings{boulosAdaptiveRayPacket2008,
  title = {Adaptive Ray Packet Reordering},
  booktitle = {2008 {{IEEE Symposium}} on {{Interactive Ray Tracing}}},
  author = {Boulos, Solomon and Wald, Ingo and Benthin, Carsten},
  date = {2008-08},
  pages = {131--138},
  publisher = {IEEE},
  location = {Los Angeles, CA, USA},
  doi = {10.1109/RT.2008.4634633},
  url = {http://ieeexplore.ieee.org/document/4634633/},
  urldate = {2025-12-07},
  abstract = {Modern high-performance ray tracers use large ray packets and SIMD instruction sets to decrease both the computational and bandwidth cost compared to a single ray implementation. Current global illumination renderers, however, are still based around single ray implementations and interfaces. The presumption is that while packets have been shown to work well for highly coherent rays, in the presence of less coherent secondary ray distributions the gains of both packet and SIMD techniques dwindle rapidly. With low enough coherence, performance can be reduced to being as slow as reasonable single ray code – if not worse – so the benefit of packets for a global illumination system is assumed to be next to none. With SIMD width expanding in future architectures, leaving SIMD units underutilized means a massive loss in performance compared to the maximum performance achievable. In this paper, we present a method for recovering packet and SIMD coherence for incoherent secondary ray distributions through demand-driven reordering of rays into more coherent packets. We demonstrate that the reordering overhead is outweighed by the increased coherence within a prototypical implementation in the Manta realtime ray tracer among a wide variety of ray distributions, including diffuse path tracing.},
  eventtitle = {2008 {{IEEE Symposium}} on {{Interactive Ray Tracing}} ({{RT}})},
  isbn = {978-1-4244-2741-3},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/ICBHGD8M/Boulos et al. - 2008 - Adaptive ray packet reordering.pdf}
}

@article{bramasNovelHybridQuicksort2017,
  title = {A {{Novel Hybrid Quicksort Algorithm Vectorized}} Using {{AVX-512}} on {{Intel Skylake}}},
  author = {Bramas, Berenger},
  date = {2017},
  journaltitle = {International Journal of Advanced Computer Science and Applications},
  shortjournal = {ijacsa},
  volume = {8},
  number = {10},
  issn = {21565570, 2158107X},
  doi = {10.14569/IJACSA.2017.081044},
  url = {http://thesai.org/Publications/ViewPaper?Volume=8&Issue=10&Code=ijacsa&SerialNo=44},
  urldate = {2025-12-05},
  abstract = {The modern CPU’s design, which is composed of hierarchical memory and SIMD/vectorization capability, governs the potential for algorithms to be transformed into efficient implementations. The release of the AVX-512 changed things radically, and motivated us to search for an efficient sorting algorithm that can take advantage of it. In this paper, we describe the best strategy we have found, which is a novel two parts hybrid sort, based on the well-known Quicksort algorithm. The central partitioning operation is performed by a new algorithm, and small partitions/arrays are sorted using a branch-free Bitonicbased sort. This study is also an illustration of how classical algorithms can be adapted and enhanced by the AVX-512 extension. We evaluate the performance of our approach on a modern Intel Xeon Skylake and assess the different layers of our implementation by sorting/partitioning integers, double floatingpoint numbers, and key/value pairs of integers. Our results demonstrate that our approach is faster than two libraries of reference: the GNU C++ sort algorithm by a speedup factor of 4, and the Intel IPP library by a speedup factor of 1.4.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/9VLZ5VS7/Bramas - 2017 - A Novel Hybrid Quicksort Algorithm Vectorized using AVX-512 on Intel Skylake.pdf}
}

@book{bronstejnTaschenbuchMathematik2001,
  title = {Taschenbuch der Mathematik},
  editor = {Bronštejn, Ilʹja N. and Semendjaev, Konstantin A.},
  date = {2001},
  edition = {5., überarb. und erw. Aufl., unver. Nachdr},
  publisher = {Deutsch},
  location = {Thun Frankfurt am Main},
  isbn = {978-3-8171-2005-5 978-3-8171-2015-4},
  langid = {german},
  pagetotal = {1191},
  file = {/Users/bernhardgerlach/Zotero/storage/6RFAQVFC/Taschenbuch der Mathematik, desktop edition -- Bronstein, Semendjajew, Musiol, Muehlig. -- ( WeLib.org ).pdf;/Users/bernhardgerlach/Zotero/storage/J8ZGXYWH/Bronštejn und Semendjaev - 2001 - Taschenbuch der Mathematik.pdf;/Users/bernhardgerlach/Zotero/storage/UB5K6AKU/Bronstein et al. - 2001 - Tschenbuch der Mathematik.pdf}
}

@book{brucePracticalStatisticsData2017,
  title = {Practical Statistics for Data Scientists: 50 Essential Concepts},
  shorttitle = {Practical Statistics for Data Scientists},
  author = {Bruce, Peter C. and Bruce, Andrew},
  date = {2017},
  edition = {First edition},
  publisher = {O'Reilly},
  location = {Beijing Boston Farnham Sebastopol Tokyo},
  isbn = {978-1-4919-5296-2 978-1-4919-5293-1},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/Zotero/storage/PUW6LK3S/Bruce und Bruce - 2017 - Practical Statistics for Data Scientists.pdf}
}

@article{burrowsBlocksortingLosslessData,
  title = {A Block-Sorting Lossless Data Compression Algorithm},
  author = {Burrows, M and Wheeler, David J},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/2U2SRX9P/Burrows und Wheeler - A block-sorting lossless data compression algorithm.pdf}
}

@article{cerconeInformalAnalysisPerfect1989,
  title = {An Informal Analysis of Perfect Hash Function Search},
  author = {Cercone, Nick and Krause, Max},
  date = {1989},
  journaltitle = {Applied Mathematics Letters},
  shortjournal = {Applied Mathematics Letters},
  volume = {2},
  number = {3},
  pages = {287--291},
  issn = {08939659},
  doi = {10.1016/0893-9659(89)90071-2},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0893965989900712},
  urldate = {2025-12-04},
  abstract = {A brief explanationof perfect hash function search is presented followed by an informal analysis of the problem.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/RA27S5RX/Cercone und Krause - 1989 - An informal analysis of perfect hash function search.pdf}
}

@article{chazelleBloomierFilterEfficient,
  title = {The {{Bloomier Filter}}: {{An Eﬃcient Data Structure}} for {{Static Support Lookup Tables}}},
  author = {Chazelle, Bernard and Kilian, Joe and Rubinfeld, Ronitt and Tal, Ayellet},
  abstract = {We introduce the Bloomier filter, a data structure for compactly encoding a function with static support in order to support approximate evaluation queries. Our construction generalizes the classical Bloom filter, an ingenious hashing scheme heavily used in networks and databases, whose main attribute—space efficiency—is achieved at the expense of a tiny false-positive rate. Whereas Bloom filters can handle only set membership queries, our Bloomier filters can deal with arbitrary functions. We give several designs varying in simplicity and optimality, and we provide lower bounds to prove the (near) optimality of our constructions.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/9C3PU628/Chazelle et al. - The Bloomier Filter An Eﬃcient Data Structure for Static Support Lookup Tables.pdf}
}

@misc{cherneyLinearAlgebra2013,
  title = {Linear {{Algebra}}},
  author = {Cherney, David and Denton, Tom and Thomas, Rohit and Waldron, Andrew},
  date = {2013},
  url = {https://www.math.ucdavis.edu/~linear/linear-guest.pdf},
  urldate = {2025-11-20},
  abstract = {We believe the entire book can be taught in twenty five 50-minute lectures to a sophomore audience that has been exposed to a one year calculus course. Vector calculus is useful, but not necessary preparation for this book, which attempts to be self-contained. Key concepts are presented multiple times, throughout the book, often first in a more intuitive setting, and then again in a definition, theorem, proof style later on. We do not aim for students to become agile mathematical proof writers, but we do expect them to be able to show and explain why key results hold. We also often use the review exercises to let students discover key results for themselves; before they are presented again in detail later in the book.},
  langid = {english},
  organization = {Davis, California},
  keywords = {Mathematics},
  file = {/Users/bernhardgerlach/Zotero/storage/E9JVSKN9/linear-guest.pdf;/Users/bernhardgerlach/Zotero/storage/F4KPUSB3/~linear.html;/Users/bernhardgerlach/Zotero/storage/HKQRRDUJ/188.html}
}

@book{choiIntroductionAnsibleNetwork2023,
  title = {Introduction to {{Ansible Network Automation}}: {{A Practical Primer}}},
  shorttitle = {Introduction to {{Ansible Network Automation}}},
  author = {Choi, Brendan},
  namea = {Medina, Erwin},
  nameatype = {collaborator},
  date = {2023},
  edition = {1st ed},
  publisher = {Apress L. P},
  location = {Berkeley, CA},
  abstract = {Intro -- Table of Contents -- About the Authors -- About the Technical Reviewer -- Acknowledgments -- Introduction -- Part I: The Intros -- Chapter 1: Is Ansible Good for Network Automation? -- 1.1 Laying the Foundation -- 1.2 What Is Ansible? -- 1.3 What Is Ansible Not? -- 1.4 Why Ansible? -- 1.4.1 1000-Foot View of How Ansible Works -- 1.5 Why Does Ansible Matter to You? -- 1.6 Starting on the Right Foot, Learning Ansible Effectively -- 1.6.1 Part 1: Ansible Primer -- 1.6.2 Part 2: Ansible Concepts -- 1.6.3 Part 3: Ansible Practical -- 1.7 Hardware Requirements -- 1.8 Software Requirements -- 1.9 Downloading Source Codes -- 1.10 Summary -- Chapter 2: Shall We Linux? (Part 1: The Linux Command Line) -- 2.1 A Good Reason to Learn Linux -- 2.2 Linux for Ansible and Network Automation -- 2.3 What Is Linux? -- 2.4 Install WSL on Windows 11 to Learn Linux -- 2.5 vi: The Default Text Editor -- 2.6 Practice Linux Commands -- 2.6.1 The Top Ten Essential Linux Commands -- 2.6.2 cat and tac -- 2.6.3 touch -- 2.6.4 mkdir and rmdir -- 2.6.5 cp and rm -- 2.6.6 rename and mv -- 2.6.7 head, tail, and shuf -- 2.6.8 less and more -- 2.6.9 ls and dir -- 2.6.10 sort -- 2.6.11 tee and nl -- 2.6.12 grep -- 2.7 Summary -- Chapter 3: Shall We Linux? (Part 2) -- 3.1 Linux Directory -- 3.2 Getting to Know Your Linux Better -- 3.3 Getting Familiar with Linux Processes -- 3.4 Getting to Know Disk Space in Linux -- 3.5 Getting Started with Linux User Management -- 3.6 Controlling Access to Files and Directories in Linux -- 3.7 Working with Zip Files in Linux -- 3.8 Downloading Files from the Internet in Linux -- 3.9 Linux Network Utilities for Troubleshooting -- 3.10 Keeping Your Linux System Up to Date -- 3.11 Jack, the Jack Russell: A Regular Expression Quiz -- 3.12 Summary -- Chapter 4: Setting Up an Ansible Learning Environment},
  isbn = {978-1-4842-9623-3 978-1-4842-9624-0},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/P6GF5KMF/Choi - 2023 - Introduction to Ansible Network Automation A Practical Primer.epub}
}

@book{chouMasteringPythonNetworking2020,
  title = {Mastering {{Python}} Networking: Your One-Stop Solution to Using {{Python}} for Network Automation, Programmability, and {{DevOps}}, {{Third}} Edition},
  shorttitle = {Mastering {{Python}} Networking},
  author = {Chou, Eric},
  date = {2020},
  edition = {3rd ed},
  publisher = {Packt Publishing},
  location = {Place of publication not identified},
  abstract = {New edition of the bestselling guide to mastering Python Networking, updated to Python 3 and including the latest on network data analysis, Cloud Networking, Ansible 2.8, and new libraries Key Features Explore the power of Python libraries to tackle difficult network problems efficiently and effectively, including pyATS, Nornir, and Ansible 2.8 Use Python and Ansible for DevOps, network device automation, DevOps, and software-defined networking Become an expert in implementing advanced network-related tasks with Python 3 Book Description Networks in your infrastructure set the foundation for how your application can be deployed, maintained, and serviced. Python is the ideal language for network engineers to explore tools that were previously available to systems engineers and application developers. In Mastering Python Networking, Third edition, you'll embark on a Python-based journey to transition from traditional network engineers to network developers ready for the next-generation of networks. This new edition is completely revised and updated to work with Python 3. In addition to new chapters on network data analysis with ELK stack (Elasticsearch, Logstash, Kibana, and Beats) and Azure Cloud Networking, it includes updates on using newer libraries such as pyATS and Nornir, as well as Ansible 2.8. Each chapter is updated with the latest libraries with working examples to ensure compatibility and understanding of the concepts. Starting with a basic overview of Python, the book teaches you how it can interact with both legacy and API-enabled network devices. You will learn to leverage high-level Python packages and frameworks to perform network automation tasks, monitoring, management, and enhanced network security followed by Azure and AWS Cloud networking. Finally, you will use Jenkins for continuous integration as well as testing tools to verify your network. What you will learn Use Python libraries to interact with your network Integrate Ansible 2.8 using Python to control Cisco, Juniper, and Arista network devices Leverage existing Flask web frameworks to construct high-level APIs Learn how to build virtual networks in the AWS \& Azure Cloud Learn how to use Elastic Stack for network data analysis Understand how Jenkins can be used to automatically deploy changes in your network Use PyTest and Unittest for Test-Driven Network Development in networking engineering with Python Who this book is for Mastering Python Networking, Third edition is for network engineers, developers, and SREs who want to use Python for network automation, programmability, and data analysis. Basic familiarity with Python programming and networking-related concepts such as Transmission Control Protocol/Internet Protocol (TCP/IP) will be useful},
  isbn = {978-1-83921-467-7 978-1-83921-867-5},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/QKTLXWCM/Chou - 2020 - Mastering Python networking your one-stop solution to using Python for network automation, programm.pdf}
}

@article{cichelliMinimalPerfectHash1980,
  title = {Minimal Perfect Hash Functions Made Simple},
  author = {Cichelli, Richard J.},
  date = {1980-01},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {23},
  number = {1},
  pages = {17--19},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/358808.358813},
  url = {https://dl.acm.org/doi/10.1145/358808.358813},
  urldate = {2025-12-04},
  abstract = {A method is presented for Computing machine independent, minimal perfect hash functions of the form: hash value {$<$}-- key length + the associated value of the key's first character + the associated value of the key's last character. Such functions allow single probe retrieval from minimally sized tables of identifier lists. Application areas include table lookup for reserved words in compilers and filtering high frequency words in natural language processing. Functions for Pascal's reserved words, Pascal's predefined identifiers, frequently occurring English words, and month abbreviations are presented as examples.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/5M552H5E/Cichelli - 1980 - Minimal perfect hash functions made simple.pdf}
}

@book{clintonCompleteObsoleteGuide2024,
  title = {The Complete Obsolete Guide to Generative {{AI}}},
  author = {Clinton, David},
  date = {2024},
  publisher = {Manning},
  location = {Shelter Island},
  isbn = {978-1-63343-698-5},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/6LT8FLRZ/Clinton - 2024 - The complete obsolete guide to generative AI.pdf}
}

@article{coddRelationalModelData,
  title = {A {{Relational Model}} of {{Data}} for {{Large Shared Data Banks}}},
  author = {Codd, E F},
  abstract = {Future users of large data banks must be protected from having to know how the data is organized in the machine (the internal representation). A prompting service which supplies such information is not a satisfactory solution. Activities of users at terminals and most application programs should remain unaffected when the internal representation of data is changed and even when some aspects of the external representation are changed. Changes in data representation will often be needed as a result of changes in query, update, and report traffic and natural growth in the types of stored information. Existing noninferential, formatted data systems provide users with tree-structured files or slightly more general network models of the data. In Section 1, inadequacies of these models are discussed. A model based on n-ary relations, a normal form for data base relations, and the concept of a universal data sublanguage are introduced. In Section 2, certain operations on relations (other than logical inference) are discussed and applied to the problems of redundancy and consistency in the user’s model.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/K6SZC4DH/Codd - A Relational Model of Data for Large Shared Data Banks.pdf}
}

@book{cohenIntroductionComputerTheory1986,
  title = {Introduction to Computer Theory},
  author = {Cohen, Daniel I. A.},
  date = {1986},
  series = {Wiley International Edition},
  publisher = {Wiley},
  location = {New York},
  isbn = {978-0-471-80271-6 978-0-471-84316-0},
  langid = {english},
  pagetotal = {823},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/GJGHYA5H/Cohen - 1986 - Introduction to computer theory.pdf}
}

@article{colbournPerfectHashFamilies,
  title = {Perfect {{Hash Families}} in {{Polynomial Time}}},
  author = {Colbourn, Charles J},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/P2LG44DU/Colbourn - Perfect Hash Families in Polynomial Time.pdf}
}

@inproceedings{cottamAbstractRenderingOutofcore2013,
  title = {Abstract Rendering: Out-of-Core Rendering for Information Visualization},
  shorttitle = {Abstract Rendering},
  author = {Cottam, Joseph A. and Lumsdaine, Andrew and Wang, Peter},
  editor = {Wong, Pak Chung and Kao, David L. and Hao, Ming C. and Chen, Chaomei},
  date = {2013-12-23},
  pages = {90170K},
  location = {San Francisco, California, USA},
  doi = {10.1117/12.2041200},
  url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2041200},
  urldate = {2025-12-07},
  abstract = {As visualization is applied to larger data sets residing in more diverse hardware environments, visualization frameworks need to adapt. Rendering techniques are currently a major limiter since they tend to be built around central processing with all of the geometric data present. This is not a fundamental requirement of information visualization. This paper presents Abstract Rendering (AR), a technique for eliminating the centralization requirement while preserving some forms of interactivity. AR is based on the observation that pixels are fundamentally bins, and that rendering is essentially a binning process on a lattice of bins. By providing a more flexible binning process, the majority of rendering can be done with the geometric information stored out-of-core. Only the bin representations need to reside in memory. This approach enables: (1) rendering on large datasets without requiring large amounts of working memory, (2) novel and useful control over image composition, (3) a direct means of distributing the rendering task across processes, and (4) high-performance interaction techniques on large datasets. This paper introduces AR in a theoretical context, provides an overview of an implementation, and discusses how it has been applied to large-scale data visualization problems.},
  eventtitle = {{{IS}}\&{{T}}/{{SPIE Electronic Imaging}}},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/HYV64XPR/Cottam et al. - 2013 - Abstract rendering out-of-core rendering for information visualization.pdf}
}

@book{crockerAIpoweredDeveloperBuild2024,
  title = {{{AI-powered}} Developer: Build Software with {{ChatGPT}} and {{Copilot}}},
  shorttitle = {{{AI-powered}} Developer},
  author = {Crocker, Nathan B.},
  date = {2024},
  publisher = {Manning},
  location = {Shelter Island},
  isbn = {978-1-63343-761-6},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/HEL6HH37/Crocker - 2024 - AI-powered developer build software with ChatGPT and Copilot.pdf}
}

@online{deepseek-aiDeepSeekLLMScaling2024,
  title = {{{DeepSeek LLM}}: {{Scaling Open-Source Language Models}} with {{Longtermism}}},
  shorttitle = {{{DeepSeek LLM}}},
  author = {DeepSeek-AI and Bi, Xiao and Chen, Deli and Chen, Guanting and Chen, Shanhuang and Dai, Damai and Deng, Chengqi and Ding, Honghui and Dong, Kai and Du, Qiushi and Fu, Zhe and Gao, Huazuo and Gao, Kaige and Gao, Wenjun and Ge, Ruiqi and Guan, Kang and Guo, Daya and Guo, Jianzhong and Hao, Guangbo and Hao, Zhewen and He, Ying and Hu, Wenjie and Huang, Panpan and Li, Erhang and Li, Guowei and Li, Jiashi and Li, Yao and Li, Y. K. and Liang, Wenfeng and Lin, Fangyun and Liu, A. X. and Liu, Bo and Liu, Wen and Liu, Xiaodong and Liu, Xin and Liu, Yiyuan and Lu, Haoyu and Lu, Shanghao and Luo, Fuli and Ma, Shirong and Nie, Xiaotao and Pei, Tian and Piao, Yishi and Qiu, Junjie and Qu, Hui and Ren, Tongzheng and Ren, Zehui and Ruan, Chong and Sha, Zhangli and Shao, Zhihong and Song, Junxiao and Su, Xuecheng and Sun, Jingxiang and Sun, Yaofeng and Tang, Minghui and Wang, Bingxuan and Wang, Peiyi and Wang, Shiyu and Wang, Yaohui and Wang, Yongji and Wu, Tong and Wu, Y. and Xie, Xin and Xie, Zhenda and Xie, Ziwei and Xiong, Yiliang and Xu, Hanwei and Xu, R. X. and Xu, Yanhong and Yang, Dejian and You, Yuxiang and Yu, Shuiping and Yu, Xingkai and Zhang, B. and Zhang, Haowei and Zhang, Lecong and Zhang, Liyue and Zhang, Mingchuan and Zhang, Minghua and Zhang, Wentao and Zhang, Yichao and Zhao, Chenggang and Zhao, Yao and Zhou, Shangyan and Zhou, Shunfeng and Zhu, Qihao and Zou, Yuheng},
  date = {2024-01-05},
  eprint = {2401.02954},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.02954},
  url = {http://arxiv.org/abs/2401.02954},
  urldate = {2025-12-07},
  abstract = {The rapid development of open-source large language models (LLMs) has been truly remarkable. However, the scaling laws described in previous literature presents varying conclusions, which casts a dark cloud over scaling LLMs. We delve into the study of scaling laws and present our distinctive findings that facilitate the scaling of large scale models in two prevalent used opensource configurations, 7B and 67B. Guided by the scaling laws, we introduce DeepSeek LLM, a project dedicated to advancing open-source language models with a long-term perspective. To support the pre-training phase, we have developed a dataset that currently consists of 2 trillion tokens and is continuously expanding. We further conduct supervised fine-tuning (SFT) and direct preference optimization (DPO) on DeepSeek LLM Base models, resulting in the creation of DeepSeek Chat models. Our evaluation results demonstrate that DeepSeek LLM 67B surpasses LLaMA-2 70B across a range of benchmarks, especially in the domains of code, mathematics, and reasoning. Furthermore, open-ended evaluations reveal that our DeepSeek LLM 67B Chat exhibits superior performance compared to GPT-3.5.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/XYCBC8CK/DeepSeek-AI et al. - 2024 - DeepSeek LLM Scaling Open-Source Language Models with Longtermism.pdf}
}

@book{dennisyurichevMathematicsProgramming2025,
  title = {Mathematics ⋂ Programming},
  author = {{Dennis Yurichev}},
  date = {2025-10-21},
  publisher = {self published},
  url = {https://αβγ.ελ/math-prog.pdf},
  langid = {english},
  pagetotal = {195},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/6GCAIRZ8/Dennis Yurichev - 2025 - Mathematics ⋂ programming.pdf}
}

@book{dennisyurichevReverseEngineeringBeginners2018,
  title = {Reverse {{Engineering}} for {{Beginners}} ({{Understanding Assembly Language}})},
  author = {{Dennis Yurichev}},
  date = {2018-08-12},
  publisher = {Self Published},
  url = {https://repository.root-me.org/Reverse%20Engineering/EN%20-%20Reverse%20Engineering%20for%20Beginners%20-%20Dennis%20Yurichev.pdf},
  urldate = {2025-12-07},
  langid = {english},
  pagetotal = {1083},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/ZFE8XPHD/Dennis Yurichev - 2018 - Reverse Engineering for Beginners (Understanding Assembly Language).pdf}
}

@book{dhamaniIntroductionGenerativeAI2024,
  title = {Introduction to Generative {{AI}}},
  author = {Dhamani, Numa and Engler, Maggie and Massachi, Sahar},
  date = {2024},
  publisher = {Manning Publications Co},
  location = {Shelter Island, NY},
  abstract = {Introduction to Generative AI guides you through benefits, risks, and limitations of Generative AI technology. You'll discover how AI models learn and think, explore best practices for creating text and graphics, and consider the impact of AI on society, the economy, and the law. Along the way, you'll practice strategies for getting accurate responses and even understand how to handle misuse and security threats},
  isbn = {978-1-63343-719-7 978-1-63835-434-5},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/EX46DSAA/Dhamani et al. - 2024 - Introduction to generative AI.pdf}
}

@article{dietzfelbingerReliableRandomizedAlgorithm1997,
  title = {A {{Reliable Randomized Algorithm}} for the {{Closest-Pair Problem}}},
  author = {Dietzfelbinger, Martin and Hagerup, Torben and Katajainen, Jyrki and Penttonen, Martti},
  date = {1997-10},
  journaltitle = {Journal of Algorithms},
  shortjournal = {Journal of Algorithms},
  volume = {25},
  number = {1},
  pages = {19--51},
  issn = {01966774},
  doi = {10.1006/jagm.1997.0873},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0196677497908737},
  urldate = {2025-12-05},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/RW7E35GP/Dietzfelbinger et al. - 1997 - A Reliable Randomized Algorithm for the Closest-Pair Problem.pdf}
}

@book{downeyModelingSimulationPython2023,
  title = {Modeling and {{Simulation}} in {{Python}}: {{An Introduction}} for {{Scientists}} and {{Engineers}}},
  shorttitle = {Modeling and {{Simulation}} in {{Python}}},
  author = {Downey, Allen B.},
  date = {2023},
  publisher = {No Starch Press},
  location = {New York},
  isbn = {978-1-7185-0216-1 978-1-7185-0217-8},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/CSZ7KAUA/Modelling and Simulation with Python OReilly_2.3.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/DTDTT6TB/Downey - 2023 - Modeling and Simulation in Python An Introduction for Scientists and Engineers.pdf}
}

@book{downeyThinkBayes2016,
  title = {Think {{Bayes}}},
  author = {Downey, Allen B.},
  date = {2016},
  series = {Bayesian Statistics in {{Python}}},
  edition = {fourth, [revised] release},
  publisher = {O'Reilly},
  location = {Beijing Köln},
  abstract = {Bayes's theorem -- Computational statistics -- Estimation -- More estimation -- Odds and addends -- Decision analysis -- Prediction -- Observer bias -- Two dimensions -- Approximate Bayesian computation -- Hypothesis testing -- Evidence -- Simulation -- A hierarchical model -- Dealing with dimensions},
  isbn = {978-1-4493-7078-7},
  langid = {english},
  pagetotal = {194},
  file = {/Users/bernhardgerlach/Zotero/storage/7QXAXT8C/Downey - 2013 - Think Bayes.pdf}
}

@book{downeyThinkStatsExploratory2015,
  title = {Think {{Stats}}: Exploratory Data Analysis},
  shorttitle = {Think {{Stats}}},
  author = {Downey, Allen B.},
  date = {2015},
  edition = {2. ed},
  publisher = {O'Reilly},
  location = {Beijing Köln},
  isbn = {978-1-4919-0733-7},
  langid = {english},
  pagetotal = {206},
  file = {/Users/bernhardgerlach/Zotero/storage/3K6Q3D5A/Downey - 2015 - Think Stats.pdf}
}

@article{ebertVERSATILEDATASTRUCTURE,
  title = {A {{VERSATILE DATA STRUCTURE FOR EDGE-ORIENTEDGRAPH Al}}.{{GORlTHMS}}},
  author = {Ebert, JiiRGEN},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/CTFKUHIM/Ebert - A VERSATILE DATA STRUCTURE FOR EDGE-ORIENTEDGRAPH Al.GORlTHMS.pdf}
}

@article{ebertVERSATILEDATASTRUCTUREa,
  title = {A {{VERSATILE DATA STRUCTURE FOR EDGE-ORIENTEDGRAPH Al}}.{{GORlTHMS}}},
  author = {Ebert, JiiRGEN},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/DL9LPZPI/Ebert - A VERSATILE DATA STRUCTURE FOR EDGE-ORIENTEDGRAPH Al.GORlTHMS.pdf}
}

@book{elgerAIServiceServerless2020,
  title = {{{AI}} as a Service: Serverless Machine Learning with {{AWS}}},
  shorttitle = {{{AI}} as a Service},
  author = {Elger, Peter and Shanaghy, Eóin},
  date = {2020},
  publisher = {Manning Publications Co. LLC},
  location = {New York},
  abstract = {Intro -- AI as a Service -- Copyright -- dedication -- contents -- front matter -- foreword -- preface -- acknowledgments -- about this book -- Who should read this book -- How this book is organized: a roadmap -- About the code -- liveBook discussion forum -- about the authors -- about the cover illustration -- Part 1. First steps -- 1 A tale of two technologies -- 1.1 Cloud landscape -- 1.2 What is Serverless? -- 1.3 The need for speed -- 1.3.1 The early days -- 1.3.2 The Unix philosophy -- 1.3.3 Object orientation and patterns -- 1.3.4 Java, J2EE, .NET, -- 1.3.5 XML and SOAXML (Extensible Markup Language)SOA (service-oriented architecture) -- 1.3.6 Web speed -- 1.3.7 Cloud computing -- 1.3.8 Microservices (rediscovery) -- 1.3.9 Cloud native services -- 1.3.10 The trend: speed -- 1.4 What is AI? -- 1.4.1 History of AI -- 1.4.2 Real world AI -- 1.4.3 AI services -- 1.4.4 AI and machine learning -- 1.4.5 Deep learning -- 1.4.6 AI challenges -- 1.5 The democratization of compute power and artificial intelligence -- 1.6 Canonical AI as a Service architecture -- 1.6.1 Web application -- 1.6.2 Realtime services -- 1.6.3 Batch services -- 1.6.4 Communication services -- 1.6.5 Utility services -- 1.6.6 AI services -- 1.6.7 Data services -- 1.6.8 Operational support -- 1.6.9 Development support -- 1.6.10 Off-platform -- 1.7 Realization on Amazon Web Services -- 1.8 Summary -- 2 Building a serverless image recognition system, part 1 -- 2.1 Our first system -- 2.2 Architecture -- 2.2.1 Web application -- 2.2.2 Synchronous services -- 2.2.3 Asynchronous services -- 2.2.4 Communication services -- 2.2.5 AI services -- 2.2.6 Data services -- 2.2.7 Development support and operational support -- 2.3 Getting ready -- 2.3.1 DNS domain and SSL/TLS certificate -- 2.3.2 Setup checklist -- 2.3.3 Get the code -- 2.3.4 Setting up cloud resources},
  isbn = {978-1-61729-615-4 978-1-63835-043-9},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/TFTFPU8C/Elger und Shanaghy - 2020 - AI as a service serverless machine learning with AWS.pdf}
}

@online{elsayedAdversarialReprogrammingNeural2018,
  title = {Adversarial {{Reprogramming}} of {{Neural Networks}}},
  author = {Elsayed, Gamaleldin F. and Goodfellow, Ian and Sohl-Dickstein, Jascha},
  date = {2018-11-29},
  eprint = {1806.11146},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1806.11146},
  url = {http://arxiv.org/abs/1806.11146},
  urldate = {2025-12-07},
  abstract = {Deep neural networks are susceptible to adversarial attacks. In computer vision, well-crafted perturbations to images can cause neural networks to make mistakes such as confusing a cat with a computer. Previous adversarial attacks have been designed to degrade performance of models or cause machine learning models to produce specific outputs chosen ahead of time by the attacker. We introduce attacks that instead reprogram the target model to perform a task chosen by the attacker—without the attacker needing to specify or compute the desired output for each test-time input. This attack finds a single adversarial perturbation, that can be added to all test-time inputs to a machine learning model in order to cause the model to perform a task chosen by the adversary—even if the model was not trained to do this task. These perturbations can thus be considered a program for the new task. We demonstrate adversarial reprogramming on six ImageNet classification models, repurposing these models to perform a counting task, as well as classification tasks: classification of MNIST and CIFAR-10 examples presented as inputs to the ImageNet model.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/Q9WR82VN/Elsayed et al. - 2018 - Adversarial Reprogramming of Neural Networks.pdf}
}

@online{espositoRecSplitMinimalPerfect2019,
  title = {{{RecSplit}}: {{Minimal Perfect Hashing}} via {{Recursive Splitting}}},
  shorttitle = {{{RecSplit}}},
  author = {Esposito, Emmanuel and Graf, Thomas Mueller and Vigna, Sebastiano},
  date = {2019-11-30},
  eprint = {1910.06416},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1910.06416},
  url = {http://arxiv.org/abs/1910.06416},
  urldate = {2025-12-04},
  abstract = {A minimal perfect hash function bijectively maps a key set 푆 out of a universe 푈 into the first 푆 natural numbers. Minimal perfect hash functions are used, for example, to map irregularly-shaped keys, such as strings, in a compact space so that metadata can then be simply stored in an array. While it is known that just 1.44 bits per key are necessary to store a minimal perfect hash function, no published technique can go below 2 bits per key in practice. We propose a new technique for storing minimal perfect hash functions with expected linear construction time and expected constant lookup time that makes it possible to build for the first time, for example, structures which need 1.56 bits per key, that is, within 8.3\% of the lower bound, in less than 2 ms per key. We show that instances of our construction are able to simultaneously beat the construction time, space usage and lookup time of the state-of-the-art data structure reaching 2 bits per key. Moreover, we provide parameter choices giving structures which are competitive with alternative, larger-size data structures in terms of space and lookup time. The construction of our data structures can be easily parallelized or mapped on distributed computational units (e.g., within the MapReduce framework), and structures larger than the available RAM can be directly built in mass storage.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Data Structures and Algorithms},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/PVFYCAS5/Esposito et al. - 2019 - RecSplit Minimal Perfect Hashing via Recursive Splitting.pdf}
}

@book{fabiangiessenTripGraphicsProcessing2011,
  title = {A Trip through the Graphics Processing Pipeline},
  author = {{Fabian Giessen}},
  date = {2011-07},
  url = {https://fgiesen.wordpress.com/2011/07/09/a-trip-through-the-graphics-pipeline-2011-index/},
  pagetotal = {87},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/VJ4PLQWM/A Trip Through The Graphics Pipeline - All Huge (2011).pdf}
}

@book{farrisHowLargeLanguage2025,
  title = {How Large Language Models Work},
  author = {Farris, Drew and Biderman, Stella and Raff, Edward},
  date = {2025},
  edition = {First edition},
  publisher = {Manning Publications},
  location = {Shelter Island, New York},
  abstract = {Learn how large language models like GPT and Gemini work under the hood in plain English. How Large Language Models Work translates years of expert research on Large Language Models into a readable, focused introduction to working with these amazing systems. It explains clearly how LLMs function, introduces the optimization techniques to fine-tune them, and shows how to create pipelines and processes to ensure your AI applications are efficient and error-free. In How Large Language Models Work you will learn how to: Test and evaluate LLMs Use human feedback, supervised fine-tuning, and Retrieval Augmented Generation (RAG) Reducing the risk of bad outputs, high-stakes errors, and automation bias Human-computer interaction systems Combine LLMs with traditional ML How Large Language Models Work is authored by top machine learning researchers at Booz Allen Hamilton, including researcher Stella Biderman, Director of AI/ML Research Drew Farris, and Director of Emerging AI Edward Raff. They lay out how LLM and GPT technology works in plain language that's accessible and engaging for all. About the Technology Large Language Models put the "I" in "AI." By connecting words, concepts, and patterns from billions of documents, LLMs are able to generate the human-like responses we've come to expect from tools like ChatGPT, Claude, and Deep-Seek. In this informative and entertaining book, the world's best machine learning researchers from Booz Allen Hamilton explore foundational concepts of LLMs, their opportunities and limitations, and the best practices for incorporating AI into your organizations and applications. About the Book How Large Language Models Work takes you inside an LLM, showing step-by-step how a natural language prompt becomes a clear, readable text completion. Written in plain language, you'll learn how LLMs are created, why they make errors, and how you can design reliable AI solutions. Along the way, you'll learn how LLMs "think," how to design LLM-powered applications like agents and Q\&A systems, and how to navigate the ethical, legal, and security issues. What's Inside Customize LLMs for specific applications Reduce the risk of bad outputs and bias Dispel myths about LLMs Go beyond language processing About the Reader No knowledge of ML or AI systems is required. About the Authors Edward Raff, Drew Farris and Stella Biderman are the Director of Emerging AI, Director of AI/ML Research, and machine learning researcher at Booz Allen Hamilton. Quotes Essential reading if you want to understand how LLMs really work. - Janelle Shane, aiweirdness.com Demystifies technology revolutionizing human-machine interaction. - Sudharshan Tumkunta, Meta An excellent no-nonsense introduction to LLMs. - Kartik Dutta, Cisco Strikes the perfect balance between depth and clarity, making it an invaluable resource for both researchers and practitioners. - Mattia Zoccarato, Chiron AI},
  isbn = {978-1-63343-708-1},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/FDAEQRCV/Farris et al. - 2025 - How large language models work.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/TSG3RGGE/How_Large_Language_Models_Work.pdf}
}

@book{fischerMaschinellesLernenFuer2024,
  title = {Maschinelles Lernen für dummies},
  author = {Fischer, Jörn},
  namea = {Eckert, Kai and Wolf, Ivo},
  nameatype = {collaborator},
  date = {2024},
  series = {Für Dummies Series},
  publisher = {John Wiley \& Sons, Incorporated},
  location = {Newark},
  isbn = {978-3-527-72055-2 978-3-527-84184-4},
  langid = {german},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/Zotero/storage/GBTZA2N8/Fischer - 2024 - Maschinelles Lernen für dummies.pdf}
}

@misc{fischerVorlesungGrundlagenNeuronale2024,
  title = {Vorlesung Grundlagen Neuronale Netze},
  author = {Fischer, Prof. Dr. Jörn},
  date = {2024},
  url = {https://services.informatik.hs-mannheim.de/~fischer/lectures/GNN_Files/GNN.pdf},
  urldate = {2025-11-26},
  langid = {ngerman},
  file = {/Users/bernhardgerlach/Zotero/storage/DWX4FG59/Fischer - Vorlesung Grundlagen Neuronale Netze.pdf}
}

@article{fleuretLittleBookDeep,
  title = {The {{Little Book}} of {{Deep Learning}}},
  author = {Fleuret, François},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/ZLY4JY3B/Fleuret - The Little Book of Deep Learning.pdf}
}

@article{fogOptimizingSubroutinesAssembly,
  title = {Optimizing Subroutines in Assembly Language},
  author = {Fog, Agner},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/L9UJU4D2/Fog - Optimizing subroutines in assembly language.pdf}
}

@article{fogVCLVectorClass,
  title = {{{VCL C}}++ Vector Class Library Manual},
  author = {Fog, Agner},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/RVJLMWDL/Fog - VCL C++ vector class library manual.pdf}
}

@inproceedings{fredmanStoringSparseTable1982,
  title = {Storing a Sparse Table with {{O}}(1) Worst Case Access Time},
  booktitle = {23rd {{Annual Symposium}} on {{Foundations}} of {{Computer Science}} (Sfcs 1982)},
  author = {Fredman, Michael L. and Komlos, Janos and Szemeredi, Endre},
  date = {1982-11},
  pages = {165--169},
  publisher = {IEEE},
  location = {Chicago, IL, USA},
  doi = {10.1109/SFCS.1982.39},
  url = {https://ieeexplore.ieee.org/document/4568389/},
  urldate = {2025-12-04},
  abstract = {A data structurefor representinga set of n items from a umverseof m items,whichusesspace n + o(n) and accommodatesmembershipqueriesm constant time is described.Boththe data structure and the query algorithmare easyto \textasciitilde mplement.},
  eventtitle = {23rd {{Annual Symposium}} on {{Foundations}} of {{Computer Science}}},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/NZCHG7RQ/Fredman et al. - 1982 - Storing a sparse table with O(1) worst case access time.pdf}
}

@book{freedEffectiveConversationalAI2025,
  title = {Effective Conversational {{AI}}: Chatbots That Work},
  shorttitle = {Effective Conversational {{AI}}},
  author = {Freed, Andrew and Jacobs, Cari and Rozsa, Eniko},
  namea = {Mantas, Jesús},
  nameatype = {collaborator},
  date = {2025},
  edition = {First edition},
  publisher = {Manning Publications},
  location = {Shelter Island, NY},
  abstract = {Create and improve conversational AI with the latest patterns, best practices, and tools, including generative AI models. Conversational AI (CAI) tools are built to solve problems, but all-too-often they just end up causing pain for users-and developers! Effective Conversational AI reveals best practices and industry-tested techniques for creating chatbots and conversational AI tools that are reliable at an enterprise scale. With the tested ideas and examples in this book, you'll learn to build chatbots that your customers and colleagues will actually want to use! In Effective Conversational AI you'll learn how to: Create high-quality chatbots and other conversational AI experiences Plan for continuous improvement Incorporate generative AI solutions to improve quality, accuracy, and usability Evaluate user experience and business results Effective Conversational AI introduces continuous improvement practices that are vital for the constant betterment and evolution of chatbots and CAI tools. It introduces the three most-common forms of chatbot--Q\&A, process-oriented, and routing agents--and presents a reliable framework for continuously improving each one. Using modern generative AI and tried-and-tested classic approaches, you'll learn to deliver high performance chatbots that can guide a customer through complex end-to-end tasks--no human required! About the Technology Powerful new chatbot frameworks and Generative AI models can practically eliminate problems like misinterpreting user intent and delivering nonsensical answers. In this book, you'll learn how to build chatbots that take advantage of large language models and other modern tools and create conversational AI experiences users will love. About the Book Effective Conversational AI teaches you how to build great chatbots that perform reliably even at enterprise scale. In it, you'll learn how to clarify user intent using LLMs, respond accurately to unanticipated input, and use Retrieval Augmented Generation to keep responses up to date. Along the way, you'll discover how to establish a feedback loop for continuous quality improvement and master techniques to integrate GenAI safely into conventional chatbot designs. What's Inside Blend Generative AI and conventional chatbot tools Use LLMs to improve quality, accuracy, and usability Plan for continuous improvement Domain-specific responses using RAG About the Reader For developers, engineers, and product managers working with conversational AI. About the Authors Andrew Freed, Cari Jacobs, and Enik¿₁ R©đzsa are seasoned conversational AI developers with IBM. Quotes A wonderful comprehensive guide written by individuals who have walked the AI conversational implementation journey into production. - Sara Hines, AI innovation pioneer Cuts through the hype and focuses on what really matters. - Jerry Cuomo, IBM A blueprint for building and measuring effective conversational AI systems. - Corville Allen, Google An invaluable resource for anyone looking to drive success with AI-driven conversations. - Marc Nehme, Microsoft},
  isbn = {978-1-63343-640-4},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/IEHXZC4C/Freed et al. - 2025 - Effective conversational AI chatbots that work.pdf}
}

@book{frenzelFreisprechenGestoerterUmgebung1992,
  title = {Freisprechen in gestörter Umgebung: 4 Tabellen},
  shorttitle = {Freisprechen in gestörter Umgebung},
  author = {Frenzel, Rudi},
  date = {1992},
  series = {Fortschrittberichte VDI Reihe 10, Informatik, Kommunikationstechnik},
  edition = {Als Ms. gedr},
  number = {228},
  publisher = {VDI-Verl},
  location = {Düsseldorf},
  isbn = {978-3-18-142810-8},
  langid = {german},
  pagetotal = {147},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/SGYEMWUA/Frenzel - 1992 - Freisprechen in gestörter Umgebung 4 Tabellen.pdf}
}

@book{fuhrerScientificComputingPython2021,
  title = {Scientific Computing with {{Python}}: High-Performance Scientific Computing with {{NumPy}}, {{SciPy}}, and Pandas, Second Edition},
  shorttitle = {Scientific Computing with {{Python}}},
  author = {Führer, Claus and Solem, Jan Erik and Verdier, Olivier},
  date = {2021},
  edition = {2nd ed},
  publisher = {Packt Publishing},
  location = {Place of publication not identified},
  abstract = {Leverage this example-packed, comprehensive guide for all your Python computational needs Key Features Learn the first steps within Python to highly specialized concepts Explore examples and code snippets taken from typical programming situations within scientific computing. Delve into essential computer science concepts like iterating, object-oriented programming, testing, and MPI presented in strong connection to applications within scientific computing. Book Description Python has tremendous potential within the scientific computing domain. This updated edition of Scientific Computing with Python features new chapters on graphical user interfaces, efficient data processing, and parallel computing to help you perform mathematical and scientific computing efficiently using Python. This book will help you to explore new Python syntax features and create different models using scientific computing principles. The book presents Python alongside mathematical applications and demonstrates how to apply Python concepts in computing with the help of examples involving Python 3.8. You'll use pandas for basic data analysis to understand the modern needs of scientific computing, and cover data module improvements and built-in features. You'll also explore numerical computation modules such as NumPy and SciPy, which enable fast access to highly efficient numerical algorithms. By learning to use the plotting module Matplotlib, you will be able to represent your computational results in talks and publications. A special chapter is devoted to SymPy, a tool for bridging symbolic and numerical computations. By the end of this Python book, you'll have gained a solid understanding of task automation and how to implement and test mathematical algorithms within the realm of scientific computing. What you will learn Understand the building blocks of computational mathematics, linear algebra, and related Python objects Use Matplotlib to create high-quality figures and graphics to draw and visualize results Apply object-oriented programming (OOP) to scientific computing in Python Discover how to use pandas to enter the world of data processing Handle exceptions for writing reliable and usable code Cover manual and automatic aspects of testing for scientific programming Get to grips with parallel computing to increase computation speed Who this book is for This book is for students with a mathematical background, university teachers designing modern courses in progra},
  isbn = {978-1-83882-232-3 978-1-83882-510-2},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/3WJD689T/Führer et al. - 2021 - Scientific computing with Python high-performance scientific computing with NumPy, SciPy, and panda.pdf}
}

@article{gageNewAlgorithmData,
  title = {A {{New Algorithm}} for {{Data Compression}}},
  author = {Gage, Philip},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/WPHI2246/Gage - A New Algorithm for Data Compression.pdf}
}

@article{gallierAlgebraTopologyDifferential,
  title = {Algebra, {{Topology}}, {{Diﬀerential Calculus}}, and {{Optimization Theory For Computer Science}} and {{Machine Learning}}},
  author = {Gallier, Jean and Quaintance, Jocelyn},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/N5SSNVBD/Gallier und Quaintance - Algebra, Topology, Diﬀerential Calculus, and Optimization Theory For Computer Science and Machine Le.pdf}
}

@article{gelmanBayesianDataAnalysis,
  title = {Bayesian {{Data Analysis Third}} Edition (with Errors Fixed as of 13 {{February}} 2020)},
  author = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/MEZJBIJ4/Gelman et al. - Bayesian Data Analysis Third edition (with errors ﬁxed as of 13 February 2020).pdf}
}

@online{genuzioFastScalableConstruction2016,
  title = {Fast {{Scalable Construction}} of ({{Minimal Perfect Hash}}) {{Functions}}},
  author = {Genuzio, Marco and Ottaviano, Giuseppe and Vigna, Sebastiano},
  date = {2016-03-22},
  eprint = {1603.04330},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1603.04330},
  url = {http://arxiv.org/abs/1603.04330},
  urldate = {2025-12-04},
  abstract = {Recent advances in random linear systems on finite fields have paved the way for the construction of constant-time data structures representing static functions and minimal perfect hash functions using less space with respect to existing techniques. The main obstruction for any practical application of these results is the cubic-time Gaussian elimination required to solve these linear systems: despite they can be made very small, the computation is still too slow to be feasible. In this paper we describe in detail a number of heuristics and programming techniques to speed up the resolution of these systems by several orders of magnitude, making the overall construction competitive with the standard and widely used MWHC technique, which is based on hypergraph peeling. In particular, we introduce broadword programming techniques for fast equation manipulation and a lazy Gaussian elimination algorithm. We also describe a number of technical improvements to the data structure which further reduce space usage and improve lookup speed. Our implementation of these techniques yields a minimal perfect hash function data structure occupying 2.24 bits per element, compared to 2.68 for MWHC-based ones, and a static function data structure which reduces the multiplicative overhead from 1.23 to 1.03.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Data Structures and Algorithms},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/DDZFAV86/Genuzio et al. - 2016 - Fast Scalable Construction of (Minimal Perfect Hash) Functions.pdf}
}

@incollection{genuzioFastScalableConstruction2016a,
  title = {Fast {{Scalable Construction}} of ({{Minimal Perfect Hash}}) {{Functions}}},
  booktitle = {Experimental {{Algorithms}}},
  author = {Genuzio, Marco and Ottaviano, Giuseppe and Vigna, Sebastiano},
  editor = {Goldberg, Andrew V. and Kulikov, Alexander S.},
  date = {2016},
  volume = {9685},
  pages = {339--352},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-38851-9_23},
  url = {http://link.springer.com/10.1007/978-3-319-38851-9_23},
  urldate = {2025-12-04},
  abstract = {Recent advances in random linear systems on finite fields have paved the way for the construction of constant-time data structures representing static functions and minimal perfect hash functions using less space with respect to existing techniques. The main obstruction for any practical application of these results is the cubic-time Gaussian elimination required to solve these linear systems: despite they can be made very small, the computation is still too slow to be feasible. In this paper we describe in detail a number of heuristics and programming techniques to speed up the resolution of these systems by several orders of magnitude, making the overall construction competitive with the standard and widely used MWHC technique, which is based on hypergraph peeling. In particular, we introduce broadword programming techniques for fast equation manipulation and a lazy Gaussian elimination algorithm. We also describe a number of technical improvements to the data structure which further reduce space usage and improve lookup speed. Our implementation of these techniques yields a minimal perfect hash function data structure occupying 2.24 bits per element, compared to 2.68 for MWHC-based ones, and a static function data structure which reduces the multiplicative overhead from 1.23 to 1.03.},
  isbn = {978-3-319-38850-2 978-3-319-38851-9},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/IQYSAMWC/Genuzio et al. - 2016 - Fast Scalable Construction of (Minimal Perfect Hash) Functions.pdf}
}

@article{GeometryDocumentation,
  title = {Geometry - {{Documentation}}},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/7UWI3MB9/geometry.pdf}
}

@book{giomettiYoctoProjectCustomization2025,
  title = {Yocto {{Project}} Customization for {{Linux}}: The Essential Guide for Embedded Developers},
  shorttitle = {Yocto {{Project}} Customization for {{Linux}}},
  author = {Giometti, Rodolfo},
  date = {2025},
  publisher = {Apress},
  location = {Berkeley, CA},
  abstract = {Embedded computers have become very complex and are now called upon to solve a range of increasingly advanced problems. This added complexity means embedded systems need even more complex operating systems in order to work as required. The Yocto Project is now the effective standard for most embedded systems around the world due to its robustness and high configuration, availability of software packages and the ability to support several hardware platforms with common mechanisms so that developers can deploy their systems with ease regardless of the machine. Yocto Project Customization for Linux is not just another book talking about the Yocto Project, but shows how the Yocto Build system really works. Developers can easily and quickly move from the demo Yocto Project distributions that silicon vendors rely on for their development kits to their final product. This book is a practical guide teaching you everything you need to know about writing new recipes and customizing existing ones by explaining the Build System internals and how to manage them for your ongoing projects. You Will Learn: To understand Yocto Project internals and how Yocto Project tools work How to define a new meta layer or a new machine/distro in order to generate a custom Yocto Project image for their embedded system To generate a new Yocto Project recipe for your software, or to alter an already existing recipe in order to fit your needs How to update one or more packages on their running Yocto Project system How to optimize and effectively manage the Yocto Build System},
  isbn = {979-8-8688-1435-8},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/RCLZWPYH/Giometti - 2025 - Yocto Project customization for Linux the essential guide for embedded developers.epub}
}

@book{graingerAIpoweredSearch2025,
  title = {{{AI-powered}} Search},
  author = {Grainger, Trey and Turnbull, Doug and Irwin, Max and Ingersoll, Grant},
  date = {2025},
  publisher = {Manning},
  location = {Shelter Island},
  isbn = {978-1-61729-697-0},
  langid = {english},
  pagetotal = {488},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/MFMZ2JWY/Grainger et al. - 2025 - AI-powered search.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/ZZWNJBWG/AI-Powered_Search.pdf}
}

@book{gujaStartingDataAnalytics2025,
  title = {Starting Data Analytics with Generative {{AI}} and {{Python}}},
  author = {Guja, Artur and Siwiak, Marlena and Siwiak, Marian},
  namea = {Tripathi, Sue},
  nameatype = {collaborator},
  date = {2025},
  edition = {First edition},
  publisher = {Manning Publications},
  location = {Shelter Island, NY},
  abstract = {You'll find reliable and practical advice that works on the job. Improve problem exploration, generate new analytical approaches, and fine-tune your data pipelines-all while developing an intuition about the risks and errors that still come with AI tools. In the end, you'll be able to do significantly more work, do it faster, and get better results, without breaking a sweat},
  isbn = {978-1-63343-721-0},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/WJGX7ZRP/Guja et al. - 2025 - Starting data analytics with generative AI and Python.pdf}
}

@book{h.jeromekeislerElementaryCalculusInfinitesimal2024,
  title = {Elementary {{Calculus}}: {{An Infinitesimal Approach}}},
  author = {{H. Jerome Keisler}},
  date = {2024-03},
  publisher = {self published},
  url = {https://people.math.wisc.edu/~hkeisler/calc.html},
  langid = {english},
  pagetotal = {992},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/VD36HT3Y/H. Jerome Keisler - 2024 - Elementary Calculus An Infinitesimal Approach.pdf}
}

@article{hamelBriefTutorialDatabase,
  title = {A {{Brief Tutorial}} on {{Database Queries}}, {{Data Mining}}, and {{OLAP}}},
  author = {Hamel, Lutz},
  journaltitle = {Data Mining},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/8LDTADEG/Hamel - A Brief Tutorial on Database Queries, Data Mining, and OLAP.pdf}
}

@book{hanDataMiningConcepts2012,
  title = {Data Mining: Concepts and Techniques},
  shorttitle = {Data Mining},
  author = {Han, Jiawei and Kamber, Micheline and Pei, Jian},
  date = {2012},
  series = {Morgan {{Kaufmann}} Series in Data Management Systems},
  edition = {3rd ed},
  publisher = {Elsevier/Morgan Kaufmann},
  location = {Amsterdam Boston},
  abstract = {"This 3rd edition presents dozens of algorithms and implementation examples, all in pseudo-code and suitable for use in real-world, large-scale data mining projects. It addresses advanced topics such as mining object-relational databases, spatial databases, multimedia databases, time-series databases, text databases, the World Wide Web, and applications in several fields. The work also provides a comprehensive, practical look at the concepts and techniques you need to get the most out of your data."--The Publisher},
  isbn = {978-0-12-381479-1},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/56TXIFF8/Han et al. - 2012 - Data mining concepts and techniques.pdf}
}

@book{hastieElementsStatisticalLearning2008,
  title = {The Elements of Statistical Learning: Data Mining, Inference, and Prediction},
  shorttitle = {The Elements of Statistical Learning},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome H.},
  date = {2008},
  series = {Springer Series in Statistics},
  edition = {10. [print.], (corr. as of 4. print.)},
  publisher = {Springer},
  location = {New York, NY},
  isbn = {978-0-387-95284-0},
  langid = {english},
  pagetotal = {533},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/MHT3T4E4/Tibshirani und Friedman - Valerie and Patrick Hastie.pdf}
}

@incollection{havasGraphsHypergraphsHashing1994,
  title = {Graphs, Hypergraphs and Hashing},
  booktitle = {Graph-{{Theoretic Concepts}} in {{Computer Science}}},
  author = {Havas, George and Majewski, Bohdan S. and Wormald, Nicholas C. and Czech, Zbigniew J.},
  editor = {Leeuwen, Jan},
  editora = {Goos, G. and Hartmanis, J.},
  editoratype = {redactor},
  date = {1994},
  volume = {790},
  pages = {153--165},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/3-540-57899-4_49},
  url = {http://link.springer.com/10.1007/3-540-57899-4_49},
  urldate = {2025-12-04},
  abstract = {Minimal perfect hash functions are used for memory efficient storage and fast retrieval of items from static sets. We present an infinite family of efficient and practical algorithms for generating minimal perfect hash functions which allow an arbitrary order to be specified for the keys. We show that almost all members of the family are space and time optimal, and we identify the one with minimum constants. Members of the family generate a minimal perfect hash function in two steps. First a special kind of function into an r–graph is computed probabilistically. Then this function is refined deterministically to a minimal perfect hash function. We give strong practical and theoretical evidence that the first step uses linear random time. The second step runs in linear deterministic time. The family not only has theoretical importance, but also offers the fastest known method for generating perfect hash functions.},
  isbn = {978-3-540-57899-4 978-3-540-48385-4},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/2YFV4FY2/Havas et al. - 1994 - Graphs, hypergraphs and hashing.pdf}
}

@article{havasGraphTheoreticObstacles,
  title = {Graph Theoretic Obstacles to Perfect Hashing},
  author = {Havas, George and Majewski, Bohdan S},
  abstract = {A number of algorithms based on quasi-random graphs for generating perfect hash functions have been published. These include Sager’s mincycle algorithm, a modification by Fox et al. of it and finally probabilistic methods due to Czech, Havas and Majewski. Each of these algorithms exploits different properties of graphs, such as being bipartite or being acyclic. In this paper we formally justify the significance of these properties. Also we indicate causes of failure for some methods. In particular we show that acyclicity of a graph plays a crucial role in finding order preserving perfect hash functions. It is a sufficient, but not necessary, condition for algorithms to actually find a perfect hash function. We provide some examples for which various published methods methods fail, taking exponential time to do so. Finally, based on our considerations of graph properties, we propose yet another method for generating perfect hash functions.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/XBMXRIYL/Havas und Majewski - Graph theoretic obstacles to perfect hashing.pdf}
}

@article{hendlerScalableLockfreeStack,
  title = {A {{Scalable Lock-free Stack Algorithm}}},
  author = {Hendler, Danny},
  abstract = {The literature describes two high performance concurrent stack algorithms based on combining funnels and elimination trees. Unfortunately, the funnels are linearizable but blocking, and the elimination trees are non-blocking but not linearizable. Neither is used in practice since they perform well only at exceptionally high loads. The literature also describes a simple lock-free linearizable stack algorithm that works at low loads but does not scale as the load increases. The question of designing a stack algorithm that is non-blocking, linearizable, and scales well throughout the concurrency range, has thus remained open.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/TSVGB6JB/Hendler - A Scalable Lock-free Stack Algorithm.pdf}
}

@article{hilewitzNewBasisShifters2009,
  title = {A {{New Basis}} for {{Shifters}} in {{General-Purpose Processors}} for {{Existing}} and {{Advanced Bit Manipulations}}},
  author = {Hilewitz, Yedidya and Lee, Ruby B.},
  date = {2009-08},
  journaltitle = {IEEE Transactions on Computers},
  shortjournal = {IEEE Trans. Comput.},
  volume = {58},
  number = {8},
  pages = {1035--1048},
  issn = {0018-9340},
  doi = {10.1109/TC.2008.219},
  url = {http://ieeexplore.ieee.org/document/4721365/},
  urldate = {2025-12-05},
  abstract = {This paper describes a new basis for the implementation of the shifter functional unit in microprocessors that can implement new advanced bit manipulations as well as standard shifter operations. Our design is based on the inverse butterfly and butterfly data path circuits, rather than the barrel shifter or log-shifter designs currently used. We show how this new shifter can implement the standard shift and rotate operations, as well as more advanced extract, deposit, and mix operations found in some processors. Furthermore, it can perform important new classes of even more advanced bit manipulation instructions like arbitrary bit permutations, bit gather (or parallel extract), and bit scatter (or parallel deposit) instructions. Thus, our new functional unit performs the functionality of three functional units—the basic shifter, the multimedia-mix unit, and the advanced bit manipulation functional unit, while having a latency only slightly longer than that of the log-shifter. For performing only the existing functions of a shifter, it has significantly smaller area.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/62UZ7H96/Hilewitz und Lee - 2009 - A New Basis for Shifters in General-Purpose Processors for Existing and Advanced Bit Manipulations.pdf}
}

@book{hitchcockEnterpriseLinuxAdministrator2023,
  title = {The {{Enterprise Linux Administrator}}: {{Journey}} to a {{New Linux Career}}},
  shorttitle = {The {{Enterprise Linux Administrator}}},
  author = {Hitchcock, Kenneth},
  date = {2023},
  edition = {1st ed. 2023},
  publisher = {Apress},
  location = {Berkeley, CA},
  doi = {10.1007/978-1-4842-8801-6},
  isbn = {978-1-4842-8800-9 978-1-4842-8801-6},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/CJJUNA72/Hitchcock - 2023 - The Enterprise Linux Administrator Journey to a New Linux Career.epub}
}

@book{hitchcockLinuxSystemAdministration2022,
  title = {Linux {{System Administration}} for {{The}} 2020s: {{The Modern Sysadmin Leaving Behind}} the {{Culture}} of {{Build}} and {{Maintain}}},
  shorttitle = {Linux {{System Administration}} for {{The}} 2020s},
  author = {Hitchcock, Kenneth},
  date = {2022},
  publisher = {Apress L. P},
  location = {Berkeley, CA},
  abstract = {Intro -- Table of Contents -- About the Author -- About the Technical Reviewer -- Acknowledgments -- Introduction -- Part I: Laying the Foundation -- Chapter 1: Linux at a Glance -- Brief Unix to Linux History -- Open Source -- Linux Is Everywhere -- Community Linux Distributions -- Community -- Upstream -- Community Contributors -- Common Distributions -- Which Distribution Is Best for You -- Before Committing -- The Three Linux Distro Categories -- Option One: Out-of-the-Box Distros -- Easy to Understand -- Installation Should Not Require a Degree -- Try Ubuntu -- Walk Before Running -- Option Two: The Almost Out-of-the-Box Distros -- Try Fedora, openSUSE, or Debian -- Option Three: The "Challenge Accepted" Distros -- With Great Power … -- Try Arch Linux or Gentoo -- Enterprise Linux Distributions -- Red Hat -- Red Hat Enterprise Linux -- Automation -- Hybrid Cloud -- Canonical -- Linux Support -- Cloud -- Internet of Things -- SUSE -- Server and Desktop -- Cloud, Storage, and Management -- Community vs. Enterprise -- Knowledge Check -- Summary -- Part II: Strengthening Core Skills -- Chapter 2: New Tools to Improve the Administrative Experience -- Task Management -- Starting a Process -- Task Visualization Tooling -- Top -- Alternatives to Top -- nmon -- Killing Processes -- Zombie Processes -- Background Tasks -- Running Time-Consuming Tasks -- Screen -- Tmux -- Ansible Introduction -- Installing Ansible -- Package Management -- Pip -- Configuring Ansible -- Ansible Inventory -- Running Ansible -- Playbooks -- Roles -- Role Directory Structure -- Generating Ansible Roles -- Modules -- Sharing Your Ansible -- Ansible Galaxy -- Web Consoles -- Cockpit -- Installation -- Configuration -- Using Cockpit -- Limitations -- Alternatives to Cockpit -- Webmin -- Ajenti -- Text Consoles -- Installing -- Using -- Summary -- Chapter 3: Estate Management},
  isbn = {978-1-4842-7983-0 978-1-4842-7984-7},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/3NRUHHZQ/Hitchcock - 2022 - Linux System Administration for The 2020s The Modern Sysadmin Leaving Behind the Culture of Build a.epub}
}

@book{holubCompilerDesign1990,
  title = {Compiler Design in {{C}}},
  author = {Holub, Allen I.},
  date = {1990},
  series = {Prentice-{{Hall}} Software Series},
  edition = {8. print},
  publisher = {Prentice Hall},
  location = {Englewood Cliffs, NJ},
  isbn = {978-0-13-155045-2},
  langid = {english},
  pagetotal = {924},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/RIH4L6EI/Holub - 1990 - Compiler design in C.pdf}
}

@book{howseLearningOpenCV42020,
  title = {Learning {{OpenCV}} 4 Computer Vision with {{Python}} 3: Get to Grips with Tools, Techniques, and Algorithms for Computer Vision and Machine Learning},
  shorttitle = {Learning {{OpenCV}} 4 Computer Vision with {{Python}} 3},
  author = {Howse, Joseph and Minichino, Joe},
  date = {2020},
  edition = {Third edition},
  publisher = {Packt Publishing},
  location = {Birmingham, UK},
  abstract = {Computer Vision is a rapidly evolving science, encompassing diverse applications and techniques. This book will not only help those who are getting started with computer vision but also experts in the domain. You'll be able to put theory into practice by building apps with OpenCV 4 and Python 3. You'll start by understanding OpenCV 4 and how to set it up with Python 3 on various platforms. Next, you'll learn how to perform basic operations such as reading, writing, manipulating, and displaying still images, videos, and camera feeds. From taking you through image processing, video analysis, and depth estimation and segmentation, to helping you gain practice by building a CUI app, this book ensures you'll have opportunities for hands-on activities. Next, you'll tackle two popular challenges: face detection and face recognition. You'll also learn about object classification and machine learning concepts, which will enable you to create and use object detectors and classifiers, and even track objects in movies or video camera feeds. Later, you'll develop your skills in 3D tracking and augmented reality. Finally, you'll cover ANNs and DNNs, learning how to develop apps for recognizing handwritten digits and classifying a person's gender and age. By the end of this book, you'll have the skills you need to execute real-world computer vision projects},
  isbn = {978-1-78953-161-9},
  langid = {english},
  pagetotal = {358},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/CE9I9S3E/Howse und Minichino - 2020 - Learning OpenCV 4 computer vision with Python 3 get to grips with tools, techniques, and algorithms.pdf}
}

@article{hsuPracticalGuideSupport,
  title = {A {{Practical Guide}} to {{Support Vector Classiﬁcation}}},
  author = {Hsu, Chih-Wei and Chang, Chih-Chung and Lin, Chih-Jen},
  abstract = {The support vector machine (SVM) is a popular classification technique. However, beginners who are not familiar with SVM often get unsatisfactory results since they miss some easy but significant steps. In this guide, we propose a simple procedure which usually gives reasonable results.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/P6GP6U37/Hsu et al. - A Practical Guide to Support Vector Classiﬁcation.pdf}
}

@article{huffmanMethodConstructionMinimumRedundancy,
  title = {A {{Method}} for the {{Construction}} of {{Minimum-Redundancy Codes}}},
  author = {Huffman, David A},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/24IEPLVE/Huffman - A Method for the Construction of Minimum-Redundancy Codes.pdf}
}

@book{hurbansGrokkingArtificialIntelligence2020,
  title = {Grokking Artificial Intelligence Algorithms},
  author = {Hurbans, Rishal},
  date = {2020},
  publisher = {Manning},
  location = {Shelter Island},
  abstract = {Grokking Artificial Intelligence Algorithms uses illustrations, exercises, and jargon-free explanations to teach fundamental AI concepts. All you need is the algebra you remember from high school math class. Explore coding challenges like detecting bank fraud, creating artistic masterpieces, and setting a self-driving car in motion},
  isbn = {978-1-61729-618-5},
  langid = {english},
  pagetotal = {362},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/43QGZ5ZE/Hurbans - 2020 - Grokking artificial intelligence algorithms.pdf}
}

@book{hussainJourneyCreatingOperating2022,
  title = {A journey in creating an operating system kernel: the 539kernel book},
  shorttitle = {A journey in creating an operating system kernel},
  namea = {Hussain, Mohammed},
  nameatype = {collaborator},
  date = {2022},
  publisher = {éditeur inconnu},
  location = {lieu inconnu},
  isbn = {979-8-3647-4477-7},
  langid = {fre},
  annotation = {OCLC: 1369570030},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/NCNE7AAV/Hussain - A Journey in Creating an Operating System Kernel.pdf}
}

@article{hydeArtAssemblyLanguage,
  title = {The {{Art Of Assembly Language Programming}}},
  author = {Hyde, Randall},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/WVTHV5VA/Full_Book.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/XKD96D8I/Hyde - The Art Of Assembly Language Programming.pdf}
}

@article{iiiCourseMachineLearning,
  title = {A {{Course}} in {{Machine Learning}}},
  author = {Iii, Hal Daumé},
  journaltitle = {ciml.info},
  pages = {227},
  url = {http://ciml.info/dl/v0_99/ciml-v0_99-all.pdf},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/75QRYXVB/ciml-v0_99-all.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/NIRJP5NL/Iii - A Course in Machine Learning.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/U686VB73/Math for Machine Learning (2009).pdf}
}

@article{iltenSVGPackagesSvg,
  title = {{{SVG}} - {{The}} Packages Svg and Svg-Extract},
  author = {Ilten, Philip and Hanisch, Falk},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/Z4WQSE8M/Ilten und Hanisch - The packages svg and svg-extract.pdf}
}

@book{jahneDigitalImageProcessing2005,
  title = {Digital Image Processing: Concepts, Algorithms and Scientific Applications},
  shorttitle = {Digital Image Processing},
  author = {Jähne, Bernd},
  date = {2005},
  edition = {6th revised and extended ed},
  publisher = {Springer},
  location = {Berlin},
  isbn = {978-3-540-24035-8},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/NVIECA8M/Jähne - 2005 - Digital image processing concepts, algorithms and scientific applications.pdf}
}

@book{jainLinuxContainersVirtualization2023,
  title = {Linux {{Containers}} and {{Virtualization}}: {{Utilizing Rust}} for {{Linux Containers}}},
  shorttitle = {Linux {{Containers}} and {{Virtualization}}},
  author = {Jain, Shashank Mohan},
  date = {2023},
  edition = {2nd ed},
  publisher = {Apress L. P},
  location = {Berkeley, CA},
  abstract = {Intro -- Table of Contents -- About the Author -- About the Technical Reviewer -- Chapter 1: Virtualization Basics -- History of Virtualization -- What Is Virtualization? -- VM-Based Virtualization -- Container-Based Virtualization -- Hypervisors -- Virtual Machine Monitor -- Device Model -- Memory Virtualization -- Shadow Page Tables -- Nested Page Tables with Hardware Support -- CPU Virtualization -- Binary Translation in the Case of Full Virtualization -- Paravirtualization in the Case of XEN with Hypercalls -- IO Virtualization -- Full Virtualization -- Paravirtualization -- Summary -- Chapter 2: Hypervisors -- The Intel Vt-x Instruction Set -- The Quick Emulator -- Creating a VM Using the KVM Module -- Vhost-Based Data Communication -- What Is an eventfd? -- Alternative Virtualization Mechanisms -- Unikernels -- Project Dune -- novm -- Summary of Alternative Virtualization Approaches -- Summary -- Chapter 3: Namespaces -- Namespace Types -- UTS -- PID -- Mount -- Network -- IPC -- Cgroup -- Time -- Data Structures for Linux Namespaces -- Adding a Device to a Namespace -- Summary -- Chapter 4: Cgroups -- Creating a Sample Cgroup -- Cgroup Types -- CPU Cgroup -- Block I/O Cgroups -- Understanding Fairness -- Understanding Throttling -- Summary -- Chapter 5: Layered File Systems -- A File System Primer -- Brief Overview of Pseudo File Systems -- Understanding layered File Systems -- The Union File System -- OverlayFS -- Summary -- Chapter 6: Creating a Simple Container Framework -- The UTS Namespace -- Golang Installation -- Building a Container with a Namespace -- Adding More Namespaces -- Launching a Shell Program Within the Container -- Providing the Root File System -- The Mount Proc File System -- Enabling the Network for the Container -- Virtual Networking: A Brief Primer -- Enabling Cgroups for the Container -- Summary},
  isbn = {978-1-4842-9767-4 978-1-4842-9768-1},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/DZCZHUMY/Jain - 2023 - Linux Containers and Virtualization Utilizing Rust for Linux Containers.epub}
}

@book{jamesIntroductionStatisticalLearning2013,
  title = {An {{Introduction}} to {{Statistical Learning}}},
  author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  date = {2013},
  series = {Springer {{Texts}} in {{Statistics}}},
  volume = {103},
  publisher = {Springer New York},
  location = {New York, NY},
  doi = {10.1007/978-1-4614-7138-7},
  url = {http://link.springer.com/10.1007/978-1-4614-7138-7},
  urldate = {2025-12-07},
  isbn = {978-1-4614-7137-0 978-1-4614-7138-7},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/8JUG3ICT/James et al. - 2013 - An Introduction to Statistical Learning.pdf}
}

@book{jansenMachineLearningAlgorithmic2020,
  title = {Machine Learning for Algorithmic Trading: Predictive Models to Extract Signals from Market and Alternative Data for Systematic Trading Strategies with {{Python}}},
  shorttitle = {Machine Learning for Algorithmic Trading},
  author = {Jansen, Stefan},
  date = {2020},
  edition = {Second edition},
  publisher = {Packt Publishing},
  location = {Birmingham, UK},
  isbn = {978-1-83921-771-5},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/5MANF63C/Jansen - 2020 - Machine learning for algorithmic trading predictive models to extract signals from market and alter.pdf}
}

@book{jaworskiExpertPythonProgramming2021,
  title = {Expert {{Python Programming}}: {{Master Python}} by Learning the Best Coding Practices and Advanced Programming Concepts},
  shorttitle = {Expert {{Python Programming}}},
  author = {Jaworski, Michał and Ziadé, Tarek},
  date = {2021},
  edition = {Fourth Edition},
  publisher = {Packt Publishing},
  location = {Birmingham Mumbai},
  abstract = {Expert Python Programming, Fourth Edition is a collection of actionable Python programming insights that will help you effectively solve challenging problems. This Python book provides you with a thorough understanding of the complete process of building and maintaining Python apps},
  isbn = {978-1-80107-110-9},
  langid = {english},
  pagetotal = {611},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/WGUU282D/Jaworski und Ziadé - 2021 - Expert Python Programming Master Python by learning the best coding practices and advanced programm.pdf}
}

@article{jeanpierrecasteleynTikZVisualTikZ,
  title = {{{TikZ}} - {{Visual TikZ}}},
  author = {{Jean Pierre Casteleyn}},
  url = {https://tug.ctan.org/info/visualtikz/VisualTikZ.pdf},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/XSBITXC8/VisualTikZ.pdf}
}

@article{judsonAbstractAlgebra,
  title = {Abstract {{Algebra}}},
  author = {Judson, Thomas W},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/QDHYFNZT/Judson - Abstract Algebra.pdf}
}

@book{kardellBuildFinancialSoftware2025,
  title = {Build {{Financial Software}} with {{Generative AI}} (from {{Scratch}})},
  author = {Kardell, Christopher},
  namea = {Brouwer, Mark},
  nameatype = {collaborator},
  date = {2025},
  edition = {1st ed},
  publisher = {Manning Publications Co. LLC},
  location = {New York},
  isbn = {978-1-63343-662-6 978-1-63835-745-2},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/3WWLZXQT/Build_Financial_Software_with_Generative.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/A64QH9Y6/Kardell - 2025 - Build Financial Software with Generative AI (from Scratch).pdf}
}

@article{kernerHistoryModern64bit,
  title = {A {{History}} of {{Modern}} 64-Bit {{Computing}}},
  author = {Kerner, Matthew},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/TC9PGM5P/Kerner - A History of Modern 64-bit Computing.pdf}
}

@article{kernXColorExtendingLATEXs,
  title = {{{XColor}} - {{Extending LATEX}}’s Color Facilities: The Xcolor Package},
  author = {Kern, Dr Uwe},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/YULAGLQ6/Kern - Extending LATEX’s color facilities the xcolor package.pdf}
}

@online{kingmaAdamMethodStochastic2017,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  shorttitle = {Adam},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  date = {2017-01-30},
  eprint = {1412.6980},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1412.6980},
  url = {http://arxiv.org/abs/1412.6980},
  urldate = {2025-12-07},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/S7C68FXR/Kingma und Ba - 2017 - Adam A Method for Stochastic Optimization.pdf}
}

@book{klostermanDataScienceProjects2021,
  title = {Data Science Projects with {{Python}}: A Case Study Approach to Gaining Valuable Insights from Real Data with Machine Learning, 2nd Edition},
  shorttitle = {Data Science Projects with {{Python}}},
  author = {Klosterman, Stephen},
  date = {2021},
  edition = {2nd ed},
  publisher = {Packt Publishing},
  location = {Place of publication not identified},
  abstract = {Gain hands-on experience of Python programming with industry-standard machine learning techniques using pandas, scikit-learn, and XGBoost Key Features Think critically about data and use it to form and test a hypothesis Choose an appropriate machine learning model and train it on your data Communicate data-driven insights with confidence and clarity Book DescriptionIf data is the new oil, then machine learning is the drill. As companies gain access to ever-increasing quantities of raw data, the ability to deliver state-of-the-art predictive models that support business decision-making becomes more and more valuable. In this book, you'll work on an end-to-end project based around a realistic data set and split up into bite-sized practical exercises. This creates a case-study approach that simulates the working conditions you'll experience in real-world data science projects. You'll learn how to use key Python packages, including pandas, Matplotlib, and scikit-learn, and master the process of data exploration and data processing, before moving on to fitting, evaluating, and tuning algorithms such as regularized logistic regression and random forest. Now in its second edition, this book will take you through the end-to-end process of exploring data and delivering machine learning models. Updated for 2021, this edition includes brand new content on XGBoost, SHAP values, algorithmic fairness, and the ethical concerns of deploying a model in the real world. By the end of this data science book, you'll have the skills, understanding, and confidence to build your own machine learning models and gain insights from real data. What you will learn Load, explore, and process data using the pandas Python package Use Matplotlib to create compelling data visualizations Implement predictive machine learning models with scikit-learn Use lasso and ridge regression to reduce model overfitting Evaluate random forest and logistic regression model performance Deliver business insights by presenting clear, convincing conclusions Who this book is forData Science Projects with Python - Second Edition is for anyone who wants to get started with data science and machine learning. If you're keen to advance your career by using data analysis and predictive modeling to generate business insights, then this book is the perfect place to begin. To quickly grasp the concepts covered, it is recommended that you have basic experience of programming with Python or another similar language, and a general interest in statistics},
  isbn = {978-1-80056-448-0 978-1-80056-944-7},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/7UR82PEI/Klosterman - 2021 - Data science projects with Python a case study approach to gaining valuable insights from real data.pdf}
}

@book{Kriesel2007NeuralNetworks,
  title = {A Brief Introduction to Neural Networks},
  author = {Kriesel, David},
  date = {2007},
  url = {available at http://www.dkriesel.com},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/P6R87H7M/Kriesel - 2007 - A brief introduction to neural networks.pdf}
}

@book{krunicSucceedingAIHow2020,
  title = {Succeeding with {{AI}}: How to Make {{AI}} Work for Your Business},
  shorttitle = {Succeeding with {{AI}}},
  author = {Krunic, Veljko},
  date = {2020},
  publisher = {Manning},
  location = {Shelter Island},
  isbn = {978-1-61729-693-2},
  langid = {english},
  pagetotal = {264},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/4LTZKU2V/Krunic - 2020 - Succeeding with AI how to make AI work for your business.pdf}
}

@article{lambertStudyCodeAbstraction,
  title = {A Study of Code Abstraction},
  author = {Lambert, Patrick},
  abstract = {Modern developers are shielded from the inner workings of computers and networks thanks to several layers of code abstraction. We'll dig into those layers from a single line of Perl code, down to the bytes that get produced at the bottom of the API stack.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/FQI22DCA/Lambert - A study of code abstraction.pdf}
}

@article{lampingFastMinimalMemory,
  title = {A {{Fast}}, {{Minimal Memory}}, {{Consistent Hash Algorithm}}},
  author = {Lamping, John and Veach, Eric},
  abstract = {We present jump consistent hash, a fast, minimal memory, consistent hash algorithm that can be expressed in about 5 lines of code. In comparison to the algorithm of Karger et al., jump consistent hash requires no storage, is faster, and does a better job of evenly dividing the key space among the buckets and of evenly dividing the workload when the number of buckets changes. Its main limitation is that the buckets must be numbered sequentially, which makes it more suitable for data storage applications than for distributed web caching.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/IMWHR6F9/Lamping und Veach - A Fast, Minimal Memory, Consistent Hash Algorithm.pdf}
}

@article{lampingFastMinimalMemorya,
  title = {A {{Fast}}, {{Minimal Memory}}, {{Consistent Hash Algorithm}}},
  author = {Lamping, John and Veach, Eric},
  abstract = {We present jump consistent hash, a fast, minimal memory, consistent hash algorithm that can be expressed in about 5 lines of code. In comparison to the algorithm of Karger et al., jump consistent hash requires no storage, is faster, and does a better job of evenly dividing the key space among the buckets and of evenly dividing the workload when the number of buckets changes. Its main limitation is that the buckets must be numbered sequentially, which makes it more suitable for data storage applications than for distributed web caching.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/WJNFSXJW/Lamping und Veach - A Fast, Minimal Memory, Consistent Hash Algorithm.pdf}
}

@book{lanhamAIAgentsAction2025,
  title = {{{AI}} Agents in Action},
  author = {Lanham, Micheal},
  date = {2025},
  edition = {First edition},
  publisher = {Manning Publications},
  location = {Shelter Island, NY},
  abstract = {In AI Agents in Action, you’ll learn how to build production-ready assistants, multi-agent systems, and behavioral agents. You’ll master the essential parts of an agent, including retrieval-augmented knowledge and memory, while you create multi-agent applications that can use software tools, plan tasks autonomously, and learn from experience. As you explore the many interesting examples, you’ll work with state-of-the-art tools like OpenAI Assistants API, GPT Nexus, LangChain, Prompt Flow, AutoGen, and CrewAI},
  isbn = {978-1-63343-634-3},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/Zotero/storage/7LAB8ZA7/Lanham - 2025 - AI agents in action.pdf;/Users/bernhardgerlach/Zotero/storage/8S9VHGFD/AI_Agents_in_Action.pdf}
}

@article{latexprojectteamLaTeXDocumentationLaTeX,
  title = {{{LaTeX}} - {{Documentation}} - {{LaTeX}} for Authors Current Version},
  author = {{LATEX Project Team}},
  url = {ftp.agdsn.de/pub/mirrors/latex/dante/macros/latex/base/usrguide.pdf},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/7KHVS8V5/LaTeX for authors current version.pdf}
}

@article{lecunWhatsWrongDeep,
  title = {What's {{Wrong With Deep Learning}}?},
  author = {LeCun, Yann},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/YFC922QK/LeCun - What's Wrong With Deep Learning.pdf}
}

@article{lehmanBiblatexDocumentation,
  title = {Biblatex - {{Documentation}}},
  author = {Lehman, Philipp and Kime, Philip and Wemheuer, Moritz},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/2BW76AAA/Lehman et al. - The biblatex Package.pdf}
}

@book{lehmannMathematicsComputerScience2017,
  title = {Mathematics for Computer Science},
  author = {Lehmann, Erich L. and Leighton, Frank Thomson and Meyer, Albert R.},
  date = {2017},
  location = {Milton Keynes\$lLightning Source},
  isbn = {978-1-68092-121-2},
  langid = {english},
  pagetotal = {998},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/X4IIYR6V/Lehmann et al. - 2017 - Mathematics for computer science.pdf}
}

@book{lehmannMathematicsComputerScience2017a,
  title = {Mathematics for Computer Science},
  author = {Lehmann, Erich L. and Leighton, Frank Thomson and Meyer, Albert R.},
  date = {2017},
  location = {Milton Keynes\$lLightning Source},
  isbn = {978-1-68092-121-2},
  langid = {english},
  pagetotal = {998},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/WK2Z5I9I/Lehmann et al. - 2017 - Mathematics for computer science.pdf}
}

@online{lehmannShockHashOptimalSpaceMinimal2024,
  title = {{{ShockHash}}: {{Near Optimal-Space Minimal Perfect Hashing Beyond Brute-Force}}},
  shorttitle = {{{ShockHash}}},
  author = {Lehmann, Hans-Peter and Sanders, Peter and Walzer, Stefan},
  date = {2024-06-05},
  eprint = {2310.14959},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2310.14959},
  url = {http://arxiv.org/abs/2310.14959},
  urldate = {2025-12-04},
  abstract = {A minimal perfect hash function (MPHF) maps a set S of n keys to the first n integers without collisions. There is a lower bound of n log2 e − O(log n) ≈ 1.44n bits needed to represent an MPHF. This can be reached by a brute-force algorithm that tries en hash function seeds in expectation and stores the first seed that leads to an MPHF. The most space-efficient previous algorithms for constructing MPHFs all use such a brute-force approach as a basic building block.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Data Structures and Algorithms},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/RR2QN5ZB/Lehmann et al. - 2024 - ShockHash Near Optimal-Space Minimal Perfect Hashing Beyond Brute-Force.pdf}
}

@book{lemaireAIEverydayIT2025,
  title = {{{AI}} for {{Everyday IT}}: {{Accelerate Workplace Productivity}}},
  shorttitle = {{{AI}} for {{Everyday IT}}},
  author = {LeMaire, Chrissy},
  namea = {Abshire, Brandon},
  nameatype = {collaborator},
  date = {2025},
  publisher = {Manning Publications Co. LLC},
  location = {New York},
  abstract = {Automate and accelerate your everyday IT tasks with instant solutions! What if you never had to write another after-incident report, piece of boilerplate code, or a performance review from scratch ever again? Use AI tools like ChatGPT, Claude, Gemini, and Copilot right, and you'll take back hours of your time--and more! AI for Everyday IT reveals how you can automate dozens of your daily IT tasks with generative AI. In AI for Everyday IT you'll learn how to: • Write effective prompts for common IT tasks • Optimize report generation, document handling, and workplace communication • Resolve IT conflicts and crises • Acquire new skills and upgrade your resume • AI for help desk, database administration and systems administration • Incorporate AI into DevOps processes and create AI-powered applications • Simplify time-consuming people management tasks In this hands-on guide, automation experts Chrissy LeMaire and Brandon Abshire show you how AI tools like ChatGPT have made their lives a million times easier, and how they can do the same for you. You'll find proven strategies for using AI to improve help desk support, automate sysadmin and database tasks, aid with DevOps engineering, handle managing IT teams, and dozens more time-saving and quality-improving hacks. Foreword by Nitya Narasimhan. About the technology Have you lost days sifting through logs to find a latency issue? AI can do it in seconds! Need to update your documentation? Mere moments for AI. Are you writing scripts, designing data recovery strategies, and evaluating network designs? AI can handle it all--if you know how to use it. About the book AI for Everyday IT shows you exactly how AI can transform support desk operations, root cause analysis, disaster recovery planning--even writing professional emails when you're too furious to be nice! This instantly-useful guide has time-saving techniques for all IT pros--from devs and DBAs to technical writers and product managers. Each relatable example is fully illustrated with the prompts and problem formulation strategies, along with interesting insights and anecdotes from authors Chrissy Lemaire and Brandon Abshire. What's inside • Document handling and workplace communication • Database administration and development • DevOps engineering and AI powered apps • People management and career planning About the reader Whether you're working in operations, development, management, or security, you'll love these productivity hacks for generative AI. No previous AI experience required. About the author Chrissy LeMaire is a dual Microsoft MVP and GitHub Star, the creator of dbatools, and author of the Manning book Learn dbatools in a Month of Lunches. Brandon Abshire has spent over twenty years in IT, including roles at a leading Fortune 500 semiconductor and telecommunications company and multiple top-ranked US hospital systems. Table of Contents Part 1 1 Artificial intelligence in IT 2 Chatbots: Tasks and tips 3 Basic intelligence 4 Prompt engineering and problem formulation 5 Prompts in action 6 Document handling 7 Emails and instant messaging in the workplace Part 2 8 IT support and service desk 9 Systems administration 10 Database administration and development Part 3 11 Code assistants and development tools 12 AI in DevOps engineering 13 Building AI-powered applications Part 4 14 Conflict resolution and crisis management 15 Management essentials 16 Management interventions 17 Career advancement A Local AI models: An accessible alternative B OpenAI GPT Actions},
  isbn = {978-1-63343-642-8 978-1-63835-752-0},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/MCXMEJ2T/AI_for_Everyday_IT.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/PMG4822N/LeMaire - 2025 - AI for Everyday IT Accelerate Workplace Productivity.pdf}
}

@book{leskovecMiningMassiveDatasets2014,
  title = {Mining of Massive Datasets},
  author = {Leskovec, Jure and Rajaraman, Anand and Ullman, Jeffrey D.},
  date = {2014},
  edition = {Second edition},
  publisher = {Cambridge University Press},
  location = {Cambridge},
  isbn = {978-1-107-07723-2},
  langid = {english},
  pagetotal = {467},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/L9XQG6UC/Leskovec et al. - 2014 - Mining of massive datasets.pdf}
}

@online{limassetFastScalableMinimal2017,
  title = {Fast and Scalable Minimal Perfect Hashing for Massive Key Sets},
  author = {Limasset, Antoine and Rizk, Guillaume and Chikhi, Rayan and Peterlongo, Pierre},
  date = {2017-02-16},
  eprint = {1702.03154},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1702.03154},
  url = {http://arxiv.org/abs/1702.03154},
  urldate = {2025-12-04},
  abstract = {Minimal perfect hash functions provide space-efficient and collision-free hashing on static sets. Existing algorithms and implementations that build such functions have practical limitations on the number of input elements they can process, due to high construction time, RAM or external memory usage. We revisit a simple algorithm and show that it is highly competitive with the state of the art, especially in terms of construction time and memory usage. We provide a parallel C++ implementation called BBhash. It is capable of creating a minimal perfect hash function of \$10\textasciicircum\{10\}\$ elements in less than 7 minutes using 8 threads and 5 GB of memory, and the resulting function uses 3.7 bits/element. To the best of our knowledge, this is also the first implementation that has been successfully tested on an input of cardinality \$10\textasciicircum\{12\}\$. Source code: https://github.com/rizkg/BBHash},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Data Structures and Algorithms},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/X683SYAE/Limasset et al. - 2017 - Fast and scalable minimal perfect hashing for massive key sets.pdf}
}

@book{lipenkovaArtAIProduct2025,
  title = {The Art of {{AI}} Product Development: Delivering Business Value},
  shorttitle = {The Art of {{AI}} Product Development},
  author = {Lipenkova, Janna},
  date = {2025},
  publisher = {Manning Publications Co},
  location = {Shelter Island, NY},
  abstract = {"Integrating AI into your software and processes can create real value for your business and its customers - if you do it right. When you're on the hook for delivering AI-enabled products, you'll need to spot high-impact opportunities, work effectively with engineers, design user-centric features, avoid common project failures, and manage real-world launches. This book shows you how. The Art of AI Product Development gives you a clear framework, practical tools, and real-world examples to build confidence and succeed with new AI projects - even if you're tackling AI for the first time" --},
  isbn = {978-1-63343-705-0},
  langid = {english},
  pagetotal = {344},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/GU8ZT3J8/Lipenkova - 2025 - The art of AI product development delivering business value.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/LA27K2DZ/The_Art_of_AI_Product_Development.pdf}
}

@online{liuKANKolmogorovArnoldNetworks2025,
  title = {{{KAN}}: {{Kolmogorov-Arnold Networks}}},
  shorttitle = {{{KAN}}},
  author = {Liu, Ziming and Wang, Yixuan and Vaidya, Sachin and Ruehle, Fabian and Halverson, James and Soljačić, Marin and Hou, Thomas Y. and Tegmark, Max},
  date = {2025-02-09},
  eprint = {2404.19756},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2404.19756},
  url = {http://arxiv.org/abs/2404.19756},
  urldate = {2025-12-07},
  abstract = {Inspired by the Kolmogorov-Arnold representation theorem, we propose KolmogorovArnold Networks (KANs) as promising alternatives to Multi-Layer Perceptrons (MLPs). While MLPs have fixed activation functions on nodes (“neurons”), KANs have learnable activation functions on edges (“weights”). KANs have no linear weights at all – every weight parameter is replaced by a univariate function parametrized as a spline. We show that this seemingly simple change makes KANs outperform MLPs in terms of accuracy and interpretability, on small-scale AI + Science tasks. For accuracy, smaller KANs can achieve comparable or better accuracy than larger MLPs in function fitting tasks. Theoretically and empirically, KANs possess faster neural scaling laws than MLPs. For interpretability, KANs can be intuitively visualized and can easily interact with human users. Through two examples in mathematics and physics, KANs are shown to be useful “collaborators” helping scientists (re)discover mathematical and physical laws. In summary, KANs are promising alternatives for MLPs, opening opportunities for further improving today’s deep learning models which rely heavily on MLPs.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Condensed Matter - Disordered Systems and Neural Networks,Statistics - Machine Learning},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/WNCBWNKC/Liu et al. - 2025 - KAN Kolmogorov-Arnold Networks.pdf}
}

@book{liuLearnGenerativeAI2025,
  title = {Learn Generative {{AI}} with {{PyTorch}}},
  author = {Liu, Mark H.},
  namea = {Sanders, Sarah},
  nameatype = {collaborator},
  date = {2025},
  edition = {First edition},
  publisher = {Manning Publications},
  location = {Shelter Island, NY},
  abstract = {Learn Generative AI with PyTorch introduces the underlying mechanics of generative AI by helping you build your own working AI models. You’ll begin by creating simple images using a GAN, and then progress to writing a language translation transformer line-by-line. As you work through the fun and fascinating projects, you’ll train models to create anime images, write like Hemingway, make music like Mozart, and more. You just need Python and a few machine learning basics to get started. You’ll learn the rest as you go!},
  isbn = {978-1-63343-646-6},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/7UEQFD9K/Liu - 2025 - Learn generative AI with PyTorch.pdf}
}

@book{loducaDataStorytellingAltair2024,
  title = {Data Storytelling with {{Altair}} and {{AI}}},
  author = {Lo Duca, Angelica},
  date = {2024},
  publisher = {Manning},
  location = {Shelter Island},
  isbn = {978-1-63343-792-0},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/7WFPVPZD/Lo Duca - 2024 - Data storytelling with Altair and AI.pdf}
}

@book{lottPythonObjectorientedProgramming2021,
  title = {Python Object-Oriented Programming: Build Robust and Maintainable Object-Oriented {{Python}} Applications and Libraries},
  shorttitle = {Python Object-Oriented Programming},
  author = {Lott, Steven and Phillips, Dusty},
  date = {2021},
  series = {Expert {{Insight}}},
  edition = {4th ed},
  publisher = {Packt Publishing},
  location = {Place of publication not identified},
  abstract = {Being familiar with object-oriented design is an essential part of programming in Python. This new edition includes all the topics that made Python Object-Oriented Programming an instant Packt classic. Moreover, it's packed with updated content to reflect more recent changes in the core Python libraries and cover modern third-party packages},
  isbn = {978-1-80107-726-2 978-1-80107-523-7},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/5AXHZ4M7/Lott und Phillips - 2021 - Python object-oriented programming build robust and maintainable object-oriented Python application.pdf}
}

@article{luUniversalApproximationTheorem,
  title = {A {{Universal Approximation Theorem}} of {{Deep Neural Networks}} for {{Expressing Probability Distributions}}},
  author = {Lu, Yulong and Lu, Jianfeng},
  abstract = {This paper studies the universal approximation property of deep neural networks for representing probability distributions. Given a target distribution π and a source distribution pz both defined on Rd, we prove under some assumptions that there exists a deep neural network g : Rd→R with ReLU activation such that the pushforward measure (∇g)\#pz of pz under the map ∇g is arbitrarily close to the target measure π. The closeness are measured by three classes of integral probability metrics between probability distributions: 1-Wasserstein distance, maximum mean distance (MMD) and kernelized Stein discrepancy (KSD). We prove upper bounds for the size (width and depth) of the deep neural network in terms of the dimension d and the approximation error ε with respect to the three discrepancies. In particular, the size of neural network can grow exponentially in d when 1-Wasserstein distance is used as the discrepancy, whereas for both MMD and KSD the size of neural network only depends on d at most polynomially. Our proof relies on convergence estimates of empirical measures under aforementioned discrepancies and semidiscrete optimal transport.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/LIEU33T9/Lu und Lu - A Universal Approximation Theorem of Deep Neural Networks for Expressing Probability Distributions.pdf}
}

@article{lyuTabularrayTypesetTabulars,
  title = {Tabularray - {{Typeset Tabulars}} and {{Arrays}} with {{LATEX3}}},
  author = {Lyu, Jianrui},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/AYHHBL98/Lyu - Tabularray Typeset Tabulars and Arrays with LATEX3.pdf}
}

@book{mackayInformationTheoryInference2005,
  title = {Information {{Theory}}, {{Inference}}, and {{Learning Algorithms}}},
  author = {MacKay, David J.C.},
  date = {2005-03-28},
  edition = {4th Edition},
  publisher = {Cambridge University Press},
  isbn = {978-0-521-64298-9},
  langid = {english},
  pagetotal = {642},
  keywords = {Mathematics},
  file = {/Users/bernhardgerlach/Zotero/storage/8CFX5X7H/MacKay - 2005 - Information Theory, Inference, and Learning Algorithms.pdf}
}

@book{maggioriAIPocketBook2025,
  title = {The {{AI}} Pocket Book},
  author = {Maggiori, Emmanuel},
  date = {2025},
  edition = {First edition},
  publisher = {Manning Publications},
  location = {Shelter Island, NY},
  abstract = {Everything you need to know about AI to survive--and thrive--as an engineer. If you're worried about your tech career going obsolete in a world of super-powered AI, never fear. The AI Pocket Book crams everything engineers need to know about AI into one short volume you can fit into your pocket. You'll build a better understanding of AI (and its limitations), learn how to use it more effectively, and future-proof your job against its advancement. In The AI Pocket Book you'll find no-nonsense advice on: Deciphering AI jargon (there's lots of it!) Where AI fits within your field of engineering Why AI hallucinates--and what to do about it What to do when AI comes for your job The dark side of AI--copyright, snake oil, and replacing humans Balancing skepticism with unrealistic expectations The AI Pocket Book gives you Emmanuel Maggiori's unvarnished and opinionated take on where AI can be useful, and where it still kind of sucks. Whatever your tech field, this short-and-sweet guide delivers the facts and techniques you'll need in the workplace of the present. About the Technology You don't have to know everything about AI to get a big payoff! Whether you're looking to boost your coding speed, generate ideas for your next project, or just get a helping hand with your next Medium article, there's an AI-powered tool ready to assist. This fit-in-your pocket guide tells you everything you need to surf the AI wave instead of drowning in it. About the Book The AI Pocket Book takes a peek inside the AI black box and gives you just enough on key topics like transformers, hallucinations, and the modern ecosystem of AI models and tools. You'll get handy techniques to select AI tools, learn when putting AI first is the smart move, and pick up some excellent tips for managing the inevitable, potentially expensive, screw ups. What's Inside Deciphering AI jargon (there's lots of it!) Evaluating AI tools Why AI hallucinates and what to do about it How and when to use AI About the Reader For engineers in all fields, from software to security. About the Author Emmanuel Maggiori, PhD, is a software engineer and 10-year AI industry insider. He is also the author of Smart Until It's Dumb and Siliconned. Quotes Helps you profit from the AI revolution. - Toby Walsh, author of The Shortest History of AI Pragmatic and balanced. I strongly recommend it! - Zubin Pratap, Chainlink Labs Packs in a surprising amount of essential AI concepts. A perfect resource! - Riddhi Shah, Vicor Corporation Your practical guide to the future. - Meghana Puvvadi, NVIDIA},
  isbn = {978-1-63343-575-9},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/KRHRHH3U/Maggiori - 2025 - The AI pocket book.pdf}
}

@article{majewskiFamilyPerfectHashing1996,
  title = {A {{Family}} of {{Perfect Hashing Methods}}},
  author = {Majewski, B. S.},
  date = {1996-06-01},
  journaltitle = {The Computer Journal},
  shortjournal = {The Computer Journal},
  volume = {39},
  number = {6},
  pages = {547--554},
  issn = {0010-4620, 1460-2067},
  doi = {10.1093/comjnl/39.6.547},
  url = {https://academic.oup.com/comjnl/article-lookup/doi/10.1093/comjnl/39.6.547},
  urldate = {2025-12-04},
  abstract = {Minimal perfect hash functions are used for memory efficient storage and fast retrieval of items from static sets. We present an infinite family of efficient and practical algorithms for generating order preserving minimal perfect hash functions. We show that almost all members of the family construct space and time optimal order preserving minimal perfect hash functions, and we identify the one with minimum constants. Members of the family generate a hash function in two steps. First a special kind of function into an r−graph is computed probabilistically. Then this function is refined deterministically to a minimal perfect hash function. We give strong theoretical evidence that the first step uses linear random time. The second step runs in linear deterministic time. The family not only has theoretical importance, but also offers the fastest known method for generating perfect hash functions.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/DZNHWQ99/Majewski - 1996 - A Family of Perfect Hashing Methods.pdf}
}

@article{majewskiFamilyPerfectHashing1996a,
  title = {A {{Family}} of {{Perfect Hashing Methods}}},
  author = {Majewski, B. S.},
  date = {1996-06-01},
  journaltitle = {The Computer Journal},
  shortjournal = {The Computer Journal},
  volume = {39},
  number = {6},
  pages = {547--554},
  issn = {0010-4620, 1460-2067},
  doi = {10.1093/comjnl/39.6.547},
  url = {https://academic.oup.com/comjnl/article-lookup/doi/10.1093/comjnl/39.6.547},
  urldate = {2025-12-04},
  abstract = {Minimal perfect hash functions are used for memory efficient storage and fast retrieval of items from static sets. We present an infinite family of efficient and practical algorithms for generating order preserving minimal perfect hash functions. We show that almost all members of the family construct space and time optimal order preserving minimal perfect hash functions, and we identify the one with minimum constants. Members of the family generate a hash function in two steps. First a special kind of function into an r−graph is computed probabilistically. Then this function is refined deterministically to a minimal perfect hash function. We give strong theoretical evidence that the first step uses linear random time. The second step runs in linear deterministic time. The family not only has theoretical importance, but also offers the fastest known method for generating perfect hash functions.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/L4ZZSEXA/Majewski - 1996 - A Family of Perfect Hashing Methods.pdf}
}

@book{masisInterpretableMachineLearning2021,
  title = {Interpretable Machine Learning with {{Python}}: Learn to Build Interpretable High-Performance Models with Hands-on Real-World Examples},
  shorttitle = {Interpretable Machine Learning with {{Python}}},
  author = {Masís, Serg},
  date = {2021},
  publisher = {Packt},
  location = {Birmingham Mumbai},
  abstract = {Understand the key aspects and challenges of machine learning interpretability, learn how to overcome them with interpretation methods, and leverage them to build fairer, safer, and more reliable modelsKey FeaturesLearn how to extract easy-to-understand insights from any machine learning modelBecome well-versed with interpretability techniques to build fairer, safer, and more reliable modelsMitigate risks in AI systems before they have broader implications by learning how to debug black-box modelsBook DescriptionDo you want to understand your models and mitigate risks associated with poor predictions using machine learning (ML) interpretation? Interpretable Machine Learning with Python can help you work effectively with ML models. The first section of the book is a beginner's guide to interpretability, covering its relevance in business and exploring its key aspects and challenges. You'll focus on how white-box models work, compare them to black-box and glass-box models, and examine their trade-off. The second section will get you up to speed with a vast array of interpretation methods, also known as Explainable AI (XAI) methods, and how to apply them to different use cases, be it for classification or regression, for tabular, time-series, image or text. In addition to the step-by-step code, the book also helps the reader to interpret model outcomes using examples. In the third section, you'll get hands-on with tuning models and training data for interpretability by reducing complexity, mitigating bias, placing guardrails, and enhancing reliability. The methods you'll explore here range from state-of-the-art feature selection and dataset debiasing methods to monotonic constraints and adversarial retraining. By the end of this book, you'll be able to understand ML models better and enhance them through interpretability tuning. What you will learnRecognize the importance of interpretability in businessStudy models that are intrinsically interpretable such as linear models, decision trees, and Naive BayesBecome well-versed in interpreting models with model-agnostic methodsVisualize how an image classifier works and what it learnsUnderstand how to mitigate the influence of bias in datasetsDiscover how to make models more reliable with adversarial robustnessUse monotonic constraints to make fairer and safer modelsWho this book is forThis book is for data scientists, machine learning developers, and data stewards who have an increasingly critical responsibility to explain how the AI systems they develop work, their impact on decision making, and how they identify and manage bias. Working knowledge of machine learning and the Python programming language is expected},
  isbn = {978-1-80020-390-7 978-1-80020-657-1},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/ZPPE4F96/Masís - 2021 - Interpretable machine learning with Python learn to build interpretable high-performance models wit.pdf}
}

@book{mathaiLinearAlgebraCourse2017,
  title = {Linear {{Algebra}}: {{A Course}} for {{Physicists}} and {{Engineers}}},
  shorttitle = {Linear {{Algebra}}},
  author = {Mathai, Arakaparampil M. and Haubold, Hans J.},
  date = {2017},
  series = {De {{Gruyter Textbook}}},
  publisher = {De Gruyter},
  location = {Berlin/Boston},
  abstract = {In order not to intimidate students by a too abstract approach, this textbook on linear algebra is written to be easy to digest by non-mathematicians. It is also designed such that no other material is required for an understanding of the topics covered. As the basis for courses on space and atmospheric science, remote sensing, and satellite communications, applications of the formal theory in physics and engineering are discussed as well},
  isbn = {978-3-11-056235-4 978-3-11-056250-7 978-3-11-056259-0},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/Zotero/storage/2YMDHGEF/Mathai und Haubold - Linear Algebra - A Course for Physicists and Engineers.pdf}
}

@book{mauroZeroAINontechnical2020,
  title = {Zero to {{AI}}: A Non-Technical, Hype-Free Manual on How to Prosper in the {{AI}} Era},
  shorttitle = {Zero to {{AI}}},
  author = {Mauro, Gianluca and Valigi, Nicolò},
  date = {2020},
  publisher = {Manning Publications},
  location = {Shelter Island, NY},
  abstract = {Zero to AI uses clear examples and jargon-free explanations to show the practical benefits of AI. Each chapter explores a real-world case study demonstrating how companies like Google and Netflix use AI to shape their industries. You begin at the beginning, with a primer on core AI concepts and realistic business outcomes. To help you prepare for the transition, the book breaks down a successful AI implementation, including advice on hiring the right team and making decisions about resources, risks, and costs},
  isbn = {978-1-61729-606-2},
  langid = {english},
  annotation = {OCLC: 1114577157},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/IF2HLS57/Mauro und Valigi - 2020 - Zero to AI a non-technical, hype-free manual on how to prosper in the AI era.pdf}
}

@book{mcmahonMachineLearningEngineering2021,
  title = {Machine {{Learning Engineering}} with {{Python}}: {{Manage}} the Production Life Cycle of Machine Learning Models Using {{MLOps}} with Practical Examples},
  shorttitle = {Machine {{Learning Engineering}} with {{Python}}},
  author = {McMahon, Andrew P.},
  date = {2021},
  edition = {1},
  publisher = {Packt Publishing Limited},
  location = {Birmingham},
  abstract = {bSupercharge the value of your machine learning models by building scalable and robust solutions that can serve them in production environments/bh4Key Features/h4ulliExplore hyperparameter optimization and model management tools/liliLearn object-oriented programming and functional programming in Python to build your own ML libraries and packages/liliExplore key ML engineering patterns like microservices and the Extract Transform Machine Learn (ETML) pattern with use cases/li/ulh4Book Description/h4Machine learning engineering is a thriving discipline at the interface of software development and machine learning. This book will help developers working with machine learning and Python to put their knowledge to work and create high-quality machine learning products and services. Machine Learning Engineering with Python takes a hands-on approach to help you get to grips with essential technical concepts, implementation patterns, and development methodologies to have you up and running in no time. You'll begin by understanding key steps of the machine learning development life cycle before moving on to practical illustrations and getting to grips with building and deploying robust machine learning solutions. As you advance, you'll explore how to create your own toolsets for training and deployment across all your projects in a consistent way. The book will also help you get hands-on with deployment architectures and discover methods for scaling up your solutions while building a solid understanding of how to use cloud-based tools effectively. Finally, you'll work through examples to help you solve typical business problems. By the end of this book, you'll be able to build end-to-end machine learning services using a variety of techniques and design your own processes for consistently performant machine learning engineering.h4What you will learn/h4ulliFind out what an effective ML engineering process looks like/liliUncover options for automating training and deployment and learn how to use them/liliDiscover how to build your own wrapper libraries for encapsulating your data science and machine learning logic and solutions/liliUnderstand what aspects of software engineering you can bring to machine learning/liliGain insights into adapting software engineering for machine learning using appropriate cloud technologies/liliPerform hyperparameter tuning in a relatively automated way/li/ulh4Who this book is for/h4This book is for machine learning engineers, data scientists, and software developers who want to build robust software solutions with machine learning components. If you're someone who manages or wants to understand the production life cycle of these systems, you'll find this book useful. Intermediate-level knowledge of Python is necessary},
  isbn = {978-1-80107-925-9 978-1-80107-710-1},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/J65BNP3A/McMahon - 2021 - Machine Learning Engineering with Python Manage the production life cycle of machine learning model.pdf}
}

@book{meleDjango3Example2020,
  title = {Django 3 by Example: Build Powerful and Reliable {{Python}} Web Applications from Scratch, Third Edition},
  shorttitle = {Django 3 by Example},
  author = {Melé, Antonio},
  date = {2020},
  edition = {3rd ed},
  publisher = {Packt Publishing},
  location = {Place of publication not identified},
  abstract = {If you want to learn the entire process of developing professional web applications with Python and Django, then this book is for you. In the process of building four professional Django projects, you will learn about Django 3 features, how to solve common web development problems, how to implement best practices, and how to successfully deploy your applications. In this book, you will build a blog application, a social image bookmarking website, an online shop, and an e-learning platform. Step-by-step guidance will teach you how to integrate popular technologies, enhance your applications with AJAX, create RESTful APIs, and set up a production environment for your Django projects. By the end of this book, you will have mastered Django 3 by building advanced web applications},
  isbn = {978-1-83898-195-2 978-1-83898-932-3},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/FIDEZ87Q/Melé - 2020 - Django 3 by example build powerful and reliable Python web applications from scratch, third edition.pdf}
}

@book{mertzRegularExpressionPuzzles2023,
  title = {Regular Expression Puzzles and {{AI}} Coding Assistants: 24 Puzzles Solved by the Author, with and without Assistance from {{Copilot}}, {{ChatGPT}} and More},
  shorttitle = {Regular Expression Puzzles and {{AI}} Coding Assistants},
  author = {Mertz, David Q.},
  date = {2023},
  publisher = {Manning},
  location = {Shelter Island, NY},
  isbn = {978-1-63343-781-4},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/JWBB2UYU/Mertz - 2023 - Regular expression puzzles and AI coding assistants 24 puzzles solved by the author, with and witho.pdf}
}

@article{millerFileComparisonProgram1985,
  title = {A File Comparison Program},
  author = {Miller, Webb and Myers, Eugene W.},
  date = {1985-11},
  journaltitle = {Software: Practice and Experience},
  shortjournal = {Softw Pract Exp},
  volume = {15},
  number = {11},
  pages = {1025--1040},
  issn = {0038-0644, 1097-024X},
  doi = {10.1002/spe.4380151102},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/spe.4380151102},
  urldate = {2025-12-04},
  abstract = {This paper presents a simple method for computing a shortest sequence of insertion and deletion commands that converts one given file to another. The method is particularly efficient when the difference between the two files is small compared to the files' lengths. In experimentsperformed on typical files, the program often ran four times faster than the UNIX diff command.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/H828BCFJ/Miller und Myers - 1985 - A file comparison program.pdf}
}

@book{molinaCraftingTestdrivenSoftware2021,
  title = {Crafting Test-Driven Software with Python: Write Test Suites That Scale with Your Applications' Needs and Complexity Using {{Python}} and {{PyTest}}},
  shorttitle = {Crafting Test-Driven Software with Python},
  author = {Molina, Alessandro},
  date = {2021},
  publisher = {Packt Publishing},
  location = {Place of publication not identified},
  abstract = {Test-driven development (TDD) is a set of best practices that helps developers to build more scalable software and is used to increase the robustness of software by using automatic tests. This book shows you how to apply TDD practices effectively in Python projects. You'll begin by learning about built-in unit tests and Mocks before covering rich frameworks like PyTest and web-based libraries such as WebTest and Robot Framework, discovering how Python allows you to embrace all modern testing practices with ease. Moving on, you'll find out how to design tests and balance them with new feature development and learn how to create a complete test suite with PyTest. The book helps you adopt a hands-on approach to implementing TDD and associated methodologies that will have you up and running and make you more productive in no time. With the help of step-by-step explanations of essential concepts and practical examples, you'll explore automatic tests and TDD best practices and get to grips with the methodologies and tools available in Python for creating effective and robust applications. By the end of this Python book, you will be able to write reliable test suites in Python to ensure the long-term resilience of your application using the range of libraries offered by Python for testing and development. What you will learn Find out how tests can make your life easier as a developer and discover related best practices Explore PyTest, the most widespread testing framework for Python Get to grips with the most common PyTest plugins, including coverage, flaky, xdist, and picked Write functional tests for WSGI web applications with WebTest Run end-to-end tests for web applications using Robot Framework Understand what test-driven development means and why it is important Discover how to use the range of tools available in Python Build reliable and robust applications Who this book is for This book is for Python developers looking to get started with test-driven development and developers who want to learn about the testing tools available in Python. Developers who want to create web applications with Python and plan to implement TDD methodology with PyTest will find this book useful. Basic knowledge of Python programming is required},
  isbn = {978-1-83864-265-5 978-1-83864-391-1},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/DU5ISE2V/Molina - 2021 - Crafting test-driven software with python write test suites that scale with your applications' need.pdf}
}

@book{molinHandsonDataAnalysis2021,
  title = {Hands-on Data Analysis with Pandas: A {{Python}} Data Science Handbook for Data Collection, Wrangling, Analysis, and Visualization},
  shorttitle = {Hands-on Data Analysis with Pandas},
  author = {Molin, Stefanie and Jee, Ken},
  namea = {Mavromoustaki, Aliki},
  nameatype = {collaborator},
  date = {2021},
  edition = {Second edition},
  publisher = {Packt{$>$}},
  location = {Birmingham Mumbai},
  isbn = {978-1-80056-345-2},
  langid = {english},
  pagetotal = {764},
  keywords = {Lesen},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/JNRZY8SQ/Molin und Jee - 2021 - Hands-on data analysis with pandas a Python data science handbook for data collection, wrangling, a.pdf}
}

@book{morganCodingAIExamples2025,
  title = {Coding with {{AI}}: {{Examples}} in {{Python}}},
  shorttitle = {Coding with {{AI}}},
  author = {Morgan, Jeremy},
  date = {2025},
  edition = {1st ed},
  publisher = {Manning Publications Co. LLC},
  location = {New York},
  abstract = {Practical techniques to accelerate software development using generative AI.Let's get real.You'd like to hand off a lot of tedious software development tasks to an assistant--and now you can!AI-powered coding tools like Copilot can accelerate research, design, code creation, testing, troubleshooting, documentation, refactoring and more},
  isbn = {978-1-63343-727-2 978-1-63835-774-2},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/8W2JP5LK/Morgan - 2025 - Coding with AI Examples in Python.pdf}
}

@inproceedings{moscoviciGPUFriendlySkiplistAlgorithm2017,
  title = {A {{GPU-Friendly Skiplist Algorithm}}},
  booktitle = {2017 26th {{International Conference}} on {{Parallel Architectures}} and {{Compilation Techniques}} ({{PACT}})},
  author = {Moscovici, Nurit and Cohen, Nachshon and Petrank, Erez},
  date = {2017-09},
  pages = {246--259},
  publisher = {IEEE},
  location = {Portland, OR},
  doi = {10.1109/PACT.2017.13},
  url = {http://ieeexplore.ieee.org/document/8091249/},
  urldate = {2025-12-04},
  abstract = {We propose a design for a fine-grained lockbased skiplist optimized for Graphics Processing Units (GPUs). While GPUs are often used to accelerate streaming parallel computations, it remains a significant challenge to efficiently offload concurrent computations with more complicated datairregular access and fine-grained synchronization. Natural building blocks for such computations would be concurrent data structures, such as skiplists, which are widely used in general purpose computations. Our design utilizes array-based nodes which are accessed and updated by warp-cooperative functions, thus taking advantage of the fact that GPUs are most efficient when memory accesses are coalesced and execution divergence is minimized. The proposed design has been implemented, and measurements demonstrate improved performance of up to 11.6x over skiplist designs for the GPU existing today.},
  eventtitle = {2017 26th {{International Conference}} on {{Parallel Architectures}} and {{Compilation Techniques}} ({{PACT}})},
  isbn = {978-1-5090-6764-0},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/3SQFX7RV/Moscovici et al. - 2017 - A GPU-Friendly Skiplist Algorithm.pdf}
}

@dataset{mullerAdaptiveStringDictionary2014,
  title = {Adaptive {{String Dictionary Compression}} in {{In-Memory Column-Store Database Systems}}},
  author = {Müller, Ingo and Ratsch, Cornelius and Färber, Franz},
  date = {2014},
  publisher = {OpenProceedings.org},
  doi = {10.5441/002/EDBT.2014.27},
  url = {https://openproceedings.org/EDBT/2014/paper_25.pdf},
  urldate = {2025-12-07},
  abstract = {Domain encoding is a common technique to compress the columns of a column store and to accelerate many types of queries at the same time. It is based on the assumption that most columns contain a relatively small set of distinct values, in particular string columns. In this paper, we argue that domain encoding is not the end of the story. In real world systems, we observe that a substantial amount of the columns are of string types. Moreover, most of the memory space is consumed by only a small fraction of these columns.},
  langid = {english},
  keywords = {Database Systems,Database Technology},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/Q6BL4Y9S/Müller et al. - 2014 - Adaptive String Dictionary Compression in In-Memory Column-Store Database Systems.pdf}
}

@misc{nageshCS725FoundationsMachine2011,
  title = {{{CS725}} : {{Foundations}} of {{Machine}} Learning - {{Lecture Notes}}},
  author = {Nagesh, Ajay},
  date = {2011-07-26},
  langid = {english},
  organization = {Indian Institute of Technology, Bombay},
  file = {/Users/bernhardgerlach/Zotero/storage/FFM4FPS8/Nagesh - 2011 - CS725  Foundations of Machine learning - Lecture Notes.pdf}
}

@book{navlaniPythonDataAnalysis2021,
  title = {Python Data Analysis: Perform Data Collection, Data Processing, Wrangling, Visualization, and Model Building Using {{Python}}},
  shorttitle = {Python Data Analysis},
  author = {Navlani, Avinash and Fandango, Armando and Idris, Ivan},
  date = {2021},
  edition = {Third edition},
  publisher = {Packt},
  location = {Birmingham Mumbai},
  abstract = {Data analysis enables you to generate value from small and big data by discovering new patterns and trends, and Python is one of the most popular tools for analyzing a wide variety of data. With this book, you’ll get up and running using Python for data analysis by exploring the different phases and methodologies used in data analysis and learning how to use modern libraries from the Python ecosystem to create efficient data pipelines. Starting with the essential statistical and data analysis fundamentals using Python, you’ll perform complex data analysis and modeling, data manipulation, data cleaning, and data visualization using easy-to-follow examples. You’ll then understand how to conduct time series analysis and signal processing using ARMA models. As you advance, you’ll get to grips with smart processing and data analytics using machine learning algorithms such as regression, classification, Principal Component Analysis (PCA), and clustering. In the concluding chapters, you’ll work on real-world examples to analyze textual and image data using natural language processing (NLP) and image analytics techniques, respectively. Finally, the book will demonstrate parallel computing using Dask. By the end of this data analysis book, you’ll be equipped with the skills you need to prepare data for analysis and create meaningful data visualizations for forecasting values from data},
  isbn = {978-1-78995-524-8 978-1-78995-345-9},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/MT27IFNC/Navlani et al. - 2021 - Python data analysis perform data collection, data processing, wrangling, visualization, and model.pdf}
}

@book{neerajsharmaDatabaseFundamentals2010,
  title = {Database {{Fundamentals}}},
  author = {{Neeraj Sharma} and {Liviu Perniu} and {Raul F. Chong} and {Abhishek Iyer} and {Adi-Cristina Mitea} and {Chaitali Nandan} and {Mallarswami Nonvinkere} and {Mirela Danubianu}},
  date = {2010-11},
  publisher = {IBM Corporation},
  isbn = {n/a},
  langid = {english},
  pagetotal = {282},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/PL7ANDG8/Database Fundamentals.pdf}
}

@book{neidingerPythonNetworkProgramming2021,
  title = {Python Network Programming Techniques: 50 Real-World Recipes to Automate Infrastructure Networks and Overcome Networking Challenges with {{Python}}},
  shorttitle = {Python Network Programming Techniques},
  author = {Neidinger, Marcel},
  date = {2021},
  publisher = {Packt Publishing},
  location = {Place of publication not identified},
  abstract = {Network automation offers a powerful new way of changing your infrastructure network. Gone are the days of manually logging on to different devices to type the same configuration commands over and over again. With this book, you'll find out how you can automate your network infrastructure using Python. You'll get started on your network automation journey with a hands-on introduction to the network programming basics to complement your infrastructure knowledge. You'll learn how to tackle different aspects of network automation using Python programming and a variety of open source libraries. In the book, you'll learn everything from templating, testing, and deploying your configuration on a device-by-device basis to using high-level REST APIs to manage your cloud-based infrastructure. Finally, you'll see how to automate network security with Cisco's Firepower APIs. By the end of this Python network programming book, you'll have not only gained a holistic overview of the different methods to automate the configuration and maintenance of network devices, but also learned how to automate simple to complex networking tasks and overcome common network programming challenges},
  isbn = {978-1-83864-663-9 978-1-83864-047-7},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/GED54EKF/Neidinger - 2021 - Python network programming techniques 50 real-world recipes to automate infrastructure networks and.pdf}
}

@book{nenkovaAutomaticSummarization2011,
  title = {Automatic Summarization},
  author = {Nenkova, Ani and McKeown, Kathleen},
  date = {2011},
  series = {Foundations and Trends in Information Retrieval},
  number = {2011.5,2/3},
  publisher = {Now},
  location = {Boston, Mass},
  isbn = {978-1-60198-470-8},
  langid = {english},
  pagetotal = {134},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/5GCQLMGJ/Nenkova und McKeown - 2011 - Automatic summarization.pdf}
}

@book{nessCausalAI2025,
  title = {Causal {{AI}}},
  author = {Ness, Robert Osazuwa},
  date = {2025},
  publisher = {Manning},
  location = {Erscheinungsort nicht ermittelbar},
  abstract = {Build AI models that can reliably deliver causal inference. How do you know what might have happened, had you done things differently? Causal AI gives you the insight you need to make predictions and control outcomes based on causal relationships instead of pure correlation, so you can make precise and timely interventions. Causal AI is a practical introduction to building AI models that can reason about causality. In Causal AI you will learn how to: • Build causal reinforcement learning algorithms • Implement causal inference with modern probabilistic machine tools such as PyTorch and Pyro • Compare and contrast statistical and econometric methods for causal inference • Set up algorithms for attribution, credit assignment, and explanation • Convert domain expertise into explainable causal models Author Robert Osazuwa Ness, a leading researcher in causal AI at Microsoft Research, brings his unique expertise to this cutting-edge guide. His clear, code-first approach explains essential details of causal machine learning that are hidden in academic papers. Everything you learn can be easily and effectively applied to industry challenges, from building explainable causal models to predicting counterfactual outcomes. Foreword by Lindsay Edwards. About the technology Traditional ML models can't answer causal questions like, "Why did that happen?" or, "What factors should I change to get a particular outcome?" This book blends advanced statistical methods, computational techniques, and new algorithms to create machine learning systems that automate the process of causal inference. About the book Causal AI introduces the tools, techniques, and algorithms of causal reasoning for machine learning. This unique book masterfully blends Bayesian and probabilistic approaches to causal inference with practical hands-on examples in Python. Along the way, you'll learn to integrate causal assumptions into deep learning architectures, including reinforcement learning and large language models. You'll also use PyTorch, Pyro, and other ML libraries to scale up causal inference. What's inside • End-to-end causal inference with DoWhy • Deep Bayesian causal generative AI models • A code-first tour of the do-calculus and Pearl's causal hierarchy • Code for fine-tuning causal large language models About the reader For data scientists and machine learning engineers. Examples in Python. About the author Robert Osazuwa Ness is an AI researcher at Microsoft Research and professor at Northeastern University. He is a contributor to open-source causal inference packages such as Python's DoWhy and R's bnlearn. Table of Contents Part 1 1 Why causal AI 2 A primer on probabilistic generative modeling Part 2 3 Building a causal graphical model 4 Testing the DAG with causal constraints 5 Connecting causality and deep learning Part 3 6 Structural causal models 7 Interventions and causal effects 8 Counterfactuals and parallel worlds 9 The general counterfactual inference algorithm 10 Identification and the causal hierarchy Part 4 11 Building a causal inference workflow 12 Causal decisions and reinforcement learning 13 Causality and large language models},
  isbn = {978-1-63343-991-7 978-1-63835-734-6},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/HFQR4H5Y/Ness - 2025 - Causal AI.pdf}
}

@inproceedings{neylonLocalitysensitiveHashReal2010,
  title = {A Locality-Sensitive Hash for Real Vectors},
  booktitle = {Proceedings of the {{Twenty-First Annual ACM-SIAM Symposium}} on {{Discrete Algorithms}}},
  author = {Neylon, Tyler},
  date = {2010-01-17},
  pages = {1179--1189},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9781611973075.94},
  url = {https://epubs.siam.org/doi/10.1137/1.9781611973075.94},
  urldate = {2025-12-05},
  abstract = {We present a simple and practical algorithm for the c−approximate near neighbor problem (c−NN): given n points P ⊂ Rd and radius R, build a data structure which, given q ∈ Rd, can with probability 1 − δ return a point p ∈ P with dist(p, q) ≤ cR if there is any p∗ ∈ P with dist(p∗, q) ≤ R. For c = d + 1, our algorithm deterministically (δ = 0) preprocesses in time O(nd log d), space O(dn), and answers queries in expected time O(d2); this is the first known algorithm to deterministically guarantee an O(d)−NN solution in constant time with respect to n for all `p metrics. A probabilistic version empirically achieves useful c values (c {$<$} 2) where c appears to grow minimally as d → ∞. A query time of O(d log d) is available, providing slightly less accuracy. These techniques can also be used to approximately find (pointers between) all pairs x, y ∈ P with dist(x, y) ≤ R in time O(nd log d). The key to the algorithm is a locality-sensitive hash: a mapping h : Rd → U with the property that h(x) = h(y) is much more likely for nearby x, y. We introduce a somewhat regular simplex which tessellates Rd, and efficiently hash each point in any simplex of this tessellation to all d + 1 corners; any points in neighboring cells will be hashed to a shared corner and noticed as nearby points. This method is completely independent of dimension reduction, so that additional space and time savings are available by first reducing all input vectors.},
  eventtitle = {Proceedings of the {{Twenty-First Annual ACM-SIAM Symposium}} on {{Discrete Algorithms}}},
  isbn = {978-0-89871-701-3 978-1-61197-307-5},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/5B9CABYC/Neylon - 2010 - A locality-sensitive hash for real vectors.pdf}
}

@article{nogueiranunesCompressedSuffixTree2014,
  title = {A {{Compressed Suffix Tree Based Implementation With Low Peak Memory Usage}}},
  author = {Nogueira Nunes, Daniel Saad and Ayala-Rincón, Mauricio},
  date = {2014-02},
  journaltitle = {Electronic Notes in Theoretical Computer Science},
  shortjournal = {Electronic Notes in Theoretical Computer Science},
  volume = {302},
  pages = {73--94},
  issn = {15710661},
  doi = {10.1016/j.entcs.2014.01.021},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S157106611400022X},
  urldate = {2025-12-04},
  abstract = {Suffix trees (ST s) and suffix arrays are well known indices which demand too much space for large inputs. Recently, several works explore a data structure called compressed suffix tree (CST ), which offers the same functionality than suffix trees and is based on compressed suffix arrays, compressed longest common prefix information and navigational operations. In this paper, the implementation of a CST based on rangeminimum-queries and nearest smaller value queries, which requires roughly more than the space needed to represent the index during the construction, is presented. Experiments show that this index is useful for many applications since, on the one side, one can execute complex traversals such as suffix links and longest common ancestor queries that are essential to deal with several questions about the combinatorial structure of sequences; and, on the other side, the structure results of practical interest for applications using computational environments in which the amount of available memory is restricted, because it fits in main memory of ordinary computers.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/SNU9KRQW/Nogueira Nunes und Ayala-Rincón - 2014 - A Compressed Suffix Tree Based Implementation With Low Peak Memory Usage.pdf}
}

@book{norlenQuantumComputingPractice2020,
  title = {Quantum Computing in Practice with {{Qiskit}}® and {{IBM Quantum Experience}}®: Practical Recipes for Quantum Computer Coding at the Gate and Algorithm Level with {{Python}}},
  shorttitle = {Quantum Computing in Practice with {{Qiskit}}® and {{IBM Quantum Experience}}®},
  author = {Norlén, Hassi},
  date = {2020},
  publisher = {Packt Publishing},
  location = {Place of publication not identified},
  abstract = {This book is a recipe-based guide for developers interested in programming quantum computers with IBM Quantum (R) Experience and Qiskit (R). You'll learn all the concepts and components of Qiskit that you need for programming quantum computers, from visualizing circuits and gates with Qiskit Terra and simulating realistic noise profiles with Qiskit},
  isbn = {978-1-83882-844-8 978-1-83882-103-6},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/2VRHJ58T/Norlén - 2020 - Quantum computing in practice with Qiskit® and IBM Quantum Experience® practical recipes for quantu.pdf}
}

@inproceedings{openaiGPT4TechnicalReport2023,
  title = {{{GPT-4 Technical Report}}},
  shorttitle = {{{OpenAI}} (2023)},
  author = {{OpenAI}},
  date = {2023},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/TFYM454F/GPT-4 Technical Report.pdf}
}

@article{paghHashDisplaceEfficient,
  title = {Hash and {{Displace}}: {{Efficient Evaluation}} of {{Minimal Perfect Hash Functions}}},
  author = {Pagh, Rasmus},
  abstract = {A new way of constructing (minimal) perfect hash functions is described. The technique considerably reduces the overhead associated with resolving buckets in two-level hashing schemes. Evaluating a hash function requires just one multiplication and a few additions apart from primitive bit operations. The number of accesses to memory is two, one of which is to a fixed location. This improves the probe performance of previous minimal perfect hashing schemes, and is shown to be optimal. The hash function description (“program”) for a set of size n occupies O(n) words, and can be constructed in expected O(n) time.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/87BRYKXJ/Pagh - Hash and Displace Efficient Evaluation of Minimal Perfect Hash Functions.pdf}
}

@online{pandeyFastX86Implementation2017,
  title = {A {{Fast}} X86 {{Implementation}} of {{Select}}},
  author = {Pandey, Prashant and Bender, Michael A. and Johnson, Rob},
  date = {2017-06-03},
  eprint = {1706.00990},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1706.00990},
  url = {http://arxiv.org/abs/1706.00990},
  urldate = {2025-12-04},
  abstract = {Rank and select are fundamental operations in succinct data structures, that is, data structures whose space consumption approaches the information-theoretic optimal. The performance of these primitives is central to the overall performance of succinct data structures.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Data Structures and Algorithms},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/W32H3FWR/Pandey et al. - 2017 - A Fast x86 Implementation of Select.pdf}
}

@online{panigrahyEfficientHashingLookups2004,
  title = {Efficient {{Hashing}} with {{Lookups}} in Two {{Memory Accesses}}},
  author = {Panigrahy, Rina},
  date = {2004-07-09},
  eprint = {cs/0407023},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.cs/0407023},
  url = {http://arxiv.org/abs/cs/0407023},
  urldate = {2025-12-04},
  abstract = {The study of hashing is closely related to the analysis of balls and bins. It is well-known that instead of using a single hash function if we randomly hash a ball into two bins and place it in the smaller of the two, then this dramatically lowers the maximum load on bins. This leads to the concept of two-way hashing where the largest bucket contains \$O(\textbackslash log\textbackslash log n)\$ balls with high probability. The hash look up will now search in both the buckets an item hashes to. Since an item may be placed in one of two buckets, we could potentially move an item after it has been initially placed to reduce maximum load. with a maximum load of We show that by performing moves during inserts, a maximum load of 2 can be maintained on-line, with high probability, while supporting hash update operations. In fact, with \$n\$ buckets, even if the space for two items are pre-allocated per bucket, as may be desirable in hardware implementations, more than \$n\$ items can be stored giving a high memory utilization. We also analyze the trade-off between the number of moves performed during inserts and the maximum load on a bucket. By performing at most \$h\$ moves, we can maintain a maximum load of \$O(\textbackslash frac\{\textbackslash log \textbackslash log n\}\{h \textbackslash log(\textbackslash log\textbackslash log n/h)\})\$. So, even by performing one move, we achieve a better bound than by performing no moves at all.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Data Structures and Algorithms},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/DGVBVSW4/Panigrahy - 2004 - Efficient Hashing with Lookups in two Memory Accesses.pdf}
}

@online{patelProbabilisticTheoryDeep2015,
  title = {A {{Probabilistic Theory}} of {{Deep Learning}}},
  author = {Patel, Ankit B. and Nguyen, Tan and Baraniuk, Richard G.},
  date = {2015-04-02},
  eprint = {1504.00641},
  eprinttype = {arXiv},
  eprintclass = {stat},
  doi = {10.48550/arXiv.1504.00641},
  url = {http://arxiv.org/abs/1504.00641},
  urldate = {2025-12-05},
  abstract = {A grand challenge in machine learning is the development of computational algorithms that match or outperform humans in perceptual inference tasks that are complicated by nuisance variation. For instance, visual object recognition involves the unknown object position, orientation, and scale in object recognition while speech recognition involves the unknown voice pronunciation, pitch, and speed. Recently, a new breed of deep learning algorithms have emerged for high-nuisance inference tasks that routinely yield pattern recognition systems with near- or super-human capabilities. But a fundamental question remains: Why do they work? Intuitions abound, but a coherent framework for understanding, analyzing, and synthesizing deep learning architectures has remained elusive. We answer this question by developing a new probabilistic framework for deep learning based on the Deep Rendering Model: a generative probabilistic model that explicitly captures latent nuisance variation. By relaxing the generative model to a discriminative one, we can recover two of the current leading deep learning systems, deep convolutional neural networks and random decision forests, providing insights into their successes and shortcomings, as well as a principled route to their improvement.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/Q25AP8M5/Patel et al. - 2015 - A Probabilistic Theory of Deep Learning.pdf}
}

@book{pearsonDigitalWorkSnapshots1992,
  title = {Digital at Work: Snapshots from the First Thirty-Five Years},
  shorttitle = {Digital at Work},
  editor = {Pearson, Jamie Parker},
  date = {1992},
  publisher = {Digital Press},
  location = {Burlington, Mass},
  isbn = {978-1-55558-092-6},
  langid = {english},
  pagetotal = {212},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/8K6V6ZJZ/Digital at Work (1992).pdf}
}

@book{peixeiroTimeSeriesForecasting2026,
  title = {Time Series Forecasting Using Foundation Models},
  author = {Peixeiro, Marco},
  date = {2026},
  edition = {[First edition]},
  publisher = {Manning Publications},
  location = {Shelter Island, New York},
  abstract = {Make accurate time series predictions with powerful pretrained foundation models! You don't need to spend weeks--or even months--coding and training your own models for time series forecasting. Time Series Forecasting Using Foundation Models shows you how to make accurate predictions using flexible pretrained models. In Time Series Forecasting Using Foundation Models you will discover: The inner workings of large time models Zero-shot forecasting on custom datasets Fine-tuning foundation forecasting models Evaluating large time models Time Series Forecasting Using Foundation Models teaches you how to do efficient forecasting using powerful time series models that have already been pretrained on billions of data points. You'll appreciate the hands-on examples that show you what you can accomplish with these amazing models. Along the way, you'll learn how time series foundation models work, how to fine-tune them, and how to use them with your own data. About the Technology Time-series forecasting is the art of analyzing historical, time-stamped data to predict future outcomes. Foundational time series models like TimeGPT and Chronos, pre-trained on billions of data points, can now effectively augment or replace painstakingly-built custom time-series models. About the Book Time Series Forecasting Using Foundation Models explores the architecture of large time models and shows you how to use them to generate fast, accurate predictions. You'll learn to fine-tune time models on your own data, execute zero-shot probabilistic forecasting, point forecasting, and more. You'll even find out how to reprogram an LLM into a time series forecaster--all following examples that will run on an ordinary laptop. What's Inside How large time models work Zero-shot forecasting on custom datasets Fine-tuning and evaluating foundation models About the Reader For data scientists and machine learning engineers familiar with the basics of time series forecasting theory. Examples in Python. About the Author Marco Peixeiro builds cutting-edge open-source forecasting Python libraries at Nixtla. He is the author of Time Series Forecasting in Python. Quotes Clear and hands-on, featuring both theory and easy-to-follow examples. - Eryk Lewinson, Author of Python for Finance Cookbook Bridges the gap between classical forecasting methods and the new developments in the foundational models. A fantastic resource. - Juan Orduz, PyMC Labs A foundational guide to forecasting's next chapter. - Tyler Blume, daybreak An immensely practical introduction to forecasting using foundation models. - Stephan Kolassa, SAP Switzerland},
  isbn = {978-1-63343-589-6},
  langid = {english},
  annotation = {OCLC: 1553739731},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/664Y3C9P/Peixeiro - 2026 - Time series forecasting using foundation models.pdf}
}

@online{pekhimenkoPracticalDataCompression2016,
  title = {Practical {{Data Compression}} for {{Modern Memory Hierarchies}}},
  author = {Pekhimenko, Gennady},
  date = {2016-09-07},
  eprint = {1609.02067},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1609.02067},
  url = {http://arxiv.org/abs/1609.02067},
  urldate = {2025-12-07},
  abstract = {In this thesis, we describe a new, practical approach to integrating hardware-based data compression within the memory hierarchy, including on-chip caches, main memory, and both on-chip and off-chip interconnects. This new approach is fast, simple, and effective in saving storage space. A key insight in our approach is that access time (including decompression latency) is critical in modern memory hierarchies. By combining inexpensive hardware support with modest OS support, our holistic approach to compression achieves substantial improvements in performance and energy efficiency across the memory hierarchy. Using this new approach, we make several major contributions in this thesis. First, we propose a new compression algorithm, Base-Delta-Immediate Compression (BDI), that achieves high compression ratio with very low compression/decompression latency. BDI exploits the existing low dynamic range of values present in many cache lines to compress them to smaller sizes using Base+Delta encoding. Second, we observe that the compressed size of a cache block can be indicative of its reuse. We use this observation to develop a new cache insertion policy for compressed caches, the Size-based Insertion Policy (SIP), which uses the size of a compressed block as one of the metrics to predict its potential future reuse. Third, we propose a new main memory compression framework, Linearly Compressed Pages (LCP), that significantly reduces the complexity and power cost of supporting main memory compression. We demonstrate that any compression algorithm can be adapted to fit the requirements of LCP, and that LCP can be efficiently integrated with the existing cache compression designs, avoiding extra compression/decompression.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Hardware Architecture,Computer Science - Operating Systems},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/BF2BNVIT/Pekhimenko - 2016 - Practical Data Compression for Modern Memory Hierarchies.pdf}
}

@inproceedings{pesterevImprovingNetworkConnection2012,
  title = {Improving Network Connection Locality on Multicore Systems},
  booktitle = {Proceedings of the 7th {{ACM}} European Conference on {{Computer Systems}}},
  author = {Pesterev, Aleksey and Strauss, Jacob and Zeldovich, Nickolai and Morris, Robert T.},
  date = {2012-04-10},
  pages = {337--350},
  publisher = {ACM},
  location = {Bern Switzerland},
  doi = {10.1145/2168836.2168870},
  url = {https://dl.acm.org/doi/10.1145/2168836.2168870},
  urldate = {2025-12-07},
  abstract = {Incoming and outgoing processing for a given TCP connection often execute on different cores: an incoming packet is typically processed on the core that receives the interrupt, while outgoing data processing occurs on the core running the relevant user code. As a result, accesses to read/write connection state (such as TCP control blocks) often involve cache invalidations and data movement between cores’ caches. These can take hundreds of processor cycles, enough to significantly reduce performance.},
  eventtitle = {{{EuroSys}} '12: {{Seventh EuroSys Conference}} 2012},
  isbn = {978-1-4503-1223-3},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/M6BSAN9F/Pesterev et al. - 2012 - Improving network connection locality on multicore systems.pdf}
}

@online{PGFplotsManualHTML,
  title = {{{PGFplots Manual}} - {{HTML Documentation}}},
  url = {https://tikz.dev/pgfplots/},
  urldate = {2025-11-30},
  abstract = {Full online version of the documentation of PGFplots, the TeX package for creating plots.},
  langid = {american},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/7UG4BAPH/pgfplots.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/7JLLLRLA/pgfplots.html}
}

@inproceedings{pibiriPTHashRevisitingFCH2021,
  title = {{{PTHash}}: {{Revisiting FCH Minimal Perfect Hashing}}},
  shorttitle = {{{PTHash}}},
  booktitle = {Proceedings of the 44th {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Pibiri, Giulio Ermanno and Trani, Roberto},
  date = {2021-07-11},
  eprint = {2104.10402},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {1339--1348},
  doi = {10.1145/3404835.3462849},
  url = {http://arxiv.org/abs/2104.10402},
  urldate = {2025-12-04},
  abstract = {Given a set 𝑆 of 𝑛 distinct keys, a function 𝑓 that bijectively maps the keys of 𝑆 into the range \{0, . . . , 𝑛 − 1\} is called a minimal perfect hash function for 𝑆. Algorithms that find such functions when 𝑛 is large and retain constant evaluation time are of practical interest; for instance, search engines and databases typically use minimal perfect hash functions to quickly assign identifiers to static sets of variable-length keys such as strings. The challenge is to design an algorithm which is efficient in three different aspects: time to find 𝑓 (construction time), time to evaluate 𝑓 on a key of 𝑆 (lookup time), and space of representation for 𝑓 . Several algorithms have been proposed to trade-off between these aspects. In 1992, Fox, Chen, and Heath (FCH) presented an algorithm at SIGIR providing very fast lookup evaluation. However, the approach received little attention because of its large construction time and higher space consumption compared to other subsequent techniques. Almost thirty years later we revisit their framework and present an improved algorithm that scales well to large sets and reduces space consumption altogether, without compromising the lookup time. We conduct an extensive experimental assessment and show that the algorithm finds functions that are competitive in space with state-of-the art techniques and provide 2 − 4× better lookup time.},
  langid = {english},
  keywords = {Computer Science - Data Structures and Algorithms},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/UTL6M9NR/Pibiri und Trani - 2021 - PTHash Revisiting FCH Minimal Perfect Hashing.pdf}
}

@article{pierquetGrapheurGrapherBased,
  title = {Grapheur - {{A}} Grapher, Based on {{TikZ}} and Xint.},
  author = {Pierquet, Cédric},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/TKQED2IS/Pierquet - A grapher, based on TikZ and xint..pdf}
}

@misc{pieterdenhamerPillarsSuccessfulArtificial2024,
  title = {The {{Pillars}} of a {{Successful Artificial Intelligence Strategy}}},
  author = {{Pieter den Hamer} and {Raghvender Bhati}},
  date = {2024-04-23},
  url = {https://www.gartner.com/en/documents/5373763},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/8KM3MHZR/The Pillars of a Successful Artificial Intelligence Strategy.pdf}
}

@article{pietervanoostrumFancyHdrFancyhdrExtramarks,
  title = {{{FancyHdr}} - {{The}} Fancyhdr and Extramarks Packages Version v5.2.},
  author = {{Pieter van Oostrum}},
  abstract = {This document describes how to customize the page layout of your LaTeX documents, i.e., how to change page margins and sizes, headers and footers, and the proper placement of figures and tables (collectively called floats) on the page.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/P8VCQE4S/The fancyhdr and extramarks packages version v5.2..pdf}
}

@book{pikHandsonFinancialTrading2021,
  title = {Hands-on Financial Trading with Python: A Practical Guide to Using {{Zipline}} and Other {{Python}} Libraries for Backtesting Trading Strategies},
  shorttitle = {Hands-on Financial Trading with Python},
  author = {Pik, Jiri and Ghosh, Sourav},
  date = {2021},
  publisher = {Packt Publishing},
  location = {Place of publication not identified},
  abstract = {Algorithmic trading helps you stay ahead of the markets by devising strategies in quantitative analysis to gain profits and cut losses. The book starts by introducing you to algorithmic trading and explaining why Python is the best platform for developing trading strategies. You'll then cover quantitative analysis using Python, and learn how to build algorithmic trading strategies with Zipline using various market data sources. Using Zipline as the backtesting library allows access to complimentary US historical daily market data until 2018. As you advance, you will gain an in-depth understanding of Python libraries such as NumPy and pandas for analyzing financial datasets, and explore Matplotlib, statsmodels, and scikit-learn libraries for advanced analytics. You'll also focus on time series forecasting, covering pmdarima and Facebook Prophet. By the end of this trading book, you will be able to build predictive trading signals, adopt basic and advanced algorithmic trading strategies, and perform portfolio optimization},
  isbn = {978-1-83898-288-1 978-1-83898-880-7},
  langid = {english},
  pagetotal = {1},
  keywords = {Lesen},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/IGGPKA3K/Pik und Ghosh - 2021 - Hands-on financial trading with python a practical guide to using Zipline and other Python librarie.pdf}
}

@article{porterLearnAIAssistedPython,
  title = {Learn {{AI-Assisted Python Programming}}, {{Second Edition}}},
  author = {Porter, Leo and Zingaro, Daniel},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/N5JR6B2Y/Porter und Zingaro - Learn AI-Assisted Python Programming, Second Edition.pdf}
}

@book{porterLearnAIassistedPython2024,
  title = {Learn {{AI-assisted Python}} Programming: With {{GitHub Copilot}} and {{ChatGPT}}},
  shorttitle = {Learn {{AI-assisted Python}} Programming},
  author = {Porter, Leo and Zingaro, Daniel},
  date = {2024},
  publisher = {Manning},
  location = {Shelter Island, NY},
  abstract = {Writing computer programs in Python just got a lot easier! Use AI-assisted coding tools like GitHub Copilot and ChatGPT to turn your ideas into applications faster than ever. AI has changed the way we write computer programs. With tools like Copilot and ChatGPT, you can describe what you want in plain English, and watch your AI assistant generate the code right before your eyes. It's perfect for beginners, or anyone who's struggled with the steep learning curve of traditional programming. Learn AI-Assisted Python Programming: With GitHub Copilot and ChatGPT is a hands-on beginner's guide that is written by two esteemed computer science university professors. It teaches you everything you need to start programming Python in an AI-first world. You'll hit the ground running, writing prompts that tell your AI-assistant exactly what you want your programs to do. Along the way, you'll pick up the essentials of Python programming and practice the higher-level thinking you'll need to create working apps for data analysis, automating tedious tasks, and even video games. The way people write computer programs has changed forever. Using GitHub Copilot, you describe in plain English what you want your program to do, and the AI generates it instantly. This book shows you how to create and improve Python programs using AI--even if you've never written a line of computer code before. Spend less time on the slow, low-level programming details and instead learn how an AI assistant can bring your ideas to life immediately. As you go, you'll even learn enough of the Python language to understand and improve what your AI assistant creates},
  isbn = {978-1-63343-778-4},
  langid = {english},
  pagetotal = {270},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/DAFW2XXM/Porter und Zingaro - 2024 - Learn AI-assisted Python programming with GitHub Copilot and ChatGPT.pdf}
}

@article{princeUnderstandingDeepLearning,
  title = {Understanding {{Deep Learning}}},
  author = {Prince, Simon J D},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/BQLXS5Q4/Prince - Understanding Deep Learning.pdf}
}

@unpublished{prof.erikdemaineAdvancedDataStructures2012,
  title = {Advanced {{Data Structures}} - {{Spring}} ’12 {{Scribe Notes Collection}}},
  shorttitle = {{{MIT}} 6.851},
  author = {{Prof. Erik Demaine}},
  date = {2012},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/QEXPPQ6P/Advanced Data Structures - MIT 6.851 (2012).pdf}
}

@article{qureshiAdaptiveInsertionPolicies,
  title = {Adaptive {{Insertion Policies}} for {{High Performance Caching}}},
  author = {Qureshi, Moinuddin K and Jaleel, Aamer and Patt, Yale N and Jr, Simon C Steely and Emer, Joel},
  abstract = {The commonly used LRU replacement policy is susceptible to thrashing for memory-intensive workloads that have a working set greater than the available cache size. For such applications, the majority of lines traverse from the MRU position to the LRU position without receiving any cache hits, resulting in inefficient use of cache space. Cache performance can be improved if some fraction of the working set is retained in the cache so that at least that fraction of the working set can contribute to cache hits.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/PMJG35F2/Qureshi et al. - Adaptive Insertion Policies for High Performance Caching.pdf}
}

@book{raschkaBuildLargeLanguage2025,
  title = {Build a {{Large Language Model}} (from {{Scratch}})},
  shorttitle = {Build a {{Large Language Model}} (from {{Scratch}})},
  author = {Raschka},
  date = {2025},
  publisher = {Manning Publications Co. LLC},
  location = {New York},
  abstract = {Test your understanding and push your knowledge further with exercises drawn from the core concepts of the bestselling LLM book! Sebastian Raschka's bestselling book Build a Large Language Model (From Scratch). is the best way to learn how Large Language Models function. It uses Python and the PyTorch deep learning library. It's a unique way to learn this subject, which some believe is the only way to truly learn: you build a model yourself. Even with the clear explanations, diagrams, and code in the book, learning a complex subject is still hard. This Test Yourself guide intends to make it a little easier. The structure mirrors the structure of Build a Large Language Model (From Scratch), focusing on key concepts from each chapter. You can test yourself with multiple-choice quizzes, questions on code and key concepts, and questions with longer answers that push you to think critically. The answers to all questions are provided. Depending on what you know at any point, this Test Yourself guide can help you in different ways. It will solidify your knowledge if used after reading a chapter. But it will also benefit you if you digest it before reading. By testing yourself on the main concepts and their relationships you are primed to navigate a chapter more easily and be ready for its messages. We recommend using it before and after reading, as well as later when you have started forgetting. Repeated learning solidifies our knowledge and integrates it with related knowledge already in our long-term memory. About the Technology About the Book What's Inside Questions on code and key concepts Critical thinking exercises requiring longer answers Answers for all questions About the Reader For readers of Build a Large Language Model (From Scratch) who want to enhance their learning with exercises and self-assessment tools. About the Author Curated from Build a Large Language Model (From Scratch). Quotes},
  isbn = {978-1-63343-716-6 978-1-63835-762-9},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/Zotero/storage/W8JBJBL5/Raschka - 2025 - Test Yourself on Build a Large Language Model (from Scratch) Exercises to Enhance Your LLM Learning.pdf}
}

@book{raschkaPythonMachineLearning2015,
  title = {Python Machine Learning: Unlock Deeper Insights into Machine Learning with This Vital Guide to Cutting-Edge Predictive Analytics},
  shorttitle = {Python Machine Learning},
  author = {Raschka, Sebastian and Olson, Randal S.},
  date = {2015},
  series = {Open Source Community Experience Distilled},
  publisher = {Packt Publishing open source},
  location = {Birmingham Mumbai},
  isbn = {978-1-78355-513-0},
  langid = {english},
  pagetotal = {425},
  file = {/Users/bernhardgerlach/Zotero/storage/9MBCSAAX/Raschka und Olson - 2015 - Python machine learning unlock deeper insights into machine learning with this vital guide to cutti.pdf;/Users/bernhardgerlach/Zotero/storage/PQ8PJUDS/Raschka - 2015 - Python Machine Learning.pdf}
}

@book{reinhartStatisticsDoneWrong2015,
  title = {Statistics {{Done Wrong}}: {{The Woefully Complete Guide}}},
  shorttitle = {Statistics {{Done Wrong}}},
  author = {Reinhart, Alex},
  date = {2015},
  publisher = {No Starch Press},
  location = {San Francisco},
  abstract = {Intro -- Praise for Statistics Done Wrong -- Statistics Done Wrong: The Woefully Complete Guide -- Copyright -- Contents -- About the Author -- Preface -- Acknowledgments -- Introduction -- 1. An Introduction to Statistical Significance -- The Power of p Values -- Psychic Statistics -- Neyman-Pearson Testing -- Have Confidence in Intervals -- 2. Statistical Power and Underpowered Statistics -- The Power Curve -- The Perils of Being Underpowered -- Wherefore Poor Power? -- Wrong Turns on Red -- Confidence Intervals and Empowerment -- Truth Inflation -- Little Extremes -- 3. Pseudoreplication: Choose Your Data Wisely -- Pseudoreplication in Action -- Accounting for Pseudoreplication -- Batch Biology -- Synchronized Pseudoreplication -- 4. The P Value and the Base Rate Fallacy -- The Base Rate Fallacy -- A Quick Quiz -- The Base Rate Fallacy in Medical Testing -- How to Lie with Smoking Statistics -- Taking Up Arms Against the Base Rate Fallacy -- If At First You Don't Succeed, Try, Try Again -- Red Herrings in Brain Imaging -- Controlling the False Discovery Rate -- 5. Bad Judges of Significance -- Insignificant Differences in Significance -- Ogling for Significance -- 6. Double-Dipping in the Data -- Circular Analysis -- Regression to the Mean -- Stopping Rules -- 7. Continuity Errors -- Needless Dichotomization -- Statistical Brownout -- Confounded Confounding -- 8. Model Abuse -- Fitting Data to Watermelons -- Correlation and Causation -- Simpson's Paradox -- 9. Researcher Freedom: Good Vibrations? -- A Little Freedom Is a Dangerous Thing -- Avoiding Bias -- 10. Everybody Makes Mistakes -- Irreproducible Genetics -- Making Reproducibility Easy -- Experiment, Rinse, Repeat -- 11. Hiding the Data -- Captive Data -- Obstacles to Sharing -- Data Decay -- Just Leave Out the Details -- Known Unknowns -- Outcome Reporting Bias},
  isbn = {978-1-59327-620-1 978-1-59327-673-7},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/Zotero/storage/DQ2JTR6K/Reinhart - 2015 - STATISTICS DONE WRONG.pdf}
}

@article{richterSevendimensionalAnalysisHashing2015,
  title = {A Seven-Dimensional Analysis of Hashing Methods and Its Implications on Query Processing},
  author = {Richter, Stefan and Alvarez, Victor and Dittrich, Jens},
  date = {2015-11},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proc. VLDB Endow.},
  volume = {9},
  number = {3},
  pages = {96--107},
  issn = {2150-8097},
  doi = {10.14778/2850583.2850585},
  url = {https://dl.acm.org/doi/10.14778/2850583.2850585},
  urldate = {2025-12-05},
  abstract = {Hashing is a solved problem. It allows us to get constant time access for lookups. Hashing is also simple. It is safe to use an arbitrary method as a black box and expect good performance, and optimizations to hashing can only improve it by a negligible delta. Why are all of the previous statements plain wrong? That is what this paper is about. In this paper we thoroughly study hashing for integer keys and carefully analyze the most common hashing methods in a five-dimensional requirements space: () data-distribution, () load factor, () dataset size, () read/write-ratio, and () un/successfulratio. Each point in that design space may potentially suggest a different hashing scheme, and additionally also a different hash function. We show that a right or wrong decision in picking the right hashing scheme and hash function combination may lead to significant difference in performance. To substantiate this claim, we carefully analyze two additional dimensions: () five representative hashing schemes (which includes an improved variant of Robin Hood hashing), () four important classes of hash functions widely used today. That is, we consider 20 different combinations in total. Finally, we also provide a glimpse about the effect of table memory layout and the use of SIMD instructions. Our study clearly indicates that picking the right combination may have considerable impact on insert and lookup performance, as well as memory footprint. A major conclusion of our work is that hashing should be considered a white box before blindly using it in applications, such as query processing. Finally, we also provide a strong guideline about when to use which hashing method.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/VJNH2MR4/Richter et al. - 2015 - A seven-dimensional analysis of hashing methods and its implications on query processing.pdf}
}

@book{rileyMathematicalMethodsPhysics2008,
  title = {Mathematical Methods for Physics and Engineering},
  author = {Riley, Kenneth Franklin and Hobson, Michael Paul and Bence, Stephen John},
  date = {2008},
  edition = {3rd ed},
  publisher = {Cambridge University Press},
  location = {Cambridge},
  isbn = {978-0-521-67971-8},
  langid = {english},
  file = {/Users/bernhardgerlach/Zotero/storage/L5X62Y3N/RILEY et al. - 2006 - MATHEMATICAL METHODS FOR PHYSICS AND ENGINEERING.pdf}
}

@article{robertsonFontspecFontspecPackage,
  title = {Fontspec - {{The}} Fontspec Package {{Font}} Selection for {{XeLaTeX}} and {{LuaLaTeX}}},
  author = {Robertson, Will},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/J7DH2THU/Robertson - The fontspec package Font selection for XeLaTeX and LuaLaTeX.pdf}
}

@book{robertsPrinciplesDeepLearning2022,
  title = {The {{Principles}} of {{Deep Learning Theory}}},
  author = {Roberts, Daniel A. and Yaida, Sho and Hanin, Boris},
  date = {2022-05-26},
  eprint = {2106.10165},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.1017/9781009023405},
  url = {http://arxiv.org/abs/2106.10165},
  urldate = {2025-12-07},
  abstract = {This book develops an effective theory approach to understanding deep neural networks of practical relevance. Beginning from a first-principles component-level picture of networks, we explain how to determine an accurate description of the output of trained networks by solving layer-to-layer iteration equations and nonlinear learning dynamics. A main result is that the predictions of networks are described by nearly-Gaussian distributions, with the depth-to-width aspect ratio of the network controlling the deviations from the infinite-width Gaussian description. We explain how these effectively-deep networks learn nontrivial representations from training and more broadly analyze the mechanism of representation learning for nonlinear models. From a nearly-kernel-methods perspective, we find that the dependence of such models' predictions on the underlying learning algorithm can be expressed in a simple and universal way. To obtain these results, we develop the notion of representation group flow (RG flow) to characterize the propagation of signals through the network. By tuning networks to criticality, we give a practical solution to the exploding and vanishing gradient problem. We further explain how RG flow leads to near-universal behavior and lets us categorize networks built from different activation functions into universality classes. Altogether, we show that the depth-to-width ratio governs the effective model complexity of the ensemble of trained networks. By using information-theoretic techniques, we estimate the optimal aspect ratio at which we expect the network to be practically most useful and show how residual connections can be used to push this scale to arbitrary depths. With these tools, we can learn in detail about the inductive bias of architectures, hyperparameters, and optimizers.},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,High Energy Physics - Theory,Statistics - Machine Learning},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/Y8LXEDH4/Roberts et al. - 2022 - The Principles of Deep Learning Theory.pdf}
}

@book{romanoLearnPythonProgramming2021,
  title = {Learn {{Python Programming}}: {{An}} in-Depth Introduction to the Fundamentals of {{Python}}},
  shorttitle = {Learn {{Python Programming}}},
  author = {Romano, Fabrizio},
  namea = {Kruger, Heinrich},
  nameatype = {collaborator},
  date = {2021},
  edition = {3},
  publisher = {Packt Publishing Limited},
  location = {Birmingham},
  abstract = {bGet up and running with Python 3.9 through concise tutorials and practical projects in this fully updated third edition/bh4Key Features/h4ulliExtensively revised with richer examples, Python 3.9 syntax, and new chapters on APIs and packaging and distributing Python code/liliDiscover how to think like a Python programmer/liliLearn the fundamentals of Python through real-world projects in API development, GUI programming, and data science/li/ulh4Book Description/h4Learn Python Programming, Third Edition is both a theoretical and practical introduction to Python, an extremely flexible and powerful programming language that can be applied to many disciplines. This book will make learning Python easy and give you a thorough understanding of the language. You'll learn how to write programs, build modern APIs, and work with data by using renowned Python data science libraries. This revised edition covers the latest updates on API management, packaging applications, and testing. There is also broader coverage of context managers and an updated data science chapter. The book empowers you to take ownership of writing your software and become independent in fetching the resources you need. You will have a clear idea of where to go and how to build on what you have learned from the book. Through examples, the book explores a wide range of applications and concludes by building real-world Python projects based on the concepts you have learned.h4What you will learn/h4ulliGet Python up and running on Windows, Mac, and Linux/liliWrite elegant, reusable, and efficient code in any situation/liliAvoid common pitfalls like duplication, complicated design, and over-engineering/liliUnderstand when to use the functional or object-oriented approach to programming/liliBuild a simple API with FastAPI and program GUI applications with Tkinter/liliGet an initial overview of more complex topics such as data persistence and cryptography/liliFetch, clean, and manipulate data, making efficient use of Python's built-in data structures/li/ulh4Who this book is for/h4This book is for everyone who wants to learn Python from scratch, as well as experienced programmers looking for a reference book. Prior knowledge of basic programming concepts will help you follow along, but it's not a prerequisite},
  isbn = {978-1-80181-509-3 978-1-80181-552-9},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/745UK6WF/Romano - 2021 - Learn Python Programming An in-depth introduction to the fundamentals of Python.pdf}
}

@book{ronzacharskiProgrammersGuideData2015,
  title = {A {{Programmer}}'s {{Guide}} to {{Data Mining}}},
  author = {{Ron Zacharski}},
  date = {2015},
  publisher = {self published},
  url = {http://guidetodatamining.com/},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/48AJ9U2A/DataMining-ch2.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/DNR5R89P/DataMining-ch7.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/EPIHC6RW/DataMining-ch3.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/PBHACEQH/DataMining-ch5.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/PSQ6FCQ9/DataMining-ch6.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/QZJQQQN3/DataMining-ch1.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/TSRIU6FE/DataMining-ch4.pdf}
}

@article{rosenblattPerceptronProbabilisticModel1958,
  title = {The Perceptron: {{A}} Probabilistic Model for Information Storage and Organization in the Brain.},
  shorttitle = {The Perceptron},
  author = {Rosenblatt, F.},
  date = {1958},
  journaltitle = {Psychological Review},
  shortjournal = {Psychological Review},
  volume = {65},
  number = {6},
  pages = {386--408},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/h0042519},
  url = {https://doi.apa.org/doi/10.1037/h0042519},
  urldate = {2025-12-07},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/7WH9R3CC/Rosenblatt - 1958 - The perceptron A probabilistic model for information storage and organization in the brain..pdf}
}

@article{sabekCanLearnedModels2022,
  title = {Can {{Learned Models Replace Hash Functions}}?},
  author = {Sabek, Ibrahim and Vaidya, Kapil and Horn, Dominik and Kipf, Andreas and Mitzenmacher, Michael and Kraska, Tim},
  date = {2022-11},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proc. VLDB Endow.},
  volume = {16},
  number = {3},
  pages = {532--545},
  issn = {2150-8097},
  doi = {10.14778/3570690.3570702},
  url = {https://dl.acm.org/doi/10.14778/3570690.3570702},
  urldate = {2025-12-04},
  abstract = {Hashing is a fundamental operation in database management, playing a key role in the implementation of numerous core database data structures and algorithms. Traditional hash functions aim to mimic a function that maps a key to a random value, which can result in collisions, where multiple keys are mapped to the same value. There are many well-known schemes like chaining, probing, and cuckoo hashing to handle collisions. In this work, we aim to study if using learned models instead of traditional hash functions can reduce collisions and whether such a reduction translates to improved performance, particularly for indexing and joins. We show that learned models reduce collisions in some cases, which depend on how the data is distributed. To evaluate the effectiveness of learned models as hash function, we test them with bucket chaining, linear probing, and cuckoo hash tables. We find that learned models can (1) yield a 1.4x lower probe latency, and (2) reduce the non-partitioned hash join runtime with 28\% over the next best baseline for certain datasets. On the other hand, if the data distribution is not suitable, we either do not see gains or see worse performance. In summary, we find that learned models can indeed outperform hash functions, but only for certain data distributions.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/BU3YMHK2/Sabek et al. - 2022 - Can Learned Models Replace Hash Functions.pdf}
}

@book{sachdevaCertifiedKubernetesAdministrator2025,
  title = {Certified {{Kubernetes}} Administrator Study Companion: Preparing for the {{Linux}} Foundation's {{CKA}} Exam},
  shorttitle = {Certified {{Kubernetes}} Administrator Study Companion},
  author = {Sachdeva, Piyush},
  date = {2025},
  series = {Certification {{Study Companion Series}}},
  edition = {First edition},
  publisher = {Apress},
  location = {New York, NY},
  abstract = {The Kubernetes landscape is constantly evolving, making it crucial to stay updated on the latest best practices and technologies. Using a structured approach and practical applications, this comprehensive study companion is designed to help individuals prepare for the Certified Kubernetes Administrator (CKA) exam. You'll start by reviewing a range of essential topics that serve as prerequisites for certification, such as what Kubernetes is, its architecture, and key components like the Control Plane, ApiServer, and ETCD. The book then addresses workloads and scheduling, providing insights into pods, deployments, and various resource management techniques. Additionally, you'll explore storage management in Kubernetes, detailing persistent volumes, access modes, and storage classes. Networking topics, including pod connectivity, CoreDNS, and network policies are covered as well. Throughout the book, troubleshooting techniques are emphasized, focusing on monitoring cluster components and application performance. Most importantly, the book offers guidance on exam preparation, including patterns, prerequisites, and last-minute tips, along with sample questions to aid your study process. Whether you're new to Kubernetes or actively studying for the CKA certification, this book will serve as your essential resource. What You Will Learn Kubernetes fundamentals, including architecture, components, and installation. In-depth knowledge on workloads and scheduling, covering pods, deployments, and services. Essential insights into storage management, networking, and cluster architecture. Troubleshooting techniques for monitoring and resolving issues in Kubernetes environments. Exam preparation tips, including sample questions and strategies for success. Who This Book Is For College students, recent graduates, IT professionals in the Cloud/DevOps domain, individuals transitioning into Cloud/DevOps roles, Kubernetes administrators, and DevOps engineers},
  isbn = {979-8-8688-1512-6 979-8-8688-1513-3},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/HZB9ACS2/Sachdeva - 2025 - Certified Kubernetes administrator study companion preparing for the Linux foundation's CKA exam.epub}
}

@article{saltzerPrinciplesComputerSystem,
  title = {Principles of {{Computer System Design}}},
  author = {Saltzer, Jerome H and Kaashoek, M Frans},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/W2ZGJ9TU/Principles of Computer System Design - An Introduction - Part II - Version 5.0 (part_ii_open_5_0).pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/X8WA9TUJ/Saltzer und Kaashoek - Principles of Computer System Design.pdf}
}

@book{sarwarPythonEthicalHacking2021,
  title = {Python Ethical Hacking from {{Scratch}}: Think like an Ethical Hacker, Avoid Detection, and Successfully Develop, Deploy, Detect, and Avoid Malware},
  shorttitle = {Python Ethical Hacking from {{Scratch}}},
  author = {Sarwar, Fahad Ali},
  date = {2021},
  edition = {First published: July 2021},
  publisher = {Packt Publishing Limited},
  location = {Birmingham},
  abstract = {bExplore the world of practical ethical hacking by developing custom network scanning and remote access tools that will help you test the system security of your organization/bh4Key Features/h4ulliGet hands-on with ethical hacking and learn to think like a real-life hacker/liliBuild practical ethical hacking tools from scratch with the help of real-world examples/liliLeverage Python 3 to develop malware and modify its complexities/li/ulh4Book Description/h4Penetration testing enables you to evaluate the security or strength of a computer system, network, or web application that an attacker can exploit. With this book, you'll understand why Python is one of the fastest-growing programming languages for penetration testing. You'll find out how to harness the power of Python and pentesting to enhance your system security. Developers working with Python will be able to put their knowledge and experience to work with this practical guide. Complete with step-by-step explanations of essential concepts and practical examples, this book takes a hands-on approach to help you build your own pentesting tools for testing the security level of systems and networks. You'll learn how to develop your own ethical hacking tools using Python and explore hacking techniques to exploit vulnerabilities in networks and systems. Finally, you'll be able to get remote access to target systems and networks using the tools you develop and modify as per your own requirements. By the end of this ethical hacking book, you'll have developed the skills needed for building cybersecurity tools and learned how to secure your systems by thinking like a hacker.h4What you will learn/h4ulliUnderstand the core concepts of ethical hacking/liliDevelop custom hacking tools from scratch to be used for ethical hacking purposes/liliDiscover ways to test the cybersecurity of an organization by bypassing protection schemes/liliDevelop attack vectors used in real cybersecurity tests/liliTest the system security of an organization or subject by identifying and exploiting its weaknesses/liliGain and maintain remote access to target systems/liliFind ways to stay undetected on target systems and local networks/li/ulh4Who this book is for/h4If you want to learn ethical hacking by developing your own tools instead of just using the prebuilt tools, this book is for you. A solid understanding of fundamental Python concepts is expected. Some complex Python concepts are explained in the book, but the goal is to teach ethical hacking, not Python},
  isbn = {978-1-83882-950-6},
  langid = {english},
  pagetotal = {201},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/WW2GCZ7B/Sarwar - 2021 - Python ethical hacking from Scratch think like an ethical hacker, avoid detection, and successfully.pdf}
}

@article{schmidtPerfectHashFunction,
  title = {A {{Perfect Hash Function Generator}}},
  author = {Schmidt, Douglas C},
  abstract = {Developers can control the generated hash function’s contents using the "-k" option to explicitly specify the keyword index positions used as keysig elements by gperf. The default is "-k 1,\$", where the ’\$’ represents the keyword’s final character.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/JC3PPDBI/Schmidt - A Perfect Hash Function Generator.pdf}
}

@book{schuhEinkaufsschachbrettMit642011,
  title = {Das Einkaufsschachbrett: Mit 64 Ansätzen Materialkosten senken und Wert schaffen},
  shorttitle = {Das Einkaufsschachbrett},
  author = {Schuh, Christian},
  date = {2011},
  publisher = {Springer Fachmedien},
  location = {Wiesbaden},
  abstract = {Die Konzentration am Lieferantenmarkt, steigende Energiepreise und der Ressourcenhunger von schnell wachsenden Volkswirtschaften wie China machen es immer schwieriger, im Einkauf Preissenkungen durchzusetzen. Um Unternehmen dabei zu unterstützen, die neuen Herausforderungen im Einkauf zu meistern und signifikante Wertbeiträge zu erzielen, haben die Autoren dieses Buchs das Einkaufsschachbrett entwickelt. Jeder Konstellation aus Nachfragemacht und Angebotsmacht weist es eine angemessene Einkaufsstrategie zu.{$<$}br{$>$}},
  isbn = {978-3-8349-1179-7},
  langid = {german},
  pagetotal = {187},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/UNEGQQ7Z/Schuh - 2011 - Das Einkaufsschachbrett Mit 64 Ansätzen Materialkosten senken und Wert schaffen.pdf}
}

@book{schwartzmanAssemblyLanguageReimagined2025,
  title = {Assembly {{Language Reimagined}}: {{Programming}} the {{Intel}} X64 {{Microprocessor}} in {{Linux}}},
  shorttitle = {Assembly {{Language Reimagined}}},
  author = {Schwartzman, John},
  date = {2025},
  edition = {1st ed. 2025},
  publisher = {Apress},
  location = {Berkeley, CA},
  doi = {10.1007/979-8-8688-1724-3},
  isbn = {979-8-8688-1723-6 979-8-8688-1724-3},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/EWMC9NWY/Schwartzman - 2025 - Assembly Language Reimagined Programming the Intel x64 Microprocessor in Linux.epub}
}

@book{scottOracleDockerRunning2023,
  title = {Oracle on {{Docker}}: {{Running Oracle Databases}} in {{Linux Containers}}},
  shorttitle = {Oracle on {{Docker}}},
  author = {Scott, Sean},
  date = {2023},
  edition = {1st ed},
  publisher = {Apress L. P},
  location = {Berkeley, CA},
  abstract = {Intro -- Table of Contents -- About the Author -- About the Technical Reviewer -- Acknowledgments -- Introduction -- Part I: Introduction to Containers -- Chapter 1: Introducing Docker and Oracle -- Why Docker? -- Simplicity -- Self-Contained -- Speed -- Portability -- Reliability -- Cost -- Use Cases -- Exchange Data -- Modular Software -- Orchestration -- Other Uses -- Objections to Docker -- Summary -- Chapter 2: Understanding the Container Landscape -- Containers vs. Virtual Machines -- Dedicated vs. Shared -- Performance -- Capacity and Capability -- Concepts and Terminology -- Images -- Tags -- Portable -- Immutable and Stateless -- Containers -- Stateful -- Ephemeral -- Resources -- Volumes -- Networking -- Additional Terminology -- Runtimes -- Dockerfiles -- Builds -- Summary -- Chapter 3: Container Foundations -- Docker Command-Line Overview -- Run Your First Container -- List Images -- Run a Container -- Explore the Container -- Image Registries -- Minimalism -- Modify the Container -- Persistence -- Check the Container State -- Start the Container -- Interactive vs. Detached -- Connect to the Container -- Verify Persistence -- Remove the Container -- Images Are Immutable -- Start a New Container -- Save a New Image -- Run the New Image -- Union Filesystems -- Commit vs. Build -- Summary -- Chapter 4: Oracle Database Quick Start -- Access the Docker Environment -- Terminology -- Docker Commands -- Images and Containers -- Build and Run -- The Docker Command Line -- Obtaining an Image -- Pre-built Images -- Download an Image -- Download a Tag -- Running Pre-built Images -- Pre-built Image Limitations -- Building Images from a Repository -- Oracle Docker GitHub Repo -- Oracle Database Software -- Build an Image -- Running a Container -- Container Properties -- Port Publishing -- Volume Mounting},
  isbn = {978-1-4842-9033-0},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/CGSLSQY8/Scott - 2023 - Oracle on Docker Running Oracle Databases in Linux Containers.epub}
}

@article{sculleyMachineLearningHighInterest,
  title = {Machine {{Learning}}: {{The High-Interest Credit Card}} of {{Technical Debt}}},
  author = {Sculley, D and Holt, Gary and Golovin, Daniel and Davydov, Eugene and Phillips, Todd and Ebner, Dietmar and Chaudhary, Vinay and Young, Michael},
  abstract = {Machine learning offers a fantastically powerful toolkit for building complex systems quickly. This paper argues that it is dangerous to think of these quick wins as coming for free. Using the framework of technical debt, we note that it is remarkably easy to incur massive ongoing maintenance costs at the system level when applying machine learning. The goal of this paper is highlight several machine learning specific risk factors and design patterns to be avoided or refactored where possible. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, changes in the external world, and a variety of system-level anti-patterns.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/CZEHQCFH/Sculley et al. - Machine Learning The High-Interest Credit Card of Technical Debt.pdf}
}

@article{serebryanyAddressSanitizerFastAddress,
  title = {{{AddressSanitizer}}: {{A Fast Address Sanity Checker}}},
  author = {Serebryany, Konstantin and Bruening, Derek and Potapenko, Alexander and Vyukov, Dmitry},
  abstract = {Memory access bugs, including buffer overflows and uses of freed heap memory, remain a serious problem for programming languages like C and C++. Many memory error detectors exist, but most of them are either slow or detect a limited set of bugs, or both.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/RIQ98IQ9/Serebryany et al. - AddressSanitizer A Fast Address Sanity Checker.pdf}
}

@article{shannonMathematicalTheoryCommunication,
  title = {A {{Mathematical Theory}} of {{Communication}}},
  author = {Shannon, C E},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/CKNQGLZZ/Shannon - A Mathematical Theory of Communication.pdf}
}

@book{shawWebDevelopmentDjango2021,
  title = {Web Development with Django: Learn to Build Modern Web Applications with a {{Python-based}} Framework},
  shorttitle = {Web Development with Django},
  author = {Shaw, Ben and Badhwar, Saurabh and Bird, Andrew and Chandra K S, Bharath and Guest, Chris},
  date = {2021},
  publisher = {Packt Publishing},
  location = {Place of publication not identified},
  abstract = {Learn how to create your own websites simply, safely, and quickly with Django by tackling practical activities based on realistic case studiesKey FeaturesUnderstand Django functionality and the Model-View-Template (MVT) paradigmCreate and iteratively build a book review website, adding features as you build your knowledgeExplore advanced concepts such as REST API implementation and third-party module integrationBook DescriptionDo you want to develop reliable and secure applications which stand out from the crowd, rather than spending hours on boilerplate code? Then the Django framework is where you should begin. Often referred to as a 'batteries included' web development framework, Django comes with all the core features needed to build a standalone application. Web Development with Django takes this philosophy and equips you with the knowledge and confidence to build real-world applications using Python. Starting with the essential concepts of Django, you'll cover its major features by building a website called Bookr - a repository for book reviews. This end-to-end case study is split into a series of bitesize projects that are presented as exercises and activities, allowing you to challenge yourself in an enjoyable and attainable way. As you progress, you'll learn various practical skills, including how to serve static files to add CSS, JavaScript, and images to your application, how to implement forms to accept user input, and how to manage sessions to ensure a reliable user experience. Throughout this book, you'll cover key daily tasks that are part of the development cycle of a real-world web application. By the end of this book, you'll have the skills and confidence to creatively tackle your own ambitious projects with Django.What you will learnCreate a new application and add models to describe your dataUse views and templates to control behavior and appearanceImplement access control through authentication and permissionsDevelop practical web forms to add features such as file uploadsDevelop a RESTful API and JavaScript code that communicates with itConnect to a database such as PostgreSQLWho this book is forWeb Development with Django is designed for programmers who want to gain web development skills with the Django framework. To fully understand the concepts explained in this book, you must have basic knowledge of Python programming, as well as familiarity with JavaScript, HTML, and CSS},
  isbn = {978-1-83921-250-5 978-1-83921-377-9},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/DRQGQSXB/Shaw et al. - 2021 - Web development with django learn to build modern web applications with a Python-based framework.pdf}
}

@book{sheikhCompTIALinuxCertification2024,
  title = {{{CompTIA Linux}}+ {{Certification Companion}}: {{Hands-on Preparation}} to {{Master Linux Administration}}},
  shorttitle = {{{CompTIA Linux}}+ {{Certification Companion}}},
  author = {Sheikh, Ahmed F.},
  date = {2024},
  series = {Certification {{Study Companion Series}}},
  edition = {1st ed. 2024},
  publisher = {Apress},
  location = {Berkeley, CA},
  doi = {10.1007/979-8-8688-0128-0},
  isbn = {979-8-8688-0127-3 979-8-8688-0128-0},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/Q4IM5NNV/Sheikh - 2024 - CompTIA Linux+ Certification Companion Hands-on Preparation to Master Linux Administration.epub}
}

@book{shivendrasrivastavaPromptEngineeringAI2025,
  title = {Prompt {{Engineering}} for {{AI Systems}}},
  author = {{Shivendra Srivastava} and {Naresh Vurukonda}},
  date = {2025-08},
  series = {{{MEAP}}},
  publisher = {Manning Publications},
  url = {https://www.manning.com/books/prompt-engineering-for-ai-systems},
  isbn = {978-1-63343-591-9},
  langid = {english},
  pagetotal = {320},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/32VVZDE6/Prompt_Engineering_for_AI_Systems_v5_MEAP.pdf}
}

@inproceedings{singhEfficientParallelImplementation2022,
  title = {An {{Efficient Parallel Implementation}} of a {{Perfect Hashing Method}} for {{Hypergraphs}}},
  booktitle = {2022 {{IEEE International Parallel}} and {{Distributed Processing Symposium Workshops}} ({{IPDPSW}})},
  author = {Singh, Somesh and Ucar, Bora},
  date = {2022-05},
  pages = {265--274},
  publisher = {IEEE},
  location = {Lyon, France},
  doi = {10.1109/IPDPSW55747.2022.00056},
  url = {https://ieeexplore.ieee.org/document/9835222/},
  urldate = {2025-12-04},
  abstract = {Querying the existence of an edge in a given graph or hypergraph is a building block in several algorithms. Hashing-based methods can be used for this purpose, where the given edges are stored in a hash table in a preprocessing step, and then the queries are answered using the lookup operations. While the general hashing methods have fast lookup times in the average case, the worst case run time is much higher. Perfect hashing methods take advantage of the fact that the items to be stored are all available and construct a collision free hash function for the given input, resulting in an optimal lookup time even in the worst case. We investigate an efficient shared-memory parallel implementation of a recently proposed perfect hashing method for hypergraphs. We experimentally compare the resulting parallel algorithms with the state-of-the-art and demonstrate better run time and scalability on a set of hypergraphs corresponding to real-life sparse tensors.},
  eventtitle = {2022 {{IEEE International Parallel}} and {{Distributed Processing Symposium Workshops}} ({{IPDPSW}})},
  isbn = {978-1-6654-9747-3},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/VFFS2NNF/Singh und Ucar - 2022 - An Efficient Parallel Implementation of a Perfect Hashing Method for Hypergraphs.pdf}
}

@book{smartPracticalPythonProgramming2020,
  title = {Practical {{Python Programming}} for {{IoT}}: Build Advanced {{IoT}} Projects Using a {{Raspberry Pi}} 4, {{MQTT}}, {{RESTful APIs}}, {{WebSockets}}, and {{Python}} 3},
  shorttitle = {Practical {{Python Programming}} for {{IoT}}},
  author = {Smart, Gary},
  date = {2020},
  publisher = {Packt Publishing},
  location = {Place of publication not identified},
  abstract = {The age of connected devices is here, be it fitness bands or smart homes. It's now more important than ever to understand how hardware components interact with the internet to collect and analyze user data. The Internet of Things (IoT), combined with the popular open source language Python, can be used to build powerful and intelligent IoT systems with intuitive interfaces. This book consists of three parts, with the first focusing on the "Internet" component of IoT. You'll get to grips with end-to-end IoT app development to control an LED over the internet, before learning how to build RESTful APIs, WebSocket APIs, and MQTT services in Python. The second part delves into the fundamentals behind electronics and GPIO interfacing. As you progress to the last part, you'll focus on the "Things" aspect of IoT, where you will learn how to connect and control a range of electronic sensors and actuators using Python. You'll also explore a variety of topics, such as motor control, ultrasonic sensors, and temperature measurement. Finally, you'll get up to speed with advanced IoT programming techniques in Python, integrate with IoT visualization and automation platforms, and build a comprehensive IoT project. By the end of this book, you'll be well-versed with IoT development and have the knowledge you need to build sophisticated IoT systems using Python},
  isbn = {978-1-83898-246-1 978-1-83898-283-6},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/S38LIDFY/Smart - 2020 - Practical Python Programming for IoT build advanced IoT projects using a Raspberry Pi 4, MQTT, REST.pdf}
}

@book{smithScientistEngineersGuide1999,
  title = {The Scientist and Engineer's Guide to Digital Signal Processing},
  author = {Smith, Steven W.},
  date = {1999},
  edition = {2nd edition},
  publisher = {California Technical Pub.},
  location = {San Diego (Calif.)},
  isbn = {978-0-9660176-7-0},
  langid = {english},
  annotation = {OCLC: 493473234},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/T9LAEW6Z/Smith - 1999 - The scientist and engineer's guide to digital signal processing.pdf}
}

@article{sorensenGLOBALEQUITYRESEARCH,
  title = {{{GLOBAL EQUITY RESEARCH}}: {{Equity Options April}} 1998},
  author = {Sorensen, Eric H and Miller, Keith L and Cox, Daniel E},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/WAA7P9X4/Sorensen et al. - GLOBAL EQUITY RESEARCH Equity Options April 1998.pdf}
}

@article{sturmTColorboxTutorialPoster,
  title = {{{TColorbox}} - {{A Tutorial}} for {{Poster Creation}} with {{Tcolorbox}}},
  author = {Sturm, Thomas F},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/8SDTF5MJ/Sturm - A Tutorial for Poster Creation with Tcolorbox.pdf}
}

@book{subramanianDeployContainerApplications2023,
  title = {Deploy {{Container Applications Using Kubernetes}}: {{Implementations}} with {{Microk8s}} and {{AWS EKS}}},
  shorttitle = {Deploy {{Container Applications Using Kubernetes}}},
  author = {Subramanian, Shiva},
  date = {2023},
  edition = {1st ed},
  publisher = {Apress L. P},
  location = {Berkeley, CA},
  isbn = {978-1-4842-9276-1 978-1-4842-9277-8},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/Y9WG8TQJ/Subramanian - 2023 - Deploy Container Applications Using Kubernetes Implementations with Microk8s and AWS EKS.epub}
}

@article{sundayVeryFastSubstring1990,
  title = {A Very Fast Substring Search Algorithm},
  author = {Sunday, Daniel M.},
  date = {1990-08},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {33},
  number = {8},
  pages = {132--142},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/79173.79184},
  url = {https://dl.acm.org/doi/10.1145/79173.79184},
  urldate = {2025-12-05},
  abstract = {This article describes a substring search algorithm that is faster than the Boyer-Moore algorithm. This algorithm does not depend on scanning the pattern string in any particular order. Three variations of the algorithm are given that use three different pattern scan orders. These include: (1) a “Quick Search” algorithm; (2) a “Maximal Shift” and (3) an “Optimal Mismatch” algorithm.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/XY3Z5MTT/Sunday - 1990 - A very fast substring search algorithm.pdf}
}

@book{thampiInterpretableAIBuilding2022,
  title = {Interpretable {{AI}}: {{Building Explainable Machine Learning Systems}}},
  shorttitle = {Interpretable {{AI}}},
  author = {Thampi, Ajay},
  date = {2022},
  publisher = {Manning},
  location = {New York},
  isbn = {978-1-61729-764-9 978-1-63835-042-2},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/JI56UFT5/Interpretable_AI.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/QH8JMF4J/Thampi - 2022 - Interpretable AI Building Explainable Machine Learning Systems.pdf}
}

@article{thomasf.sturmTColorboxDocumentation,
  title = {{{TColorbox}} - {{Documentation}}},
  author = {{Thomas F. Sturm}},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/M79RRHGX/tcolorbox.pdf}
}

@online{tilltantauPGFTikZManual,
  title = {{{PGF}}/{{TikZ Manual}} - {{Complete Online Documentation}}},
  author = {{Till Tantau}},
  url = {https://tikz.dev/},
  urldate = {2025-11-30},
  abstract = {Full online version of the documentation of PGF/TikZ, the TeX package for creating graphics.},
  langid = {american},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/6GDJDV3E/pgfmanual.pdf;/Users/bernhardgerlach/1_Bibliothek Zotero/storage/TFJ4RMH7/tikz.dev.html}
}

@book{tonelloPracticalLinuxDevOps2022,
  title = {Practical {{Linux DevOps}}: {{Building}} a {{Linux Lab}} for {{Modern Software Development}}},
  shorttitle = {Practical {{Linux DevOps}}},
  author = {Tonello, John S.},
  date = {2022},
  edition = {1st ed},
  publisher = {Apress L. P},
  location = {Berkeley, CA},
  isbn = {978-1-4842-8317-2 978-1-4842-8318-9},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/22C3YPMW/Tonello - 2022 - Practical Linux DevOps Building a Linux Lab for Modern Software Development.epub}
}

@book{tukeyExploratoryDataAnalysis1977,
  title = {Exploratory Data Analysis},
  author = {Tukey, John Wilder},
  date = {1977},
  series = {Addison-{{Wesley}} Series in Behavioral Science},
  publisher = {Addison-Wesley publ},
  location = {Reading (Mass.) Menlo Park (Calif.) London [etc.]},
  isbn = {978-0-201-07616-5},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/6WX54EZW/Tukey - 1977 - Exploratory data analysis.pdf}
}

@book{unknownVIMBookOPL,
  title = {{{VIM Book OPL}}},
  author = {{unknown}},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/RKMMVSNZ/VIM Book OPL.pdf}
}

@book{varmaProBashLearn2023,
  title = {Pro {{Bash}}: {{Learn}} to {{Script}} and {{Program}} the {{GNU}}/{{Linux Shell}}},
  shorttitle = {Pro {{Bash}}},
  author = {Varma, Jayant},
  date = {2023},
  edition = {3rd ed},
  publisher = {Apress L. P},
  location = {Berkeley, CA},
  abstract = {Intro -- Table of Contents -- About the Authors -- About the Technical Reviewer -- Acknowledgments -- Chapter 1: Hello, World: Your First Shell Program -- What Is a Shell Script? -- The Hello World Code -- The Hello World Program File -- Naming the Script File -- Selecting a Directory for the Script -- Creating the File and Running the Script -- Choosing and Using a Text Editor -- Building a Better "Hello, World!" -- Summary -- Commands -- Concepts -- Variables -- Exercises -- Chapter 2: Input, Output, and Throughput -- Parameters and Variables -- Positional Parameters -- Special *\#0?\_!- Parameters -- Variables -- Arguments and Options -- Why You Should Avoid echo -- printf: Formatting and Printing Data -- Escape Sequences -- Format Specifiers -- Width Specification -- Printing to a Variable -- Line Continuation -- Standard Input/Output Streams and Redirection -- Redirection: \&gt -- , \&gt -- \&gt -- , and \&lt -- -- Reading Input -- Pipelines -- Command Substitution -- Summary -- Commands -- Concepts -- Exercises -- Chapter 3: Looping and Branching -- Exit Status -- Testing an Expression -- test, a.k.a. [ … ] -- File Tests -- Integer Tests -- String Tests -- [[ … ]]: Evaluate an Expression -- Enhancements over Test -- (( …)): Evaluate an Arithmetic Expression -- Conditional Execution -- if -- Conditional Operators: \&amp -- \&amp -- and || -- case -- Looping -- while -- until -- for -- break -- continue -- Summary -- Commands -- Concepts -- Exercises -- Chapter 4: Command-Line Parsing and Expansion -- Quoting -- Brace Expansion -- Tilde Expansion -- Parameter and Variable Expansion -- Arithmetic Expansion -- Command Substitution -- Word Splitting -- Pathname Expansion -- Process Substitution -- Parsing Options -- Summary -- Commands -- Exercises -- Chapter 5: Parameters and Variables -- The Naming of Variables},
  isbn = {978-1-4842-9588-5},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/YR8EGVDV/Varma - 2023 - Pro Bash Learn to Script and Program the GNULinux Shell.epub}
}

@online{vaswaniAttentionAllYou2023,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  date = {2023-08-02},
  eprint = {1706.03762},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1706.03762},
  url = {http://arxiv.org/abs/1706.03762},
  urldate = {2025-12-07},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/U3C7FIKY/Vaswani et al. - 2023 - Attention Is All You Need.pdf}
}

@book{vostokovFoundationsARM64Linux2023,
  title = {Foundations of {{ARM64 Linux Debugging}}, {{Disassembling}}, and {{Reversing}}: {{Analyze Code}}, {{Understand Stack Memory Usage}}, and {{Reconstruct Original C}}/{{C}}++ {{Code}} with {{ARM64}}},
  shorttitle = {Foundations of {{ARM64 Linux Debugging}}, {{Disassembling}}, and {{Reversing}}},
  author = {Vostokov, Dmitry},
  date = {2023},
  edition = {1st ed},
  publisher = {Apress L. P},
  location = {Berkeley, CA},
  isbn = {978-1-4842-9081-1 978-1-4842-9082-8},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/W9XJKP22/Vostokov - 2023 - Foundations of ARM64 Linux Debugging, Disassembling, and Reversing Analyze Code, Understand Stack M.epub}
}

@book{vostokovFoundationsLinuxDebugging2023,
  title = {Foundations of {{Linux Debugging}}, {{Disassembling}}, and {{Reversing}}: {{Analyze Binary Code}}, {{Understand Stack Memory Usage}}, and {{Reconstruct C}}/{{C}}++ {{Code}} with {{Intel X64}}},
  shorttitle = {Foundations of {{Linux Debugging}}, {{Disassembling}}, and {{Reversing}}},
  author = {Vostokov, Dmitry},
  date = {2023},
  edition = {1st ed},
  publisher = {Apress L. P},
  location = {Berkeley, CA},
  isbn = {978-1-4842-9152-8 978-1-4842-9153-5},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/9SRVFCQC/Vostokov - 2023 - Foundations of Linux Debugging, Disassembling, and Reversing Analyze Binary Code, Understand Stack.epub}
}

@book{vriesLearnOpenGLGraphics2020,
  title = {Learn {{OpenGL}} - Graphics Programming: Learn Modern {{OpenGL}} Graphics Programming in a Step-by-Step Fashion},
  shorttitle = {Learn {{OpenGL}} - Graphics Programming},
  author = {family=Vries, given=Joey, prefix=de, useprefix=false},
  date = {2020},
  publisher = {Kendall \& Welling},
  location = {Erscheinungsort nicht ermittelbar},
  abstract = {Graphics programmers are often coined the 'wizards' of the game industry. As every magician knows, terms like wizardry and magic are often somewhat exaggerated. Yet, there is a certain charm to graphics programming: the ability to conjure up complete living worlds at our fingertips. Learn OpenGL will teach you the basics, the intermediate, and tons of advanced knowledge, using modern (core-profile) OpenGL. The aim of this book is to show you all there is to modern OpenGL in an easy-to-understand fashion, with clear examples and step-by-step instructions, while also providing a useful reference for later studies. After years of continuous work and improvements on the accompanying website learnopengl.com, with the help of thousands of readers, its content has been professionally revised for this physical copy you now find in your hands. Graphics programming isn't as hard as many people make it out to be... you just need to start},
  isbn = {978-90-90-33256-7},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/5DHHGHXY/Vries - 2020 - Learn OpenGL - graphics programming learn modern OpenGL graphics programming in a step-by-step fash.pdf}
}

@online{weaverConstructingMinimalPerfect2019,
  title = {Constructing {{Minimal Perfect Hash Functions Using SAT Technology}}},
  author = {Weaver, Sean and Heule, Marijn},
  date = {2019-11-22},
  eprint = {1911.10099},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1911.10099},
  url = {http://arxiv.org/abs/1911.10099},
  urldate = {2025-12-04},
  abstract = {Minimal perfect hash functions (MPHFs) are used to provide efficient access to values of large dictionaries (sets of key-value pairs). Discovering new algorithms for building MPHFs is an area of active research, especially from the perspective of storage efficiency. The information-theoretic limit for MPHFs is 1/(ln 2) or roughly 1.44 bits per key. The current best practical algorithms range between 2 and 4 bits per key. In this article, we propose two SAT-based constructions of MPHFs. Our first construction yields MPHFs near the information-theoretic limit. For this construction, current state-of-the-art SAT solvers can handle instances where the dictionaries contain up to 40 elements, thereby outperforming the existing (brute-force) methods. Our second construction uses XOR-SAT filters to realize a practical approach with long-term storage of approximately 1.83 bits per key.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Logic in Computer Science},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/7XDB964K/Weaver und Heule - 2019 - Constructing Minimal Perfect Hash Functions Using SAT Technology.pdf}
}

@article{wellingFirstEncounterMachine2011,
  title = {A {{First Encounter}} with {{Machine Learning}}},
  author = {Welling, Max},
  date = {2011-02-04},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/XDD8FXWU/Welling - A First Encounter with Machine Learning.pdf}
}

@article{wickhamTidyData2014,
  title = {Tidy {{Data}}},
  author = {Wickham, Hadley},
  date = {2014-09-12},
  journaltitle = {Journal of Statistical Software},
  shortjournal = {J. Stat. Soft.},
  volume = {59},
  number = {10},
  pages = {1--23},
  doi = {10.18637/jss.v059.i10},
  url = {https://www.jstatsoft.org/index.php/jss/article/view/v059i10},
  urldate = {2025-12-04},
  abstract = {A huge amount of effort is spent cleaning data to get it ready for analysis, but there has been little research on how to make data cleaning as easy and effective as possible. This paper tackles a small, but important, component of data cleaning: data tidying. Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets. This structure also makes it easier to develop tidy tools for data analysis, tools that both input and output tidy datasets. The advantages of a consistent data structure and matching tools are demonstrated with a case study free from mundane data manipulation chores.},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/AA2JZBTN/Wickham - 2014 - Tidy Data.pdf}
}

@book{winteringhamSoftwareTestingGenerative2025,
  title = {Software Testing with Generative {{AI}}},
  author = {Winteringham, Mark},
  namea = {Martin, Nicola},
  nameatype = {collaborator},
  date = {2025},
  publisher = {Manning Publications Co},
  location = {Shelter Island, NY},
  isbn = {978-1-63343-736-4},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/3A5H6DDM/Winteringham - 2025 - Software testing with generative AI.pdf}
}

@book{yamgMathematicsCivilEngineers2017,
  title = {Mathematics for {{Civil Engineers}}: An {{Introduction}}},
  shorttitle = {Mathematics for {{Civil Engineers}}},
  author = {Yamg, Xin-She},
  date = {2017},
  publisher = {Dunedin Academic Press},
  location = {Edinburgh},
  abstract = {Civil Engineers use mathematics as part of their daily routine. In this introductory book Dr Yang provides methods for practical application as well as an introductory text for undergraduate students},
  isbn = {978-1-78046-084-0},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/Zotero/storage/YQ2DTXUK/Yang - 2018 - Mathematics for Civil Engineers - An Introduction.pdf}
}

@article{yangDynamicPerfectHash1984,
  title = {A {{Dynamic Perfect Hash Function Defined}} by an {{Extended Hash Indicator Table}}},
  author = {Yang, W P and Du, M W},
  date = {1984},
  abstract = {This paper presents a new dynamic file organization scheme based on hashing. The hash functions used here, being defined by extended hash indicator tables (EHITs), are both dynamic and perfect. The allocated storage space can be enlarged and shrunk without reorganizing the data file. Simulation results show'that the storage utilization is approximately equal to 70\% in an experiment where the number of rehash functions s=7, the size of a segment r=lO, and the size of the key set n varies from 1 to 1000. Since the hash functions are perfect, the retrieval operation needs only one disk access.},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/SJ67QF9G/Yang und Du - 1984 - A Dynamic Perfect Hash Function Defined by an Extended Hash Indicator Table.PDF}
}

@unpublished{yannlecunDeepLearningTutorial2013,
  title = {Deep {{Learning Tutorial}}},
  author = {{Yann LeCun}},
  date = {2013-06-16},
  location = {Center for Data Science \& Courant Institute, NYU},
  url = {https://www.youtube.com/playlist?list=PLgF7i4LH-YxacgG0OPmTYe1UUQAvcw9Ke},
  langid = {english},
  pagetotal = {204},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/PF367ZAA/Deep Learning Tutorial - Slides - 2013 (lecun-ranzato-icml2013).pdf}
}

@article{yurichevAssemblyLanguageBeginners,
  title = {Assembly {{Language}} for {{Beginners}}},
  author = {Yurichev, Dennis},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/LLSBJ5Q5/Yurichev - Assembly Language for Beginners.pdf}
}

@article{zarrasvandCrashCourseX86,
  title = {A {{Crash Course}} in X86 {{Assembly}} for {{Reverse Engineers}}},
  author = {Zarrasvand, Siavosh},
  langid = {english},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/SADBP2N6/Zarrasvand - A Crash Course in x86 Assembly for Reverse Engineers.pdf}
}

@online{zhangTensorProductAttention2025,
  title = {Tensor {{Product Attention Is All You Need}}},
  author = {Zhang, Yifan and Liu, Yifeng and Yuan, Huizhuo and Qin, Zhen and Yuan, Yang and Gu, Quanquan and Yao, Andrew Chi-Chih},
  date = {2025-10-23},
  eprint = {2501.06425},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2501.06425},
  url = {http://arxiv.org/abs/2501.06425},
  urldate = {2025-12-07},
  abstract = {Scaling language models to handle longer input sequences typically necessitates large key-value (KV) caches, resulting in substantial memory overhead during inference. In this paper, we propose Tensor Product Attention (TPA), a novel attention mechanism that uses tensor decompositions to represent queries, keys, and values compactly, significantly shrinking KV cache size at inference time. By factorizing these representations into contextual low-rank components (contextual factorization) and seamlessly integrating with RoPE, TPA achieves improved model quality alongside memory efficiency. Based on TPA, we introduce the Tensor ProducT ATTenTion Transformer (T6), a new model architecture for sequence modeling. Through extensive empirical evaluation of language modeling tasks, we demonstrate that T6 exceeds the performance of standard Transformer baselines including MHA, MQA, GQA, and MLA across various metrics, including perplexity and a range of renowned evaluation benchmarks. Notably, TPA’s memory efficiency enables the processing of significantly longer sequences under fixed resource constraints, addressing a critical scalability challenge in modern language models. The code is available at https://github.com/tensorgi/T6.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/8W88F82R/Zhang et al. - 2025 - Tensor Product Attention Is All You Need.pdf}
}

@book{zhumatiySupercomputersLinuxSysAdmins2025,
  title = {Supercomputers for {{Linux SysAdmins}}: {{Managing Modern HPC Clusters}} and {{Supercomputers}} from {{Software}} to {{Hardware}}},
  shorttitle = {Supercomputers for {{Linux SysAdmins}}},
  author = {Zhumatiy, Sergey},
  date = {2025},
  edition = {1st ed. 2025},
  publisher = {Apress},
  location = {Berkeley, CA},
  doi = {10.1007/979-8-8688-1600-0},
  isbn = {979-8-8688-1600-0},
  langid = {english},
  pagetotal = {1},
  file = {/Users/bernhardgerlach/1_Bibliothek Zotero/storage/XWC26UC5/Zhumatiy - 2025 - Supercomputers for Linux SysAdmins Managing Modern HPC Clusters and Supercomputers from Software to.epub}
}
